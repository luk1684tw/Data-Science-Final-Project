{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_transfer_baseline.ipynb","version":"0.3.2","provenance":[{"file_id":"1uBJn1ckA7yqIo4w8butGd9u7ZNzCnowO","timestamp":1560362295283},{"file_id":"1FFYZ7OnRYD3APo-w1HXxrQsCxr2MR7FW","timestamp":1560362200513},{"file_id":"11TiVq0H7_CP2GxS-yXb5AgjX_MSfNtxM","timestamp":1560247267804},{"file_id":"1_3EeaN1QGxz19V5HXbVOrHZFVE5wYUwm","timestamp":1559206522821}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lYvWtpiWmQXc","colab_type":"code","outputId":"3ede0788-5a76-40da-df42-cd1e789c46fb","executionInfo":{"status":"ok","timestamp":1560834454106,"user_tz":-480,"elapsed":83521,"user":{"displayName":"鍾昀諠","photoUrl":"","userId":"05912834044091473222"}},"colab":{"base_uri":"https://localhost:8080/","height":600}},"source":["# install pytorch and torchvision\n","!pip3 install torchvision==0.2.2\n","!pip3 install torch==1.0.0 -f https://download.pytorch.org/whl/cu92/stable"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchvision==0.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/a1/66d72a2fe580a9f0fcbaaa5b976911fbbde9dce9b330ba12791997b856e9/torchvision-0.2.2-py2.py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (4.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.16.4)\n","Collecting tqdm==4.19.9 (from torchvision==0.2.2)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n","\u001b[K     |████████████████████████████████| 61kB 23.0MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.1.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.2) (0.46)\n","Installing collected packages: tqdm, torchvision\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","  Found existing installation: torchvision 0.3.0\n","    Uninstalling torchvision-0.3.0:\n","      Successfully uninstalled torchvision-0.3.0\n","Successfully installed torchvision-0.2.2 tqdm-4.19.9\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/cu92/stable\n","Collecting torch==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n","\u001b[K     |████████████████████████████████| 591.8MB 28kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Found existing installation: torch 1.1.0\n","    Uninstalling torch-1.1.0:\n","      Successfully uninstalled torch-1.1.0\n","Successfully installed torch-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"noGHihvRocIU","colab_type":"code","outputId":"cef70a39-49f5-423b-fb67-08a9a8d6532f","executionInfo":{"status":"ok","timestamp":1560834461045,"user_tz":-480,"elapsed":81988,"user":{"displayName":"鍾昀諠","photoUrl":"","userId":"05912834044091473222"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# install pydrive to access imagenet stored in googledrive\n","!pip install -U -q pydrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 7.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 7.1MB/s \n","\u001b[?25h  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jCXEwfOfpq1w","colab_type":"code","colab":{}},"source":["# import librarys to access googledrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials\n","\n","# import pytorch and related packages\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","# import common packages\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOj_-uB1prDP","colab_type":"code","outputId":"443aa294-3a05-4826-ce8f-01311e172d84","executionInfo":{"status":"ok","timestamp":1560834501547,"user_tz":-480,"elapsed":117835,"user":{"displayName":"鍾昀諠","photoUrl":"","userId":"05912834044091473222"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# mount googledrive\n","drive.mount('./Drive', force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at ./Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otTfwEyUSP_W","colab_type":"code","outputId":"9fce3794-6223-4011-c3a8-798e0ba569e1","executionInfo":{"status":"ok","timestamp":1560835175150,"user_tz":-480,"elapsed":3610,"user":{"displayName":"鍾昀諠","photoUrl":"","userId":"05912834044091473222"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# update custom packages\n","if not os.path.exists('/content/dsfinal'):\n","    !git clone https://github.com/luk1684tw/dsfinal.git\n","%cd /content/dsfinal\n","!git pull\n","os.getcwd()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/dsfinal\n","remote: Enumerating objects: 7, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (1/1), done.\u001b[K\n","remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (4/4), done.\n","From https://github.com/luk1684tw/dsfinal\n","   4280dee..9cf32c7  master     -> origin/master\n","Updating 4280dee..9cf32c7\n","Fast-forward\n"," l1-norm-pruning/main_transfer.py | 1 \u001b[31m-\u001b[m\n"," 1 file changed, 1 deletion(-)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content/dsfinal'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"5fx3EjBSoNDU","colab_type":"code","outputId":"08bfe585-95b3-4ccc-dbbe-f18d465be308","executionInfo":{"status":"ok","timestamp":1560595982607,"user_tz":-480,"elapsed":19130534,"user":{"displayName":"張惟筑","photoUrl":"","userId":"00045941261865378743"}},"colab":{"base_uri":"https://localhost:8080/","height":1834}},"source":["%cd l1-norm-pruning/\n","#!python main_transfer.py --dataset cifar10 --scratch modelA100_best.pth.tar --method 2 --dist A100 --batch-size 32\n","#!python main_transfer.py --dataset cifar10 --scratch modelA200_best.pth.tar --method 2 --dist A200 --batch-size 32\n","!python main_transfer.py --dataset cifar10 --scratch modelA500_best.pth.tar --method 0 --dist B500 \n","# !python main_transfer.py --dataset cifar10 --scratch checkpointDistA200.pth.tar --method 3"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/dsfinal/l1-norm-pruning\n","[INFO] Method:  finetune\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/finetune/modelA500_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new transfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.803540\n","Train Epoch: 0 [320/12000 (2.7%)]\tLoss: 5.899422\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.616827\n","Train Epoch: 0 [960/12000 (8.0%)]\tLoss: 4.830357\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.720914\n","Train Epoch: 0 [1600/12000 (13.3%)]\tLoss: 4.654939\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 4.589548\n","Train Epoch: 0 [2240/12000 (18.7%)]\tLoss: 4.343970\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.645724\n","Train Epoch: 0 [2880/12000 (24.0%)]\tLoss: 4.743818\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.412471\n","Train Epoch: 0 [3520/12000 (29.3%)]\tLoss: 4.568203\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.467301\n","Train Epoch: 0 [4160/12000 (34.7%)]\tLoss: 4.476676\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.206027\n","Train Epoch: 0 [4800/12000 (40.0%)]\tLoss: 4.440076\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.250288\n","Train Epoch: 0 [5440/12000 (45.3%)]\tLoss: 4.115897\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.211232\n","Train Epoch: 0 [6080/12000 (50.7%)]\tLoss: 4.334817\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.481040\n","Train Epoch: 0 [6720/12000 (56.0%)]\tLoss: 4.040569\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 3.769318\n","Train Epoch: 0 [7360/12000 (61.3%)]\tLoss: 4.452754\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.060630\n","Train Epoch: 0 [8000/12000 (66.7%)]\tLoss: 4.047083\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 3.658702\n","Train Epoch: 0 [8640/12000 (72.0%)]\tLoss: 4.431091\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.250626\n","Train Epoch: 0 [9280/12000 (77.3%)]\tLoss: 4.384186\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.400023\n","Train Epoch: 0 [9920/12000 (82.7%)]\tLoss: 4.143155\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.134424\n","Train Epoch: 0 [10560/12000 (88.0%)]\tLoss: 4.272482\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.368779\n","Train Epoch: 0 [11200/12000 (93.3%)]\tLoss: 3.864767\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 4.102173\n","Train Epoch: 0 [11840/12000 (98.7%)]\tLoss: 4.088925\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wtDWrhsJcZX","colab_type":"code","outputId":"8e79535d-c46f-4805-b3aa-88730f20b776","colab":{"base_uri":"https://localhost:8080/","height":42477}},"source":["%cd l1-norm-pruning/\n","!python main_transfer.py --dataset cifar10 --scratch modelA100_best.pth.tar --method 2 --dist A100 --batch-size 32\n","!python main_transfer.py --dataset cifar10 --scratch modelA200_best.pth.tar --method 2 --dist A200 --batch-size 32\n","!python main_transfer.py --dataset cifar10 --scratch modelA500_best.pth.tar --method 2 --dist A500 --batch-size 32\n","# !python main_transfer.py --dataset cifar10 --scratch checkpointDistA200.pth.tar --method 3"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/dsfinal/l1-norm-pruning\n","[INFO] Method:  scratchE\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/scratchE/modelA100_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new trasfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.838215\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.523954\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.988637\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 5.079625\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.728930\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.705261\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.357798\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.708573\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.340662\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.482130\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.445547\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 4.492495\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.328741\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 4.065875\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.123610\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.324297\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.222260\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.208129\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 3.890881\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","\n","Test set: Average loss: 4.1672, Accuracy: 646/8580 (7.00%), F1: 0.05\n","\n","Train Epoch: 1 [0/12000 (0.0%)]\tLoss: 4.082260\n","Train Epoch: 1 [640/12000 (5.3%)]\tLoss: 3.934776\n","Train Epoch: 1 [1280/12000 (10.7%)]\tLoss: 3.752941\n","Train Epoch: 1 [1920/12000 (16.0%)]\tLoss: 3.804335\n","Train Epoch: 1 [2560/12000 (21.3%)]\tLoss: 4.077505\n","Train Epoch: 1 [3200/12000 (26.7%)]\tLoss: 4.127241\n","Train Epoch: 1 [3840/12000 (32.0%)]\tLoss: 3.868355\n","Train Epoch: 1 [4480/12000 (37.3%)]\tLoss: 4.334706\n","Train Epoch: 1 [5120/12000 (42.7%)]\tLoss: 4.050394\n","Train Epoch: 1 [5760/12000 (48.0%)]\tLoss: 3.928042\n","Train Epoch: 1 [6400/12000 (53.3%)]\tLoss: 4.147878\n","Train Epoch: 1 [7040/12000 (58.7%)]\tLoss: 4.145665\n","Train Epoch: 1 [7680/12000 (64.0%)]\tLoss: 4.015904\n","Train Epoch: 1 [8320/12000 (69.3%)]\tLoss: 3.937772\n","Train Epoch: 1 [8960/12000 (74.7%)]\tLoss: 4.040449\n","Train Epoch: 1 [9600/12000 (80.0%)]\tLoss: 3.841176\n","Train Epoch: 1 [10240/12000 (85.3%)]\tLoss: 3.983212\n","Train Epoch: 1 [10880/12000 (90.7%)]\tLoss: 4.123879\n","Train Epoch: 1 [11520/12000 (96.0%)]\tLoss: 4.047446\n","\n","Test set: Average loss: 3.9977, Accuracy: 771/8580 (8.00%), F1: 0.08\n","\n","Train Epoch: 2 [0/12000 (0.0%)]\tLoss: 3.861224\n","Train Epoch: 2 [640/12000 (5.3%)]\tLoss: 3.508662\n","Train Epoch: 2 [1280/12000 (10.7%)]\tLoss: 3.248765\n","Train Epoch: 2 [1920/12000 (16.0%)]\tLoss: 4.092702\n","Train Epoch: 2 [2560/12000 (21.3%)]\tLoss: 3.603029\n","Train Epoch: 2 [3200/12000 (26.7%)]\tLoss: 3.702490\n","Train Epoch: 2 [3840/12000 (32.0%)]\tLoss: 3.825881\n","Train Epoch: 2 [4480/12000 (37.3%)]\tLoss: 3.958091\n","Train Epoch: 2 [5120/12000 (42.7%)]\tLoss: 3.559798\n","Train Epoch: 2 [5760/12000 (48.0%)]\tLoss: 3.700421\n","Train Epoch: 2 [6400/12000 (53.3%)]\tLoss: 3.898786\n","Train Epoch: 2 [7040/12000 (58.7%)]\tLoss: 3.872562\n","Train Epoch: 2 [7680/12000 (64.0%)]\tLoss: 3.921809\n","Train Epoch: 2 [8320/12000 (69.3%)]\tLoss: 3.428622\n","Train Epoch: 2 [8960/12000 (74.7%)]\tLoss: 3.569828\n","Train Epoch: 2 [9600/12000 (80.0%)]\tLoss: 3.641808\n","Train Epoch: 2 [10240/12000 (85.3%)]\tLoss: 3.662676\n","Train Epoch: 2 [10880/12000 (90.7%)]\tLoss: 3.734256\n","Train Epoch: 2 [11520/12000 (96.0%)]\tLoss: 3.842074\n","\n","Test set: Average loss: 3.8768, Accuracy: 898/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 3 [0/12000 (0.0%)]\tLoss: 3.091735\n","Train Epoch: 3 [640/12000 (5.3%)]\tLoss: 3.255462\n","Train Epoch: 3 [1280/12000 (10.7%)]\tLoss: 3.134516\n","Train Epoch: 3 [1920/12000 (16.0%)]\tLoss: 3.049857\n","Train Epoch: 3 [2560/12000 (21.3%)]\tLoss: 3.616545\n","Train Epoch: 3 [3200/12000 (26.7%)]\tLoss: 3.345688\n","Train Epoch: 3 [3840/12000 (32.0%)]\tLoss: 2.904064\n","Train Epoch: 3 [4480/12000 (37.3%)]\tLoss: 3.708904\n","Train Epoch: 3 [5120/12000 (42.7%)]\tLoss: 3.676569\n","Train Epoch: 3 [5760/12000 (48.0%)]\tLoss: 2.955998\n","Train Epoch: 3 [6400/12000 (53.3%)]\tLoss: 3.663093\n","Train Epoch: 3 [7040/12000 (58.7%)]\tLoss: 3.326687\n","Train Epoch: 3 [7680/12000 (64.0%)]\tLoss: 3.278756\n","Train Epoch: 3 [8320/12000 (69.3%)]\tLoss: 3.345348\n","Train Epoch: 3 [8960/12000 (74.7%)]\tLoss: 3.713297\n","Train Epoch: 3 [9600/12000 (80.0%)]\tLoss: 3.515210\n","Train Epoch: 3 [10240/12000 (85.3%)]\tLoss: 3.518625\n","Train Epoch: 3 [10880/12000 (90.7%)]\tLoss: 3.419125\n","Train Epoch: 3 [11520/12000 (96.0%)]\tLoss: 3.407539\n","\n","Test set: Average loss: 3.9391, Accuracy: 959/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 4 [0/12000 (0.0%)]\tLoss: 2.704507\n","Train Epoch: 4 [640/12000 (5.3%)]\tLoss: 3.079609\n","Train Epoch: 4 [1280/12000 (10.7%)]\tLoss: 3.299051\n","Train Epoch: 4 [1920/12000 (16.0%)]\tLoss: 2.538142\n","Train Epoch: 4 [2560/12000 (21.3%)]\tLoss: 3.144367\n","Train Epoch: 4 [3200/12000 (26.7%)]\tLoss: 2.957622\n","Train Epoch: 4 [3840/12000 (32.0%)]\tLoss: 3.354344\n","Train Epoch: 4 [4480/12000 (37.3%)]\tLoss: 2.806453\n","Train Epoch: 4 [5120/12000 (42.7%)]\tLoss: 3.338472\n","Train Epoch: 4 [5760/12000 (48.0%)]\tLoss: 3.270961\n","Train Epoch: 4 [6400/12000 (53.3%)]\tLoss: 3.607124\n","Train Epoch: 4 [7040/12000 (58.7%)]\tLoss: 2.775383\n","Train Epoch: 4 [7680/12000 (64.0%)]\tLoss: 2.911388\n","Train Epoch: 4 [8320/12000 (69.3%)]\tLoss: 2.943121\n","Train Epoch: 4 [8960/12000 (74.7%)]\tLoss: 3.339554\n","Train Epoch: 4 [9600/12000 (80.0%)]\tLoss: 3.336347\n","Train Epoch: 4 [10240/12000 (85.3%)]\tLoss: 2.911235\n","Train Epoch: 4 [10880/12000 (90.7%)]\tLoss: 3.289722\n","Train Epoch: 4 [11520/12000 (96.0%)]\tLoss: 3.237891\n","\n","Test set: Average loss: 4.0073, Accuracy: 953/8580 (11.00%), F1: 0.05\n","\n","Train Epoch: 5 [0/12000 (0.0%)]\tLoss: 2.331459\n","Train Epoch: 5 [640/12000 (5.3%)]\tLoss: 2.341927\n","Train Epoch: 5 [1280/12000 (10.7%)]\tLoss: 2.950955\n","Train Epoch: 5 [1920/12000 (16.0%)]\tLoss: 2.651316\n","Train Epoch: 5 [2560/12000 (21.3%)]\tLoss: 2.562518\n","Train Epoch: 5 [3200/12000 (26.7%)]\tLoss: 3.010924\n","Train Epoch: 5 [3840/12000 (32.0%)]\tLoss: 2.605490\n","Train Epoch: 5 [4480/12000 (37.3%)]\tLoss: 2.708563\n","Train Epoch: 5 [5120/12000 (42.7%)]\tLoss: 2.837600\n","Train Epoch: 5 [5760/12000 (48.0%)]\tLoss: 2.169113\n","Train Epoch: 5 [6400/12000 (53.3%)]\tLoss: 2.923596\n","Train Epoch: 5 [7040/12000 (58.7%)]\tLoss: 2.543212\n","Train Epoch: 5 [7680/12000 (64.0%)]\tLoss: 2.489563\n","Train Epoch: 5 [8320/12000 (69.3%)]\tLoss: 3.549547\n","Train Epoch: 5 [8960/12000 (74.7%)]\tLoss: 2.978942\n","Train Epoch: 5 [9600/12000 (80.0%)]\tLoss: 2.662080\n","Train Epoch: 5 [10240/12000 (85.3%)]\tLoss: 2.984629\n","Train Epoch: 5 [10880/12000 (90.7%)]\tLoss: 3.051358\n","Train Epoch: 5 [11520/12000 (96.0%)]\tLoss: 2.919198\n","\n","Test set: Average loss: 4.1765, Accuracy: 973/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 6 [0/12000 (0.0%)]\tLoss: 2.504475\n","Train Epoch: 6 [640/12000 (5.3%)]\tLoss: 2.365691\n","Train Epoch: 6 [1280/12000 (10.7%)]\tLoss: 2.645247\n","Train Epoch: 6 [1920/12000 (16.0%)]\tLoss: 2.198176\n","Train Epoch: 6 [2560/12000 (21.3%)]\tLoss: 2.675375\n","Train Epoch: 6 [3200/12000 (26.7%)]\tLoss: 2.509138\n","Train Epoch: 6 [3840/12000 (32.0%)]\tLoss: 2.585006\n","Train Epoch: 6 [4480/12000 (37.3%)]\tLoss: 2.594194\n","Train Epoch: 6 [5120/12000 (42.7%)]\tLoss: 2.289321\n","Train Epoch: 6 [5760/12000 (48.0%)]\tLoss: 2.721001\n","Train Epoch: 6 [6400/12000 (53.3%)]\tLoss: 2.251022\n","Train Epoch: 6 [7040/12000 (58.7%)]\tLoss: 2.463446\n","Train Epoch: 6 [7680/12000 (64.0%)]\tLoss: 2.861502\n","Train Epoch: 6 [8320/12000 (69.3%)]\tLoss: 2.892190\n","Train Epoch: 6 [8960/12000 (74.7%)]\tLoss: 2.383687\n","Train Epoch: 6 [9600/12000 (80.0%)]\tLoss: 2.684537\n","Train Epoch: 6 [10240/12000 (85.3%)]\tLoss: 3.077240\n","Train Epoch: 6 [10880/12000 (90.7%)]\tLoss: 3.007514\n","Train Epoch: 6 [11520/12000 (96.0%)]\tLoss: 2.879052\n","\n","Test set: Average loss: 4.3056, Accuracy: 1027/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 7 [0/12000 (0.0%)]\tLoss: 1.980910\n","Train Epoch: 7 [640/12000 (5.3%)]\tLoss: 2.586321\n","Train Epoch: 7 [1280/12000 (10.7%)]\tLoss: 1.655172\n","Train Epoch: 7 [1920/12000 (16.0%)]\tLoss: 2.263050\n","Train Epoch: 7 [2560/12000 (21.3%)]\tLoss: 2.583041\n","Train Epoch: 7 [3200/12000 (26.7%)]\tLoss: 1.597534\n","Train Epoch: 7 [3840/12000 (32.0%)]\tLoss: 2.408349\n","Train Epoch: 7 [4480/12000 (37.3%)]\tLoss: 2.826995\n","Train Epoch: 7 [5120/12000 (42.7%)]\tLoss: 2.235647\n","Train Epoch: 7 [5760/12000 (48.0%)]\tLoss: 2.117180\n","Train Epoch: 7 [6400/12000 (53.3%)]\tLoss: 2.163368\n","Train Epoch: 7 [7040/12000 (58.7%)]\tLoss: 2.544743\n","Train Epoch: 7 [7680/12000 (64.0%)]\tLoss: 2.252189\n","Train Epoch: 7 [8320/12000 (69.3%)]\tLoss: 2.816339\n","Train Epoch: 7 [8960/12000 (74.7%)]\tLoss: 2.125484\n","Train Epoch: 7 [9600/12000 (80.0%)]\tLoss: 1.982895\n","Train Epoch: 7 [10240/12000 (85.3%)]\tLoss: 3.169270\n","Train Epoch: 7 [10880/12000 (90.7%)]\tLoss: 2.701613\n","Train Epoch: 7 [11520/12000 (96.0%)]\tLoss: 2.210361\n","\n","Test set: Average loss: 4.4197, Accuracy: 980/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 8 [0/12000 (0.0%)]\tLoss: 1.499493\n","Train Epoch: 8 [640/12000 (5.3%)]\tLoss: 2.133311\n","Train Epoch: 8 [1280/12000 (10.7%)]\tLoss: 2.300357\n","Train Epoch: 8 [1920/12000 (16.0%)]\tLoss: 1.568982\n","Train Epoch: 8 [2560/12000 (21.3%)]\tLoss: 2.140570\n","Train Epoch: 8 [3200/12000 (26.7%)]\tLoss: 1.496450\n","Train Epoch: 8 [3840/12000 (32.0%)]\tLoss: 2.135802\n","Train Epoch: 8 [4480/12000 (37.3%)]\tLoss: 1.898198\n","Train Epoch: 8 [5120/12000 (42.7%)]\tLoss: 2.827038\n","Train Epoch: 8 [5760/12000 (48.0%)]\tLoss: 1.932295\n","Train Epoch: 8 [6400/12000 (53.3%)]\tLoss: 1.752184\n","Train Epoch: 8 [7040/12000 (58.7%)]\tLoss: 1.678251\n","Train Epoch: 8 [7680/12000 (64.0%)]\tLoss: 2.031315\n","Train Epoch: 8 [8320/12000 (69.3%)]\tLoss: 2.443337\n","Train Epoch: 8 [8960/12000 (74.7%)]\tLoss: 2.479793\n","Train Epoch: 8 [9600/12000 (80.0%)]\tLoss: 1.941930\n","Train Epoch: 8 [10240/12000 (85.3%)]\tLoss: 3.162802\n","Train Epoch: 8 [10880/12000 (90.7%)]\tLoss: 1.613390\n","Train Epoch: 8 [11520/12000 (96.0%)]\tLoss: 1.860137\n","\n","Test set: Average loss: 4.6263, Accuracy: 1016/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 9 [0/12000 (0.0%)]\tLoss: 2.035464\n","Train Epoch: 9 [640/12000 (5.3%)]\tLoss: 1.351393\n","Train Epoch: 9 [1280/12000 (10.7%)]\tLoss: 1.519511\n","Train Epoch: 9 [1920/12000 (16.0%)]\tLoss: 1.615840\n","Train Epoch: 9 [2560/12000 (21.3%)]\tLoss: 0.974937\n","Train Epoch: 9 [3200/12000 (26.7%)]\tLoss: 1.505881\n","Train Epoch: 9 [3840/12000 (32.0%)]\tLoss: 1.745612\n","Train Epoch: 9 [4480/12000 (37.3%)]\tLoss: 2.462193\n","Train Epoch: 9 [5120/12000 (42.7%)]\tLoss: 1.822529\n","Train Epoch: 9 [5760/12000 (48.0%)]\tLoss: 2.283356\n","Train Epoch: 9 [6400/12000 (53.3%)]\tLoss: 1.611489\n","Train Epoch: 9 [7040/12000 (58.7%)]\tLoss: 1.473774\n","Train Epoch: 9 [7680/12000 (64.0%)]\tLoss: 2.201932\n","Train Epoch: 9 [8320/12000 (69.3%)]\tLoss: 2.052193\n","Train Epoch: 9 [8960/12000 (74.7%)]\tLoss: 1.805202\n","Train Epoch: 9 [9600/12000 (80.0%)]\tLoss: 1.874088\n","Train Epoch: 9 [10240/12000 (85.3%)]\tLoss: 1.763397\n","Train Epoch: 9 [10880/12000 (90.7%)]\tLoss: 1.899304\n","Train Epoch: 9 [11520/12000 (96.0%)]\tLoss: 2.080879\n","\n","Test set: Average loss: 4.7617, Accuracy: 969/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 10 [0/12000 (0.0%)]\tLoss: 0.960442\n","Train Epoch: 10 [640/12000 (5.3%)]\tLoss: 1.923311\n","Train Epoch: 10 [1280/12000 (10.7%)]\tLoss: 1.111750\n","Train Epoch: 10 [1920/12000 (16.0%)]\tLoss: 1.227984\n","Train Epoch: 10 [2560/12000 (21.3%)]\tLoss: 1.608819\n","Train Epoch: 10 [3200/12000 (26.7%)]\tLoss: 1.043840\n","Train Epoch: 10 [3840/12000 (32.0%)]\tLoss: 1.379601\n","Train Epoch: 10 [4480/12000 (37.3%)]\tLoss: 1.721928\n","Train Epoch: 10 [5120/12000 (42.7%)]\tLoss: 1.452094\n","Train Epoch: 10 [5760/12000 (48.0%)]\tLoss: 1.354947\n","Train Epoch: 10 [6400/12000 (53.3%)]\tLoss: 1.701468\n","Train Epoch: 10 [7040/12000 (58.7%)]\tLoss: 1.948701\n","Train Epoch: 10 [7680/12000 (64.0%)]\tLoss: 1.607500\n","Train Epoch: 10 [8320/12000 (69.3%)]\tLoss: 1.761308\n","Train Epoch: 10 [8960/12000 (74.7%)]\tLoss: 1.592795\n","Train Epoch: 10 [9600/12000 (80.0%)]\tLoss: 1.919116\n","Train Epoch: 10 [10240/12000 (85.3%)]\tLoss: 2.207605\n","Train Epoch: 10 [10880/12000 (90.7%)]\tLoss: 1.486151\n","Train Epoch: 10 [11520/12000 (96.0%)]\tLoss: 1.799092\n","\n","Test set: Average loss: 5.0386, Accuracy: 1010/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 11 [0/12000 (0.0%)]\tLoss: 1.063663\n","Train Epoch: 11 [640/12000 (5.3%)]\tLoss: 1.208930\n","Train Epoch: 11 [1280/12000 (10.7%)]\tLoss: 0.633389\n","Train Epoch: 11 [1920/12000 (16.0%)]\tLoss: 1.220616\n","Train Epoch: 11 [2560/12000 (21.3%)]\tLoss: 1.121749\n","Train Epoch: 11 [3200/12000 (26.7%)]\tLoss: 1.874880\n","Train Epoch: 11 [3840/12000 (32.0%)]\tLoss: 0.786180\n","Train Epoch: 11 [4480/12000 (37.3%)]\tLoss: 1.340230\n","Train Epoch: 11 [5120/12000 (42.7%)]\tLoss: 1.631349\n","Train Epoch: 11 [5760/12000 (48.0%)]\tLoss: 1.297748\n","Train Epoch: 11 [6400/12000 (53.3%)]\tLoss: 1.867763\n","Train Epoch: 11 [7040/12000 (58.7%)]\tLoss: 1.744521\n","Train Epoch: 11 [7680/12000 (64.0%)]\tLoss: 2.465435\n","Train Epoch: 11 [8320/12000 (69.3%)]\tLoss: 1.357741\n","Train Epoch: 11 [8960/12000 (74.7%)]\tLoss: 1.100986\n","Train Epoch: 11 [9600/12000 (80.0%)]\tLoss: 1.201949\n","Train Epoch: 11 [10240/12000 (85.3%)]\tLoss: 1.471942\n","Train Epoch: 11 [10880/12000 (90.7%)]\tLoss: 1.345231\n","Train Epoch: 11 [11520/12000 (96.0%)]\tLoss: 2.028378\n","\n","Test set: Average loss: 5.2827, Accuracy: 935/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 12 [0/12000 (0.0%)]\tLoss: 1.355524\n","Train Epoch: 12 [640/12000 (5.3%)]\tLoss: 1.470757\n","Train Epoch: 12 [1280/12000 (10.7%)]\tLoss: 1.485551\n","Train Epoch: 12 [1920/12000 (16.0%)]\tLoss: 1.345050\n","Train Epoch: 12 [2560/12000 (21.3%)]\tLoss: 0.711447\n","Train Epoch: 12 [3200/12000 (26.7%)]\tLoss: 0.941484\n","Train Epoch: 12 [3840/12000 (32.0%)]\tLoss: 1.034929\n","Train Epoch: 12 [4480/12000 (37.3%)]\tLoss: 1.908020\n","Train Epoch: 12 [5120/12000 (42.7%)]\tLoss: 2.178956\n","Train Epoch: 12 [5760/12000 (48.0%)]\tLoss: 1.859366\n","Train Epoch: 12 [6400/12000 (53.3%)]\tLoss: 1.085545\n","Train Epoch: 12 [7040/12000 (58.7%)]\tLoss: 0.894252\n","Train Epoch: 12 [7680/12000 (64.0%)]\tLoss: 1.015431\n","Train Epoch: 12 [8320/12000 (69.3%)]\tLoss: 1.632956\n","Train Epoch: 12 [8960/12000 (74.7%)]\tLoss: 1.369966\n","Train Epoch: 12 [9600/12000 (80.0%)]\tLoss: 1.285294\n","Train Epoch: 12 [10240/12000 (85.3%)]\tLoss: 1.168180\n","Train Epoch: 12 [10880/12000 (90.7%)]\tLoss: 1.534547\n","Train Epoch: 12 [11520/12000 (96.0%)]\tLoss: 1.779484\n","\n","Test set: Average loss: 5.3985, Accuracy: 924/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 13 [0/12000 (0.0%)]\tLoss: 1.573284\n","Train Epoch: 13 [640/12000 (5.3%)]\tLoss: 0.967340\n","Train Epoch: 13 [1280/12000 (10.7%)]\tLoss: 0.918512\n","Train Epoch: 13 [1920/12000 (16.0%)]\tLoss: 0.681974\n","Train Epoch: 13 [2560/12000 (21.3%)]\tLoss: 1.103325\n","Train Epoch: 13 [3200/12000 (26.7%)]\tLoss: 1.214041\n","Train Epoch: 13 [3840/12000 (32.0%)]\tLoss: 1.742530\n","Train Epoch: 13 [4480/12000 (37.3%)]\tLoss: 1.224650\n","Train Epoch: 13 [5120/12000 (42.7%)]\tLoss: 0.832179\n","Train Epoch: 13 [5760/12000 (48.0%)]\tLoss: 1.000853\n","Train Epoch: 13 [6400/12000 (53.3%)]\tLoss: 0.985907\n","Train Epoch: 13 [7040/12000 (58.7%)]\tLoss: 1.191107\n","Train Epoch: 13 [7680/12000 (64.0%)]\tLoss: 0.893029\n","Train Epoch: 13 [8320/12000 (69.3%)]\tLoss: 2.000132\n","Train Epoch: 13 [8960/12000 (74.7%)]\tLoss: 0.913840\n","Train Epoch: 13 [9600/12000 (80.0%)]\tLoss: 1.982250\n","Train Epoch: 13 [10240/12000 (85.3%)]\tLoss: 1.547828\n","Train Epoch: 13 [10880/12000 (90.7%)]\tLoss: 1.286154\n","Train Epoch: 13 [11520/12000 (96.0%)]\tLoss: 1.398952\n","\n","Test set: Average loss: 5.6402, Accuracy: 966/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 14 [0/12000 (0.0%)]\tLoss: 1.104928\n","Train Epoch: 14 [640/12000 (5.3%)]\tLoss: 1.103671\n","Train Epoch: 14 [1280/12000 (10.7%)]\tLoss: 0.906623\n","Train Epoch: 14 [1920/12000 (16.0%)]\tLoss: 0.791638\n","Train Epoch: 14 [2560/12000 (21.3%)]\tLoss: 1.035186\n","Train Epoch: 14 [3200/12000 (26.7%)]\tLoss: 1.368568\n","Train Epoch: 14 [3840/12000 (32.0%)]\tLoss: 1.641337\n","Train Epoch: 14 [4480/12000 (37.3%)]\tLoss: 1.143181\n","Train Epoch: 14 [5120/12000 (42.7%)]\tLoss: 0.750526\n","Train Epoch: 14 [5760/12000 (48.0%)]\tLoss: 1.211236\n","Train Epoch: 14 [6400/12000 (53.3%)]\tLoss: 1.659634\n","Train Epoch: 14 [7040/12000 (58.7%)]\tLoss: 1.652323\n","Train Epoch: 14 [7680/12000 (64.0%)]\tLoss: 2.012183\n","Train Epoch: 14 [8320/12000 (69.3%)]\tLoss: 1.125774\n","Train Epoch: 14 [8960/12000 (74.7%)]\tLoss: 0.961003\n","Train Epoch: 14 [9600/12000 (80.0%)]\tLoss: 0.793011\n","Train Epoch: 14 [10240/12000 (85.3%)]\tLoss: 0.742175\n","Train Epoch: 14 [10880/12000 (90.7%)]\tLoss: 0.825090\n","Train Epoch: 14 [11520/12000 (96.0%)]\tLoss: 1.317722\n","\n","Test set: Average loss: 5.6118, Accuracy: 873/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 15 [0/12000 (0.0%)]\tLoss: 1.170682\n","Train Epoch: 15 [640/12000 (5.3%)]\tLoss: 0.436005\n","Train Epoch: 15 [1280/12000 (10.7%)]\tLoss: 0.814838\n","Train Epoch: 15 [1920/12000 (16.0%)]\tLoss: 1.209378\n","Train Epoch: 15 [2560/12000 (21.3%)]\tLoss: 1.224536\n","Train Epoch: 15 [3200/12000 (26.7%)]\tLoss: 0.734818\n","Train Epoch: 15 [3840/12000 (32.0%)]\tLoss: 1.527569\n","Train Epoch: 15 [4480/12000 (37.3%)]\tLoss: 1.039903\n","Train Epoch: 15 [5120/12000 (42.7%)]\tLoss: 0.853614\n","Train Epoch: 15 [5760/12000 (48.0%)]\tLoss: 1.324732\n","Train Epoch: 15 [6400/12000 (53.3%)]\tLoss: 1.225741\n","Train Epoch: 15 [7040/12000 (58.7%)]\tLoss: 0.882349\n","Train Epoch: 15 [7680/12000 (64.0%)]\tLoss: 0.912741\n","Train Epoch: 15 [8320/12000 (69.3%)]\tLoss: 0.905276\n","Train Epoch: 15 [8960/12000 (74.7%)]\tLoss: 1.464184\n","Train Epoch: 15 [9600/12000 (80.0%)]\tLoss: 0.815706\n","Train Epoch: 15 [10240/12000 (85.3%)]\tLoss: 0.930284\n","Train Epoch: 15 [10880/12000 (90.7%)]\tLoss: 1.691620\n","Train Epoch: 15 [11520/12000 (96.0%)]\tLoss: 1.074996\n","\n","Test set: Average loss: 5.6144, Accuracy: 941/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 16 [0/12000 (0.0%)]\tLoss: 0.611608\n","Train Epoch: 16 [640/12000 (5.3%)]\tLoss: 0.827739\n","Train Epoch: 16 [1280/12000 (10.7%)]\tLoss: 0.373744\n","Train Epoch: 16 [1920/12000 (16.0%)]\tLoss: 0.650301\n","Train Epoch: 16 [2560/12000 (21.3%)]\tLoss: 0.960885\n","Train Epoch: 16 [3200/12000 (26.7%)]\tLoss: 0.796951\n","Train Epoch: 16 [3840/12000 (32.0%)]\tLoss: 0.851080\n","Train Epoch: 16 [4480/12000 (37.3%)]\tLoss: 1.040938\n","Train Epoch: 16 [5120/12000 (42.7%)]\tLoss: 1.601756\n","Train Epoch: 16 [5760/12000 (48.0%)]\tLoss: 1.092314\n","Train Epoch: 16 [6400/12000 (53.3%)]\tLoss: 1.187495\n","Train Epoch: 16 [7040/12000 (58.7%)]\tLoss: 1.813725\n","Train Epoch: 16 [7680/12000 (64.0%)]\tLoss: 0.863027\n","Train Epoch: 16 [8320/12000 (69.3%)]\tLoss: 1.526937\n","Train Epoch: 16 [8960/12000 (74.7%)]\tLoss: 1.122212\n","Train Epoch: 16 [9600/12000 (80.0%)]\tLoss: 1.333598\n","Train Epoch: 16 [10240/12000 (85.3%)]\tLoss: 1.065834\n","Train Epoch: 16 [10880/12000 (90.7%)]\tLoss: 1.555708\n","Train Epoch: 16 [11520/12000 (96.0%)]\tLoss: 0.788763\n","\n","Test set: Average loss: 5.7868, Accuracy: 969/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 17 [0/12000 (0.0%)]\tLoss: 0.468580\n","Train Epoch: 17 [640/12000 (5.3%)]\tLoss: 0.497125\n","Train Epoch: 17 [1280/12000 (10.7%)]\tLoss: 0.921886\n","Train Epoch: 17 [1920/12000 (16.0%)]\tLoss: 0.664390\n","Train Epoch: 17 [2560/12000 (21.3%)]\tLoss: 0.368408\n","Train Epoch: 17 [3200/12000 (26.7%)]\tLoss: 0.748515\n","Train Epoch: 17 [3840/12000 (32.0%)]\tLoss: 0.941819\n","Train Epoch: 17 [4480/12000 (37.3%)]\tLoss: 0.851684\n","Train Epoch: 17 [5120/12000 (42.7%)]\tLoss: 0.534910\n","Train Epoch: 17 [5760/12000 (48.0%)]\tLoss: 0.392217\n","Train Epoch: 17 [6400/12000 (53.3%)]\tLoss: 0.664438\n","Train Epoch: 17 [7040/12000 (58.7%)]\tLoss: 1.259257\n","Train Epoch: 17 [7680/12000 (64.0%)]\tLoss: 0.905143\n","Train Epoch: 17 [8320/12000 (69.3%)]\tLoss: 0.759515\n","Train Epoch: 17 [8960/12000 (74.7%)]\tLoss: 1.321881\n","Train Epoch: 17 [9600/12000 (80.0%)]\tLoss: 0.943841\n","Train Epoch: 17 [10240/12000 (85.3%)]\tLoss: 0.518288\n","Train Epoch: 17 [10880/12000 (90.7%)]\tLoss: 1.273533\n","Train Epoch: 17 [11520/12000 (96.0%)]\tLoss: 1.083256\n","\n","Test set: Average loss: 6.0886, Accuracy: 879/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 18 [0/12000 (0.0%)]\tLoss: 0.729319\n","Train Epoch: 18 [640/12000 (5.3%)]\tLoss: 0.579935\n","Train Epoch: 18 [1280/12000 (10.7%)]\tLoss: 0.560561\n","Train Epoch: 18 [1920/12000 (16.0%)]\tLoss: 0.723431\n","Train Epoch: 18 [2560/12000 (21.3%)]\tLoss: 0.746001\n","Train Epoch: 18 [3200/12000 (26.7%)]\tLoss: 0.931642\n","Train Epoch: 18 [3840/12000 (32.0%)]\tLoss: 0.955504\n","Train Epoch: 18 [4480/12000 (37.3%)]\tLoss: 0.771251\n","Train Epoch: 18 [5120/12000 (42.7%)]\tLoss: 0.807011\n","Train Epoch: 18 [5760/12000 (48.0%)]\tLoss: 0.716063\n","Train Epoch: 18 [6400/12000 (53.3%)]\tLoss: 0.806374\n","Train Epoch: 18 [7040/12000 (58.7%)]\tLoss: 0.375285\n","Train Epoch: 18 [7680/12000 (64.0%)]\tLoss: 0.810193\n","Train Epoch: 18 [8320/12000 (69.3%)]\tLoss: 0.679766\n","Train Epoch: 18 [8960/12000 (74.7%)]\tLoss: 0.621005\n","Train Epoch: 18 [9600/12000 (80.0%)]\tLoss: 0.705924\n","Train Epoch: 18 [10240/12000 (85.3%)]\tLoss: 1.380654\n","Train Epoch: 18 [10880/12000 (90.7%)]\tLoss: 1.155360\n","Train Epoch: 18 [11520/12000 (96.0%)]\tLoss: 0.563227\n","\n","Test set: Average loss: 6.1950, Accuracy: 955/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 19 [0/12000 (0.0%)]\tLoss: 0.485676\n","Train Epoch: 19 [640/12000 (5.3%)]\tLoss: 0.775060\n","Train Epoch: 19 [1280/12000 (10.7%)]\tLoss: 1.005631\n","Train Epoch: 19 [1920/12000 (16.0%)]\tLoss: 0.841509\n","Train Epoch: 19 [2560/12000 (21.3%)]\tLoss: 1.249279\n","Train Epoch: 19 [3200/12000 (26.7%)]\tLoss: 0.727383\n","Train Epoch: 19 [3840/12000 (32.0%)]\tLoss: 0.773573\n","Train Epoch: 19 [4480/12000 (37.3%)]\tLoss: 0.734558\n","Train Epoch: 19 [5120/12000 (42.7%)]\tLoss: 0.866470\n","Train Epoch: 19 [5760/12000 (48.0%)]\tLoss: 1.197066\n","Train Epoch: 19 [6400/12000 (53.3%)]\tLoss: 1.104382\n","Train Epoch: 19 [7040/12000 (58.7%)]\tLoss: 0.932969\n","Train Epoch: 19 [7680/12000 (64.0%)]\tLoss: 1.149420\n","Train Epoch: 19 [8320/12000 (69.3%)]\tLoss: 0.739466\n","Train Epoch: 19 [8960/12000 (74.7%)]\tLoss: 1.103547\n","Train Epoch: 19 [9600/12000 (80.0%)]\tLoss: 1.259186\n","Train Epoch: 19 [10240/12000 (85.3%)]\tLoss: 0.664545\n","Train Epoch: 19 [10880/12000 (90.7%)]\tLoss: 0.557507\n","Train Epoch: 19 [11520/12000 (96.0%)]\tLoss: 1.276170\n","\n","Test set: Average loss: 6.2770, Accuracy: 941/8580 (10.00%), F1: 0.08\n","\n","Train Epoch: 20 [0/12000 (0.0%)]\tLoss: 0.395363\n","Train Epoch: 20 [640/12000 (5.3%)]\tLoss: 0.630013\n","Train Epoch: 20 [1280/12000 (10.7%)]\tLoss: 0.331856\n","Train Epoch: 20 [1920/12000 (16.0%)]\tLoss: 0.614798\n","Train Epoch: 20 [2560/12000 (21.3%)]\tLoss: 0.455957\n","Train Epoch: 20 [3200/12000 (26.7%)]\tLoss: 0.236665\n","Train Epoch: 20 [3840/12000 (32.0%)]\tLoss: 0.185645\n","Train Epoch: 20 [4480/12000 (37.3%)]\tLoss: 0.483033\n","Train Epoch: 20 [5120/12000 (42.7%)]\tLoss: 0.875530\n","Train Epoch: 20 [5760/12000 (48.0%)]\tLoss: 0.228409\n","Train Epoch: 20 [6400/12000 (53.3%)]\tLoss: 0.427325\n","Train Epoch: 20 [7040/12000 (58.7%)]\tLoss: 0.447313\n","Train Epoch: 20 [7680/12000 (64.0%)]\tLoss: 0.137288\n","Train Epoch: 20 [8320/12000 (69.3%)]\tLoss: 0.048423\n","Train Epoch: 20 [8960/12000 (74.7%)]\tLoss: 0.322343\n","Train Epoch: 20 [9600/12000 (80.0%)]\tLoss: 0.275778\n","Train Epoch: 20 [10240/12000 (85.3%)]\tLoss: 0.055755\n","Train Epoch: 20 [10880/12000 (90.7%)]\tLoss: 0.442131\n","Train Epoch: 20 [11520/12000 (96.0%)]\tLoss: 0.736012\n","\n","Test set: Average loss: 5.6831, Accuracy: 1186/8580 (13.00%), F1: 0.11\n","\n","Train Epoch: 21 [0/12000 (0.0%)]\tLoss: 0.189965\n","Train Epoch: 21 [640/12000 (5.3%)]\tLoss: 0.173053\n","Train Epoch: 21 [1280/12000 (10.7%)]\tLoss: 0.257681\n","Train Epoch: 21 [1920/12000 (16.0%)]\tLoss: 0.207019\n","Train Epoch: 21 [2560/12000 (21.3%)]\tLoss: 0.194358\n","Train Epoch: 21 [3200/12000 (26.7%)]\tLoss: 0.166985\n","Train Epoch: 21 [3840/12000 (32.0%)]\tLoss: 0.103240\n","Train Epoch: 21 [4480/12000 (37.3%)]\tLoss: 0.217436\n","Train Epoch: 21 [5120/12000 (42.7%)]\tLoss: 0.117509\n","Train Epoch: 21 [5760/12000 (48.0%)]\tLoss: 0.056908\n","Train Epoch: 21 [6400/12000 (53.3%)]\tLoss: 0.377944\n","Train Epoch: 21 [7040/12000 (58.7%)]\tLoss: 0.150280\n","Train Epoch: 21 [7680/12000 (64.0%)]\tLoss: 0.225872\n","Train Epoch: 21 [8320/12000 (69.3%)]\tLoss: 0.089304\n","Train Epoch: 21 [8960/12000 (74.7%)]\tLoss: 0.182994\n","Train Epoch: 21 [9600/12000 (80.0%)]\tLoss: 0.101989\n","Train Epoch: 21 [10240/12000 (85.3%)]\tLoss: 0.271312\n","Train Epoch: 21 [10880/12000 (90.7%)]\tLoss: 0.055815\n","Train Epoch: 21 [11520/12000 (96.0%)]\tLoss: 0.062076\n","\n","Test set: Average loss: 5.7425, Accuracy: 1215/8580 (14.00%), F1: 0.08\n","\n","Train Epoch: 22 [0/12000 (0.0%)]\tLoss: 0.101528\n","Train Epoch: 22 [640/12000 (5.3%)]\tLoss: 0.162495\n","Train Epoch: 22 [1280/12000 (10.7%)]\tLoss: 0.057233\n","Train Epoch: 22 [1920/12000 (16.0%)]\tLoss: 0.031353\n","Train Epoch: 22 [2560/12000 (21.3%)]\tLoss: 0.249545\n","Train Epoch: 22 [3200/12000 (26.7%)]\tLoss: 0.086086\n","Train Epoch: 22 [3840/12000 (32.0%)]\tLoss: 0.126070\n","Train Epoch: 22 [4480/12000 (37.3%)]\tLoss: 0.066195\n","Train Epoch: 22 [5120/12000 (42.7%)]\tLoss: 0.028623\n","Train Epoch: 22 [5760/12000 (48.0%)]\tLoss: 0.219400\n","Train Epoch: 22 [6400/12000 (53.3%)]\tLoss: 0.043566\n","Train Epoch: 22 [7040/12000 (58.7%)]\tLoss: 0.042993\n","Train Epoch: 22 [7680/12000 (64.0%)]\tLoss: 0.173369\n","Train Epoch: 22 [8320/12000 (69.3%)]\tLoss: 0.014057\n","Train Epoch: 22 [8960/12000 (74.7%)]\tLoss: 0.038072\n","Train Epoch: 22 [9600/12000 (80.0%)]\tLoss: 0.081010\n","Train Epoch: 22 [10240/12000 (85.3%)]\tLoss: 0.082458\n","Train Epoch: 22 [10880/12000 (90.7%)]\tLoss: 0.123453\n","Train Epoch: 22 [11520/12000 (96.0%)]\tLoss: 0.174063\n","\n","Test set: Average loss: 5.9107, Accuracy: 1228/8580 (14.00%), F1: 0.12\n","\n","Train Epoch: 23 [0/12000 (0.0%)]\tLoss: 0.079034\n","Train Epoch: 23 [640/12000 (5.3%)]\tLoss: 0.025492\n","Train Epoch: 23 [1280/12000 (10.7%)]\tLoss: 0.027543\n","Train Epoch: 23 [1920/12000 (16.0%)]\tLoss: 0.195038\n","Train Epoch: 23 [2560/12000 (21.3%)]\tLoss: 0.041336\n","Train Epoch: 23 [3200/12000 (26.7%)]\tLoss: 0.114173\n","Train Epoch: 23 [3840/12000 (32.0%)]\tLoss: 0.074325\n","Train Epoch: 23 [4480/12000 (37.3%)]\tLoss: 0.030271\n","Train Epoch: 23 [5120/12000 (42.7%)]\tLoss: 0.086659\n","Train Epoch: 23 [5760/12000 (48.0%)]\tLoss: 0.235821\n","Train Epoch: 23 [6400/12000 (53.3%)]\tLoss: 0.085911\n","Train Epoch: 23 [7040/12000 (58.7%)]\tLoss: 0.078236\n","Train Epoch: 23 [7680/12000 (64.0%)]\tLoss: 0.084006\n","Train Epoch: 23 [8320/12000 (69.3%)]\tLoss: 0.014996\n","Train Epoch: 23 [8960/12000 (74.7%)]\tLoss: 0.030075\n","Train Epoch: 23 [9600/12000 (80.0%)]\tLoss: 0.184715\n","Train Epoch: 23 [10240/12000 (85.3%)]\tLoss: 0.129751\n","Train Epoch: 23 [10880/12000 (90.7%)]\tLoss: 0.091097\n","Train Epoch: 23 [11520/12000 (96.0%)]\tLoss: 0.328897\n","\n","Test set: Average loss: 5.9692, Accuracy: 1252/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 24 [0/12000 (0.0%)]\tLoss: 0.056401\n","Train Epoch: 24 [640/12000 (5.3%)]\tLoss: 0.072724\n","Train Epoch: 24 [1280/12000 (10.7%)]\tLoss: 0.037189\n","Train Epoch: 24 [1920/12000 (16.0%)]\tLoss: 0.187138\n","Train Epoch: 24 [2560/12000 (21.3%)]\tLoss: 0.015004\n","Train Epoch: 24 [3200/12000 (26.7%)]\tLoss: 0.093062\n","Train Epoch: 24 [3840/12000 (32.0%)]\tLoss: 0.024314\n","Train Epoch: 24 [4480/12000 (37.3%)]\tLoss: 0.202777\n","Train Epoch: 24 [5120/12000 (42.7%)]\tLoss: 0.031785\n","Train Epoch: 24 [5760/12000 (48.0%)]\tLoss: 0.015978\n","Train Epoch: 24 [6400/12000 (53.3%)]\tLoss: 0.104011\n","Train Epoch: 24 [7040/12000 (58.7%)]\tLoss: 0.171273\n","Train Epoch: 24 [7680/12000 (64.0%)]\tLoss: 0.057260\n","Train Epoch: 24 [8320/12000 (69.3%)]\tLoss: 0.015905\n","Train Epoch: 24 [8960/12000 (74.7%)]\tLoss: 0.039226\n","Train Epoch: 24 [9600/12000 (80.0%)]\tLoss: 0.079293\n","Train Epoch: 24 [10240/12000 (85.3%)]\tLoss: 0.046642\n","Train Epoch: 24 [10880/12000 (90.7%)]\tLoss: 0.023842\n","Train Epoch: 24 [11520/12000 (96.0%)]\tLoss: 0.055470\n","\n","Test set: Average loss: 5.9969, Accuracy: 1270/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 25 [0/12000 (0.0%)]\tLoss: 0.244644\n","Train Epoch: 25 [640/12000 (5.3%)]\tLoss: 0.011682\n","Train Epoch: 25 [1280/12000 (10.7%)]\tLoss: 0.097347\n","Train Epoch: 25 [1920/12000 (16.0%)]\tLoss: 0.040762\n","Train Epoch: 25 [2560/12000 (21.3%)]\tLoss: 0.031303\n","Train Epoch: 25 [3200/12000 (26.7%)]\tLoss: 0.029800\n","Train Epoch: 25 [3840/12000 (32.0%)]\tLoss: 0.082736\n","Train Epoch: 25 [4480/12000 (37.3%)]\tLoss: 0.017432\n","Train Epoch: 25 [5120/12000 (42.7%)]\tLoss: 0.389539\n","Train Epoch: 25 [5760/12000 (48.0%)]\tLoss: 0.043033\n","Train Epoch: 25 [6400/12000 (53.3%)]\tLoss: 0.043208\n","Train Epoch: 25 [7040/12000 (58.7%)]\tLoss: 0.126811\n","Train Epoch: 25 [7680/12000 (64.0%)]\tLoss: 0.006443\n","Train Epoch: 25 [8320/12000 (69.3%)]\tLoss: 0.011302\n","Train Epoch: 25 [8960/12000 (74.7%)]\tLoss: 0.044986\n","Train Epoch: 25 [9600/12000 (80.0%)]\tLoss: 0.011723\n","Train Epoch: 25 [10240/12000 (85.3%)]\tLoss: 0.127320\n","Train Epoch: 25 [10880/12000 (90.7%)]\tLoss: 0.056159\n","Train Epoch: 25 [11520/12000 (96.0%)]\tLoss: 0.032344\n","\n","Test set: Average loss: 5.9889, Accuracy: 1269/8580 (14.00%), F1: 0.10\n","\n","Train Epoch: 26 [0/12000 (0.0%)]\tLoss: 0.052084\n","Train Epoch: 26 [640/12000 (5.3%)]\tLoss: 0.006778\n","Train Epoch: 26 [1280/12000 (10.7%)]\tLoss: 0.193802\n","Train Epoch: 26 [1920/12000 (16.0%)]\tLoss: 0.019679\n","Train Epoch: 26 [2560/12000 (21.3%)]\tLoss: 0.022985\n","Train Epoch: 26 [3200/12000 (26.7%)]\tLoss: 0.073447\n","Train Epoch: 26 [3840/12000 (32.0%)]\tLoss: 0.066523\n","Train Epoch: 26 [4480/12000 (37.3%)]\tLoss: 0.125388\n","Train Epoch: 26 [5120/12000 (42.7%)]\tLoss: 0.018514\n","Train Epoch: 26 [5760/12000 (48.0%)]\tLoss: 0.008533\n","Train Epoch: 26 [6400/12000 (53.3%)]\tLoss: 0.030921\n","Train Epoch: 26 [7040/12000 (58.7%)]\tLoss: 0.037171\n","Train Epoch: 26 [7680/12000 (64.0%)]\tLoss: 0.042385\n","Train Epoch: 26 [8320/12000 (69.3%)]\tLoss: 0.162056\n","Train Epoch: 26 [8960/12000 (74.7%)]\tLoss: 0.029704\n","Train Epoch: 26 [9600/12000 (80.0%)]\tLoss: 0.024951\n","Train Epoch: 26 [10240/12000 (85.3%)]\tLoss: 0.115410\n","Train Epoch: 26 [10880/12000 (90.7%)]\tLoss: 0.054730\n","Train Epoch: 26 [11520/12000 (96.0%)]\tLoss: 0.007332\n","\n","Test set: Average loss: 6.0790, Accuracy: 1274/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 27 [0/12000 (0.0%)]\tLoss: 0.024073\n","Train Epoch: 27 [640/12000 (5.3%)]\tLoss: 0.024557\n","Train Epoch: 27 [1280/12000 (10.7%)]\tLoss: 0.046715\n","Train Epoch: 27 [1920/12000 (16.0%)]\tLoss: 0.015374\n","Train Epoch: 27 [2560/12000 (21.3%)]\tLoss: 0.018083\n","Train Epoch: 27 [3200/12000 (26.7%)]\tLoss: 0.018600\n","Train Epoch: 27 [3840/12000 (32.0%)]\tLoss: 0.003655\n","Train Epoch: 27 [4480/12000 (37.3%)]\tLoss: 0.016667\n","Train Epoch: 27 [5120/12000 (42.7%)]\tLoss: 0.040601\n","Train Epoch: 27 [5760/12000 (48.0%)]\tLoss: 0.019985\n","Train Epoch: 27 [6400/12000 (53.3%)]\tLoss: 0.051322\n","Train Epoch: 27 [7040/12000 (58.7%)]\tLoss: 0.016579\n","Train Epoch: 27 [7680/12000 (64.0%)]\tLoss: 0.107655\n","Train Epoch: 27 [8320/12000 (69.3%)]\tLoss: 0.039721\n","Train Epoch: 27 [8960/12000 (74.7%)]\tLoss: 0.024318\n","Train Epoch: 27 [9600/12000 (80.0%)]\tLoss: 0.040465\n","Train Epoch: 27 [10240/12000 (85.3%)]\tLoss: 0.011091\n","Train Epoch: 27 [10880/12000 (90.7%)]\tLoss: 0.032819\n","Train Epoch: 27 [11520/12000 (96.0%)]\tLoss: 0.246273\n","\n","Test set: Average loss: 6.1126, Accuracy: 1232/8580 (14.00%), F1: 0.10\n","\n","Train Epoch: 28 [0/12000 (0.0%)]\tLoss: 0.093359\n","Train Epoch: 28 [640/12000 (5.3%)]\tLoss: 0.027133\n","Train Epoch: 28 [1280/12000 (10.7%)]\tLoss: 0.004330\n","Train Epoch: 28 [1920/12000 (16.0%)]\tLoss: 0.054429\n","Train Epoch: 28 [2560/12000 (21.3%)]\tLoss: 0.001849\n","Train Epoch: 28 [3200/12000 (26.7%)]\tLoss: 0.052557\n","Train Epoch: 28 [3840/12000 (32.0%)]\tLoss: 0.005376\n","Train Epoch: 28 [4480/12000 (37.3%)]\tLoss: 0.021782\n","Train Epoch: 28 [5120/12000 (42.7%)]\tLoss: 0.036647\n","Train Epoch: 28 [5760/12000 (48.0%)]\tLoss: 0.073358\n","Train Epoch: 28 [6400/12000 (53.3%)]\tLoss: 0.016662\n","Train Epoch: 28 [7040/12000 (58.7%)]\tLoss: 0.047063\n","Train Epoch: 28 [7680/12000 (64.0%)]\tLoss: 0.109641\n","Train Epoch: 28 [8320/12000 (69.3%)]\tLoss: 0.008532\n","Train Epoch: 28 [8960/12000 (74.7%)]\tLoss: 0.067026\n","Train Epoch: 28 [9600/12000 (80.0%)]\tLoss: 0.027243\n","Train Epoch: 28 [10240/12000 (85.3%)]\tLoss: 0.016324\n","Train Epoch: 28 [10880/12000 (90.7%)]\tLoss: 0.008503\n","Train Epoch: 28 [11520/12000 (96.0%)]\tLoss: 0.022583\n","\n","Test set: Average loss: 6.0881, Accuracy: 1299/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 29 [0/12000 (0.0%)]\tLoss: 0.018365\n","Train Epoch: 29 [640/12000 (5.3%)]\tLoss: 0.004434\n","Train Epoch: 29 [1280/12000 (10.7%)]\tLoss: 0.003503\n","Train Epoch: 29 [1920/12000 (16.0%)]\tLoss: 0.018447\n","Train Epoch: 29 [2560/12000 (21.3%)]\tLoss: 0.010903\n","Train Epoch: 29 [3200/12000 (26.7%)]\tLoss: 0.047180\n","Train Epoch: 29 [3840/12000 (32.0%)]\tLoss: 0.047653\n","Train Epoch: 29 [4480/12000 (37.3%)]\tLoss: 0.011613\n","Train Epoch: 29 [5120/12000 (42.7%)]\tLoss: 0.041309\n","Train Epoch: 29 [5760/12000 (48.0%)]\tLoss: 0.017109\n","Train Epoch: 29 [6400/12000 (53.3%)]\tLoss: 0.061199\n","Train Epoch: 29 [7040/12000 (58.7%)]\tLoss: 0.017028\n","Train Epoch: 29 [7680/12000 (64.0%)]\tLoss: 0.072458\n","Train Epoch: 29 [8320/12000 (69.3%)]\tLoss: 0.010738\n","Train Epoch: 29 [8960/12000 (74.7%)]\tLoss: 0.080282\n","Train Epoch: 29 [9600/12000 (80.0%)]\tLoss: 0.005149\n","Train Epoch: 29 [10240/12000 (85.3%)]\tLoss: 0.003030\n","Train Epoch: 29 [10880/12000 (90.7%)]\tLoss: 0.070989\n","Train Epoch: 29 [11520/12000 (96.0%)]\tLoss: 0.042879\n","\n","Test set: Average loss: 6.1687, Accuracy: 1270/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 30 [0/12000 (0.0%)]\tLoss: 0.059037\n","Train Epoch: 30 [640/12000 (5.3%)]\tLoss: 0.092227\n","Train Epoch: 30 [1280/12000 (10.7%)]\tLoss: 0.018134\n","Train Epoch: 30 [1920/12000 (16.0%)]\tLoss: 0.014270\n","Train Epoch: 30 [2560/12000 (21.3%)]\tLoss: 0.087921\n","Train Epoch: 30 [3200/12000 (26.7%)]\tLoss: 0.036866\n","Train Epoch: 30 [3840/12000 (32.0%)]\tLoss: 0.068709\n","Train Epoch: 30 [4480/12000 (37.3%)]\tLoss: 0.102358\n","Train Epoch: 30 [5120/12000 (42.7%)]\tLoss: 0.011030\n","Train Epoch: 30 [5760/12000 (48.0%)]\tLoss: 0.113231\n","Train Epoch: 30 [6400/12000 (53.3%)]\tLoss: 0.011506\n","Train Epoch: 30 [7040/12000 (58.7%)]\tLoss: 0.060214\n","Train Epoch: 30 [7680/12000 (64.0%)]\tLoss: 0.020987\n","Train Epoch: 30 [8320/12000 (69.3%)]\tLoss: 0.022146\n","Train Epoch: 30 [8960/12000 (74.7%)]\tLoss: 0.007343\n","Train Epoch: 30 [9600/12000 (80.0%)]\tLoss: 0.067344\n","Train Epoch: 30 [10240/12000 (85.3%)]\tLoss: 0.010579\n","Train Epoch: 30 [10880/12000 (90.7%)]\tLoss: 0.005825\n","Train Epoch: 30 [11520/12000 (96.0%)]\tLoss: 0.010889\n","\n","Test set: Average loss: 6.1272, Accuracy: 1283/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 31 [0/12000 (0.0%)]\tLoss: 0.025533\n","Train Epoch: 31 [640/12000 (5.3%)]\tLoss: 0.035407\n","Train Epoch: 31 [1280/12000 (10.7%)]\tLoss: 0.083020\n","Train Epoch: 31 [1920/12000 (16.0%)]\tLoss: 0.015601\n","Train Epoch: 31 [2560/12000 (21.3%)]\tLoss: 0.020935\n","Train Epoch: 31 [3200/12000 (26.7%)]\tLoss: 0.013830\n","Train Epoch: 31 [3840/12000 (32.0%)]\tLoss: 0.004820\n","Train Epoch: 31 [4480/12000 (37.3%)]\tLoss: 0.006423\n","Train Epoch: 31 [5120/12000 (42.7%)]\tLoss: 0.011365\n","Train Epoch: 31 [5760/12000 (48.0%)]\tLoss: 0.060084\n","Train Epoch: 31 [6400/12000 (53.3%)]\tLoss: 0.026947\n","Train Epoch: 31 [7040/12000 (58.7%)]\tLoss: 0.009637\n","Train Epoch: 31 [7680/12000 (64.0%)]\tLoss: 0.029639\n","Train Epoch: 31 [8320/12000 (69.3%)]\tLoss: 0.253167\n","Train Epoch: 31 [8960/12000 (74.7%)]\tLoss: 0.011828\n","Train Epoch: 31 [9600/12000 (80.0%)]\tLoss: 0.006271\n","Train Epoch: 31 [10240/12000 (85.3%)]\tLoss: 0.028415\n","Train Epoch: 31 [10880/12000 (90.7%)]\tLoss: 0.054729\n","Train Epoch: 31 [11520/12000 (96.0%)]\tLoss: 0.045784\n","\n","Test set: Average loss: 6.0872, Accuracy: 1269/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 32 [0/12000 (0.0%)]\tLoss: 0.021662\n","Train Epoch: 32 [640/12000 (5.3%)]\tLoss: 0.019702\n","Train Epoch: 32 [1280/12000 (10.7%)]\tLoss: 0.038048\n","Train Epoch: 32 [1920/12000 (16.0%)]\tLoss: 0.001727\n","Train Epoch: 32 [2560/12000 (21.3%)]\tLoss: 0.007558\n","Train Epoch: 32 [3200/12000 (26.7%)]\tLoss: 0.011208\n","Train Epoch: 32 [3840/12000 (32.0%)]\tLoss: 0.046918\n","Train Epoch: 32 [4480/12000 (37.3%)]\tLoss: 0.013041\n","Train Epoch: 32 [5120/12000 (42.7%)]\tLoss: 0.005130\n","Train Epoch: 32 [5760/12000 (48.0%)]\tLoss: 0.008232\n","Train Epoch: 32 [6400/12000 (53.3%)]\tLoss: 0.012971\n","Train Epoch: 32 [7040/12000 (58.7%)]\tLoss: 0.050218\n","Train Epoch: 32 [7680/12000 (64.0%)]\tLoss: 0.016367\n","Train Epoch: 32 [8320/12000 (69.3%)]\tLoss: 0.031436\n","Train Epoch: 32 [8960/12000 (74.7%)]\tLoss: 0.017761\n","Train Epoch: 32 [9600/12000 (80.0%)]\tLoss: 0.011829\n","Train Epoch: 32 [10240/12000 (85.3%)]\tLoss: 0.002660\n","Train Epoch: 32 [10880/12000 (90.7%)]\tLoss: 0.014933\n","Train Epoch: 32 [11520/12000 (96.0%)]\tLoss: 0.019859\n","\n","Test set: Average loss: 6.0960, Accuracy: 1291/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 33 [0/12000 (0.0%)]\tLoss: 0.011074\n","Train Epoch: 33 [640/12000 (5.3%)]\tLoss: 0.003364\n","Train Epoch: 33 [1280/12000 (10.7%)]\tLoss: 0.004035\n","Train Epoch: 33 [1920/12000 (16.0%)]\tLoss: 0.055237\n","Train Epoch: 33 [2560/12000 (21.3%)]\tLoss: 0.011582\n","Train Epoch: 33 [3200/12000 (26.7%)]\tLoss: 0.007726\n","Train Epoch: 33 [3840/12000 (32.0%)]\tLoss: 0.013596\n","Train Epoch: 33 [4480/12000 (37.3%)]\tLoss: 0.065850\n","Train Epoch: 33 [5120/12000 (42.7%)]\tLoss: 0.051615\n","Train Epoch: 33 [5760/12000 (48.0%)]\tLoss: 0.010589\n","Train Epoch: 33 [6400/12000 (53.3%)]\tLoss: 0.029296\n","Train Epoch: 33 [7040/12000 (58.7%)]\tLoss: 0.026366\n","Train Epoch: 33 [7680/12000 (64.0%)]\tLoss: 0.024554\n","Train Epoch: 33 [8320/12000 (69.3%)]\tLoss: 0.049320\n","Train Epoch: 33 [8960/12000 (74.7%)]\tLoss: 0.005793\n","Train Epoch: 33 [9600/12000 (80.0%)]\tLoss: 0.002466\n","Train Epoch: 33 [10240/12000 (85.3%)]\tLoss: 0.016075\n","Train Epoch: 33 [10880/12000 (90.7%)]\tLoss: 0.025559\n","Train Epoch: 33 [11520/12000 (96.0%)]\tLoss: 0.005808\n","\n","Test set: Average loss: 6.0643, Accuracy: 1296/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 34 [0/12000 (0.0%)]\tLoss: 0.031357\n","Train Epoch: 34 [640/12000 (5.3%)]\tLoss: 0.009162\n","Train Epoch: 34 [1280/12000 (10.7%)]\tLoss: 0.074077\n","Train Epoch: 34 [1920/12000 (16.0%)]\tLoss: 0.012373\n","Train Epoch: 34 [2560/12000 (21.3%)]\tLoss: 0.005840\n","Train Epoch: 34 [3200/12000 (26.7%)]\tLoss: 0.002965\n","Train Epoch: 34 [3840/12000 (32.0%)]\tLoss: 0.041135\n","Train Epoch: 34 [4480/12000 (37.3%)]\tLoss: 0.027659\n","Train Epoch: 34 [5120/12000 (42.7%)]\tLoss: 0.012407\n","Train Epoch: 34 [5760/12000 (48.0%)]\tLoss: 0.004069\n","Train Epoch: 34 [6400/12000 (53.3%)]\tLoss: 0.015491\n","Train Epoch: 34 [7040/12000 (58.7%)]\tLoss: 0.028498\n","Train Epoch: 34 [7680/12000 (64.0%)]\tLoss: 0.007470\n","Train Epoch: 34 [8320/12000 (69.3%)]\tLoss: 0.003329\n","Train Epoch: 34 [8960/12000 (74.7%)]\tLoss: 0.003878\n","Train Epoch: 34 [9600/12000 (80.0%)]\tLoss: 0.040701\n","Train Epoch: 34 [10240/12000 (85.3%)]\tLoss: 0.044994\n","Train Epoch: 34 [10880/12000 (90.7%)]\tLoss: 0.013433\n","Train Epoch: 34 [11520/12000 (96.0%)]\tLoss: 0.014807\n","\n","Test set: Average loss: 6.0907, Accuracy: 1288/8580 (15.00%), F1: 0.09\n","\n","Train Epoch: 35 [0/12000 (0.0%)]\tLoss: 0.010033\n","Train Epoch: 35 [640/12000 (5.3%)]\tLoss: 0.007347\n","Train Epoch: 35 [1280/12000 (10.7%)]\tLoss: 0.007885\n","Train Epoch: 35 [1920/12000 (16.0%)]\tLoss: 0.055499\n","Train Epoch: 35 [2560/12000 (21.3%)]\tLoss: 0.019941\n","Train Epoch: 35 [3200/12000 (26.7%)]\tLoss: 0.015043\n","Train Epoch: 35 [3840/12000 (32.0%)]\tLoss: 0.001948\n","Train Epoch: 35 [4480/12000 (37.3%)]\tLoss: 0.043497\n","Train Epoch: 35 [5120/12000 (42.7%)]\tLoss: 0.066057\n","Train Epoch: 35 [5760/12000 (48.0%)]\tLoss: 0.006549\n","Train Epoch: 35 [6400/12000 (53.3%)]\tLoss: 0.019272\n","Train Epoch: 35 [7040/12000 (58.7%)]\tLoss: 0.009298\n","Train Epoch: 35 [7680/12000 (64.0%)]\tLoss: 0.012274\n","Train Epoch: 35 [8320/12000 (69.3%)]\tLoss: 0.019099\n","Train Epoch: 35 [8960/12000 (74.7%)]\tLoss: 0.002387\n","Train Epoch: 35 [9600/12000 (80.0%)]\tLoss: 0.012651\n","Train Epoch: 35 [10240/12000 (85.3%)]\tLoss: 0.021306\n","Train Epoch: 35 [10880/12000 (90.7%)]\tLoss: 0.010559\n","Train Epoch: 35 [11520/12000 (96.0%)]\tLoss: 0.003705\n","\n","Test set: Average loss: 6.0865, Accuracy: 1287/8580 (15.00%), F1: 0.11\n","\n","Train Epoch: 36 [0/12000 (0.0%)]\tLoss: 0.013442\n","Train Epoch: 36 [640/12000 (5.3%)]\tLoss: 0.123169\n","Train Epoch: 36 [1280/12000 (10.7%)]\tLoss: 0.031568\n","Train Epoch: 36 [1920/12000 (16.0%)]\tLoss: 0.125733\n","Train Epoch: 36 [2560/12000 (21.3%)]\tLoss: 0.002916\n","Train Epoch: 36 [3200/12000 (26.7%)]\tLoss: 0.053350\n","Train Epoch: 36 [3840/12000 (32.0%)]\tLoss: 0.009854\n","Train Epoch: 36 [4480/12000 (37.3%)]\tLoss: 0.018686\n","Train Epoch: 36 [5120/12000 (42.7%)]\tLoss: 0.003936\n","Train Epoch: 36 [5760/12000 (48.0%)]\tLoss: 0.025654\n","Train Epoch: 36 [6400/12000 (53.3%)]\tLoss: 0.062181\n","Train Epoch: 36 [7040/12000 (58.7%)]\tLoss: 0.035204\n","Train Epoch: 36 [7680/12000 (64.0%)]\tLoss: 0.008130\n","Train Epoch: 36 [8320/12000 (69.3%)]\tLoss: 0.023770\n","Train Epoch: 36 [8960/12000 (74.7%)]\tLoss: 0.011083\n","Train Epoch: 36 [9600/12000 (80.0%)]\tLoss: 0.009290\n","Train Epoch: 36 [10240/12000 (85.3%)]\tLoss: 0.015057\n","Train Epoch: 36 [10880/12000 (90.7%)]\tLoss: 0.077152\n","Train Epoch: 36 [11520/12000 (96.0%)]\tLoss: 0.022528\n","\n","Test set: Average loss: 6.1415, Accuracy: 1273/8580 (14.00%), F1: 0.13\n","\n","Train Epoch: 37 [0/12000 (0.0%)]\tLoss: 0.091976\n","Train Epoch: 37 [640/12000 (5.3%)]\tLoss: 0.001289\n","Train Epoch: 37 [1280/12000 (10.7%)]\tLoss: 0.052978\n","Train Epoch: 37 [1920/12000 (16.0%)]\tLoss: 0.023585\n","Train Epoch: 37 [2560/12000 (21.3%)]\tLoss: 0.010682\n","Train Epoch: 37 [3200/12000 (26.7%)]\tLoss: 0.082123\n","Train Epoch: 37 [3840/12000 (32.0%)]\tLoss: 0.037041\n","Train Epoch: 37 [4480/12000 (37.3%)]\tLoss: 0.015341\n","Train Epoch: 37 [5120/12000 (42.7%)]\tLoss: 0.021090\n","Train Epoch: 37 [5760/12000 (48.0%)]\tLoss: 0.020887\n","Train Epoch: 37 [6400/12000 (53.3%)]\tLoss: 0.061316\n","Train Epoch: 37 [7040/12000 (58.7%)]\tLoss: 0.035647\n","Train Epoch: 37 [7680/12000 (64.0%)]\tLoss: 0.048935\n","Train Epoch: 37 [8320/12000 (69.3%)]\tLoss: 0.004647\n","Train Epoch: 37 [8960/12000 (74.7%)]\tLoss: 0.030268\n","Train Epoch: 37 [9600/12000 (80.0%)]\tLoss: 0.153772\n","Train Epoch: 37 [10240/12000 (85.3%)]\tLoss: 0.005507\n","Train Epoch: 37 [10880/12000 (90.7%)]\tLoss: 0.029295\n","Train Epoch: 37 [11520/12000 (96.0%)]\tLoss: 0.005327\n","\n","Test set: Average loss: 6.1561, Accuracy: 1289/8580 (15.00%), F1: 0.12\n","\n","Train Epoch: 38 [0/12000 (0.0%)]\tLoss: 0.054244\n","Train Epoch: 38 [640/12000 (5.3%)]\tLoss: 0.016437\n","Train Epoch: 38 [1280/12000 (10.7%)]\tLoss: 0.042604\n","Train Epoch: 38 [1920/12000 (16.0%)]\tLoss: 0.031204\n","Train Epoch: 38 [2560/12000 (21.3%)]\tLoss: 0.105845\n","Train Epoch: 38 [3200/12000 (26.7%)]\tLoss: 0.005233\n","Train Epoch: 38 [3840/12000 (32.0%)]\tLoss: 0.007887\n","Train Epoch: 38 [4480/12000 (37.3%)]\tLoss: 0.103805\n","Train Epoch: 38 [5120/12000 (42.7%)]\tLoss: 0.006037\n","Train Epoch: 38 [5760/12000 (48.0%)]\tLoss: 0.041775\n","Train Epoch: 38 [6400/12000 (53.3%)]\tLoss: 0.001655\n","Train Epoch: 38 [7040/12000 (58.7%)]\tLoss: 0.035483\n","Train Epoch: 38 [7680/12000 (64.0%)]\tLoss: 0.070671\n","Train Epoch: 38 [8320/12000 (69.3%)]\tLoss: 0.006790\n","Train Epoch: 38 [8960/12000 (74.7%)]\tLoss: 0.060947\n","Train Epoch: 38 [9600/12000 (80.0%)]\tLoss: 0.060743\n","Train Epoch: 38 [10240/12000 (85.3%)]\tLoss: 0.009820\n","Train Epoch: 38 [10880/12000 (90.7%)]\tLoss: 0.002996\n","Train Epoch: 38 [11520/12000 (96.0%)]\tLoss: 0.030215\n","\n","Test set: Average loss: 6.1736, Accuracy: 1291/8580 (15.00%), F1: 0.15\n","\n","Train Epoch: 39 [0/12000 (0.0%)]\tLoss: 0.036864\n","Train Epoch: 39 [640/12000 (5.3%)]\tLoss: 0.010654\n","Train Epoch: 39 [1280/12000 (10.7%)]\tLoss: 0.071740\n","Train Epoch: 39 [1920/12000 (16.0%)]\tLoss: 0.006910\n","Train Epoch: 39 [2560/12000 (21.3%)]\tLoss: 0.026170\n","Train Epoch: 39 [3200/12000 (26.7%)]\tLoss: 0.005587\n","Train Epoch: 39 [3840/12000 (32.0%)]\tLoss: 0.011077\n","Train Epoch: 39 [4480/12000 (37.3%)]\tLoss: 0.010635\n","Train Epoch: 39 [5120/12000 (42.7%)]\tLoss: 0.108474\n","Train Epoch: 39 [5760/12000 (48.0%)]\tLoss: 0.005822\n","Train Epoch: 39 [6400/12000 (53.3%)]\tLoss: 0.068571\n","Train Epoch: 39 [7040/12000 (58.7%)]\tLoss: 0.020428\n","Train Epoch: 39 [7680/12000 (64.0%)]\tLoss: 0.033938\n","Train Epoch: 39 [8320/12000 (69.3%)]\tLoss: 0.015808\n","Train Epoch: 39 [8960/12000 (74.7%)]\tLoss: 0.026937\n","Train Epoch: 39 [9600/12000 (80.0%)]\tLoss: 0.009020\n","Train Epoch: 39 [10240/12000 (85.3%)]\tLoss: 0.008912\n","Train Epoch: 39 [10880/12000 (90.7%)]\tLoss: 0.010078\n","Train Epoch: 39 [11520/12000 (96.0%)]\tLoss: 0.021527\n","\n","Test set: Average loss: 6.0537, Accuracy: 1260/8580 (14.00%), F1: 0.11\n","\n","[INFO] Method:  scratchE\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/scratchE/modelA200_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new trasfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.838215\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.523954\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.988637\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 5.079625\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.728930\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.705261\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.357798\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.708573\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.340662\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.482130\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.445547\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 4.492495\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.328741\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 4.065875\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.123610\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.324297\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.222260\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.208129\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 3.890881\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","\n","Test set: Average loss: 4.1672, Accuracy: 646/8580 (7.00%), F1: 0.05\n","\n","Train Epoch: 1 [0/12000 (0.0%)]\tLoss: 4.082260\n","Train Epoch: 1 [640/12000 (5.3%)]\tLoss: 3.934776\n","Train Epoch: 1 [1280/12000 (10.7%)]\tLoss: 3.752941\n","Train Epoch: 1 [1920/12000 (16.0%)]\tLoss: 3.804335\n","Train Epoch: 1 [2560/12000 (21.3%)]\tLoss: 4.077505\n","Train Epoch: 1 [3200/12000 (26.7%)]\tLoss: 4.127241\n","Train Epoch: 1 [3840/12000 (32.0%)]\tLoss: 3.868355\n","Train Epoch: 1 [4480/12000 (37.3%)]\tLoss: 4.334706\n","Train Epoch: 1 [5120/12000 (42.7%)]\tLoss: 4.050394\n","Train Epoch: 1 [5760/12000 (48.0%)]\tLoss: 3.928042\n","Train Epoch: 1 [6400/12000 (53.3%)]\tLoss: 4.147878\n","Train Epoch: 1 [7040/12000 (58.7%)]\tLoss: 4.145665\n","Train Epoch: 1 [7680/12000 (64.0%)]\tLoss: 4.015904\n","Train Epoch: 1 [8320/12000 (69.3%)]\tLoss: 3.937772\n","Train Epoch: 1 [8960/12000 (74.7%)]\tLoss: 4.040449\n","Train Epoch: 1 [9600/12000 (80.0%)]\tLoss: 3.841176\n","Train Epoch: 1 [10240/12000 (85.3%)]\tLoss: 3.983212\n","Train Epoch: 1 [10880/12000 (90.7%)]\tLoss: 4.123879\n","Train Epoch: 1 [11520/12000 (96.0%)]\tLoss: 4.047446\n","\n","Test set: Average loss: 3.9977, Accuracy: 771/8580 (8.00%), F1: 0.08\n","\n","Train Epoch: 2 [0/12000 (0.0%)]\tLoss: 3.861224\n","Train Epoch: 2 [640/12000 (5.3%)]\tLoss: 3.508662\n","Train Epoch: 2 [1280/12000 (10.7%)]\tLoss: 3.248765\n","Train Epoch: 2 [1920/12000 (16.0%)]\tLoss: 4.092702\n","Train Epoch: 2 [2560/12000 (21.3%)]\tLoss: 3.603029\n","Train Epoch: 2 [3200/12000 (26.7%)]\tLoss: 3.702490\n","Train Epoch: 2 [3840/12000 (32.0%)]\tLoss: 3.825881\n","Train Epoch: 2 [4480/12000 (37.3%)]\tLoss: 3.958091\n","Train Epoch: 2 [5120/12000 (42.7%)]\tLoss: 3.559798\n","Train Epoch: 2 [5760/12000 (48.0%)]\tLoss: 3.700421\n","Train Epoch: 2 [6400/12000 (53.3%)]\tLoss: 3.898786\n","Train Epoch: 2 [7040/12000 (58.7%)]\tLoss: 3.872562\n","Train Epoch: 2 [7680/12000 (64.0%)]\tLoss: 3.921809\n","Train Epoch: 2 [8320/12000 (69.3%)]\tLoss: 3.428622\n","Train Epoch: 2 [8960/12000 (74.7%)]\tLoss: 3.569828\n","Train Epoch: 2 [9600/12000 (80.0%)]\tLoss: 3.641808\n","Train Epoch: 2 [10240/12000 (85.3%)]\tLoss: 3.662676\n","Train Epoch: 2 [10880/12000 (90.7%)]\tLoss: 3.734256\n","Train Epoch: 2 [11520/12000 (96.0%)]\tLoss: 3.842074\n","\n","Test set: Average loss: 3.8768, Accuracy: 898/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 3 [0/12000 (0.0%)]\tLoss: 3.091735\n","Train Epoch: 3 [640/12000 (5.3%)]\tLoss: 3.255462\n","Train Epoch: 3 [1280/12000 (10.7%)]\tLoss: 3.134516\n","Train Epoch: 3 [1920/12000 (16.0%)]\tLoss: 3.049857\n","Train Epoch: 3 [2560/12000 (21.3%)]\tLoss: 3.616545\n","Train Epoch: 3 [3200/12000 (26.7%)]\tLoss: 3.345688\n","Train Epoch: 3 [3840/12000 (32.0%)]\tLoss: 2.904064\n","Train Epoch: 3 [4480/12000 (37.3%)]\tLoss: 3.708904\n","Train Epoch: 3 [5120/12000 (42.7%)]\tLoss: 3.676569\n","Train Epoch: 3 [5760/12000 (48.0%)]\tLoss: 2.955998\n","Train Epoch: 3 [6400/12000 (53.3%)]\tLoss: 3.663093\n","Train Epoch: 3 [7040/12000 (58.7%)]\tLoss: 3.326687\n","Train Epoch: 3 [7680/12000 (64.0%)]\tLoss: 3.278756\n","Train Epoch: 3 [8320/12000 (69.3%)]\tLoss: 3.345348\n","Train Epoch: 3 [8960/12000 (74.7%)]\tLoss: 3.713297\n","Train Epoch: 3 [9600/12000 (80.0%)]\tLoss: 3.515210\n","Train Epoch: 3 [10240/12000 (85.3%)]\tLoss: 3.518625\n","Train Epoch: 3 [10880/12000 (90.7%)]\tLoss: 3.419125\n","Train Epoch: 3 [11520/12000 (96.0%)]\tLoss: 3.407539\n","\n","Test set: Average loss: 3.9391, Accuracy: 959/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 4 [0/12000 (0.0%)]\tLoss: 2.704507\n","Train Epoch: 4 [640/12000 (5.3%)]\tLoss: 3.079609\n","Train Epoch: 4 [1280/12000 (10.7%)]\tLoss: 3.299051\n","Train Epoch: 4 [1920/12000 (16.0%)]\tLoss: 2.538142\n","Train Epoch: 4 [2560/12000 (21.3%)]\tLoss: 3.144367\n","Train Epoch: 4 [3200/12000 (26.7%)]\tLoss: 2.957622\n","Train Epoch: 4 [3840/12000 (32.0%)]\tLoss: 3.354344\n","Train Epoch: 4 [4480/12000 (37.3%)]\tLoss: 2.806453\n","Train Epoch: 4 [5120/12000 (42.7%)]\tLoss: 3.338472\n","Train Epoch: 4 [5760/12000 (48.0%)]\tLoss: 3.270961\n","Train Epoch: 4 [6400/12000 (53.3%)]\tLoss: 3.607124\n","Train Epoch: 4 [7040/12000 (58.7%)]\tLoss: 2.775383\n","Train Epoch: 4 [7680/12000 (64.0%)]\tLoss: 2.911388\n","Train Epoch: 4 [8320/12000 (69.3%)]\tLoss: 2.943121\n","Train Epoch: 4 [8960/12000 (74.7%)]\tLoss: 3.339554\n","Train Epoch: 4 [9600/12000 (80.0%)]\tLoss: 3.336347\n","Train Epoch: 4 [10240/12000 (85.3%)]\tLoss: 2.911235\n","Train Epoch: 4 [10880/12000 (90.7%)]\tLoss: 3.289722\n","Train Epoch: 4 [11520/12000 (96.0%)]\tLoss: 3.237891\n","\n","Test set: Average loss: 4.0073, Accuracy: 953/8580 (11.00%), F1: 0.05\n","\n","Train Epoch: 5 [0/12000 (0.0%)]\tLoss: 2.331459\n","Train Epoch: 5 [640/12000 (5.3%)]\tLoss: 2.341927\n","Train Epoch: 5 [1280/12000 (10.7%)]\tLoss: 2.950955\n","Train Epoch: 5 [1920/12000 (16.0%)]\tLoss: 2.651316\n","Train Epoch: 5 [2560/12000 (21.3%)]\tLoss: 2.562518\n","Train Epoch: 5 [3200/12000 (26.7%)]\tLoss: 3.010924\n","Train Epoch: 5 [3840/12000 (32.0%)]\tLoss: 2.605490\n","Train Epoch: 5 [4480/12000 (37.3%)]\tLoss: 2.708563\n","Train Epoch: 5 [5120/12000 (42.7%)]\tLoss: 2.837600\n","Train Epoch: 5 [5760/12000 (48.0%)]\tLoss: 2.169113\n","Train Epoch: 5 [6400/12000 (53.3%)]\tLoss: 2.923596\n","Train Epoch: 5 [7040/12000 (58.7%)]\tLoss: 2.543212\n","Train Epoch: 5 [7680/12000 (64.0%)]\tLoss: 2.489563\n","Train Epoch: 5 [8320/12000 (69.3%)]\tLoss: 3.549547\n","Train Epoch: 5 [8960/12000 (74.7%)]\tLoss: 2.978942\n","Train Epoch: 5 [9600/12000 (80.0%)]\tLoss: 2.662080\n","Train Epoch: 5 [10240/12000 (85.3%)]\tLoss: 2.984629\n","Train Epoch: 5 [10880/12000 (90.7%)]\tLoss: 3.051358\n","Train Epoch: 5 [11520/12000 (96.0%)]\tLoss: 2.919198\n","\n","Test set: Average loss: 4.1765, Accuracy: 973/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 6 [0/12000 (0.0%)]\tLoss: 2.504475\n","Train Epoch: 6 [640/12000 (5.3%)]\tLoss: 2.365691\n","Train Epoch: 6 [1280/12000 (10.7%)]\tLoss: 2.645247\n","Train Epoch: 6 [1920/12000 (16.0%)]\tLoss: 2.198176\n","Train Epoch: 6 [2560/12000 (21.3%)]\tLoss: 2.675375\n","Train Epoch: 6 [3200/12000 (26.7%)]\tLoss: 2.509138\n","Train Epoch: 6 [3840/12000 (32.0%)]\tLoss: 2.585006\n","Train Epoch: 6 [4480/12000 (37.3%)]\tLoss: 2.594194\n","Train Epoch: 6 [5120/12000 (42.7%)]\tLoss: 2.289321\n","Train Epoch: 6 [5760/12000 (48.0%)]\tLoss: 2.721001\n","Train Epoch: 6 [6400/12000 (53.3%)]\tLoss: 2.251022\n","Train Epoch: 6 [7040/12000 (58.7%)]\tLoss: 2.463446\n","Train Epoch: 6 [7680/12000 (64.0%)]\tLoss: 2.861502\n","Train Epoch: 6 [8320/12000 (69.3%)]\tLoss: 2.892190\n","Train Epoch: 6 [8960/12000 (74.7%)]\tLoss: 2.383687\n","Train Epoch: 6 [9600/12000 (80.0%)]\tLoss: 2.684537\n","Train Epoch: 6 [10240/12000 (85.3%)]\tLoss: 3.077240\n","Train Epoch: 6 [10880/12000 (90.7%)]\tLoss: 3.007514\n","Train Epoch: 6 [11520/12000 (96.0%)]\tLoss: 2.879052\n","\n","Test set: Average loss: 4.3056, Accuracy: 1027/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 7 [0/12000 (0.0%)]\tLoss: 1.980910\n","Train Epoch: 7 [640/12000 (5.3%)]\tLoss: 2.586321\n","Train Epoch: 7 [1280/12000 (10.7%)]\tLoss: 1.655172\n","Train Epoch: 7 [1920/12000 (16.0%)]\tLoss: 2.263050\n","Train Epoch: 7 [2560/12000 (21.3%)]\tLoss: 2.583041\n","Train Epoch: 7 [3200/12000 (26.7%)]\tLoss: 1.597534\n","Train Epoch: 7 [3840/12000 (32.0%)]\tLoss: 2.408349\n","Train Epoch: 7 [4480/12000 (37.3%)]\tLoss: 2.826995\n","Train Epoch: 7 [5120/12000 (42.7%)]\tLoss: 2.235647\n","Train Epoch: 7 [5760/12000 (48.0%)]\tLoss: 2.117180\n","Train Epoch: 7 [6400/12000 (53.3%)]\tLoss: 2.163368\n","Train Epoch: 7 [7040/12000 (58.7%)]\tLoss: 2.544743\n","Train Epoch: 7 [7680/12000 (64.0%)]\tLoss: 2.252189\n","Train Epoch: 7 [8320/12000 (69.3%)]\tLoss: 2.816339\n","Train Epoch: 7 [8960/12000 (74.7%)]\tLoss: 2.125484\n","Train Epoch: 7 [9600/12000 (80.0%)]\tLoss: 1.982895\n","Train Epoch: 7 [10240/12000 (85.3%)]\tLoss: 3.169270\n","Train Epoch: 7 [10880/12000 (90.7%)]\tLoss: 2.701613\n","Train Epoch: 7 [11520/12000 (96.0%)]\tLoss: 2.210361\n","\n","Test set: Average loss: 4.4197, Accuracy: 980/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 8 [0/12000 (0.0%)]\tLoss: 1.499493\n","Train Epoch: 8 [640/12000 (5.3%)]\tLoss: 2.133311\n","Train Epoch: 8 [1280/12000 (10.7%)]\tLoss: 2.300357\n","Train Epoch: 8 [1920/12000 (16.0%)]\tLoss: 1.568982\n","Train Epoch: 8 [2560/12000 (21.3%)]\tLoss: 2.140570\n","Train Epoch: 8 [3200/12000 (26.7%)]\tLoss: 1.496450\n","Train Epoch: 8 [3840/12000 (32.0%)]\tLoss: 2.135802\n","Train Epoch: 8 [4480/12000 (37.3%)]\tLoss: 1.898198\n","Train Epoch: 8 [5120/12000 (42.7%)]\tLoss: 2.827038\n","Train Epoch: 8 [5760/12000 (48.0%)]\tLoss: 1.932295\n","Train Epoch: 8 [6400/12000 (53.3%)]\tLoss: 1.752184\n","Train Epoch: 8 [7040/12000 (58.7%)]\tLoss: 1.678251\n","Train Epoch: 8 [7680/12000 (64.0%)]\tLoss: 2.031315\n","Train Epoch: 8 [8320/12000 (69.3%)]\tLoss: 2.443337\n","Train Epoch: 8 [8960/12000 (74.7%)]\tLoss: 2.479793\n","Train Epoch: 8 [9600/12000 (80.0%)]\tLoss: 1.941930\n","Train Epoch: 8 [10240/12000 (85.3%)]\tLoss: 3.162802\n","Train Epoch: 8 [10880/12000 (90.7%)]\tLoss: 1.613390\n","Train Epoch: 8 [11520/12000 (96.0%)]\tLoss: 1.860137\n","\n","Test set: Average loss: 4.6263, Accuracy: 1016/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 9 [0/12000 (0.0%)]\tLoss: 2.035464\n","Train Epoch: 9 [640/12000 (5.3%)]\tLoss: 1.351393\n","Train Epoch: 9 [1280/12000 (10.7%)]\tLoss: 1.519511\n","Train Epoch: 9 [1920/12000 (16.0%)]\tLoss: 1.615840\n","Train Epoch: 9 [2560/12000 (21.3%)]\tLoss: 0.974937\n","Train Epoch: 9 [3200/12000 (26.7%)]\tLoss: 1.505881\n","Train Epoch: 9 [3840/12000 (32.0%)]\tLoss: 1.745612\n","Train Epoch: 9 [4480/12000 (37.3%)]\tLoss: 2.462193\n","Train Epoch: 9 [5120/12000 (42.7%)]\tLoss: 1.822529\n","Train Epoch: 9 [5760/12000 (48.0%)]\tLoss: 2.283356\n","Train Epoch: 9 [6400/12000 (53.3%)]\tLoss: 1.611489\n","Train Epoch: 9 [7040/12000 (58.7%)]\tLoss: 1.473774\n","Train Epoch: 9 [7680/12000 (64.0%)]\tLoss: 2.201932\n","Train Epoch: 9 [8320/12000 (69.3%)]\tLoss: 2.052193\n","Train Epoch: 9 [8960/12000 (74.7%)]\tLoss: 1.805202\n","Train Epoch: 9 [9600/12000 (80.0%)]\tLoss: 1.874088\n","Train Epoch: 9 [10240/12000 (85.3%)]\tLoss: 1.763397\n","Train Epoch: 9 [10880/12000 (90.7%)]\tLoss: 1.899304\n","Train Epoch: 9 [11520/12000 (96.0%)]\tLoss: 2.080879\n","\n","Test set: Average loss: 4.7617, Accuracy: 969/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 10 [0/12000 (0.0%)]\tLoss: 0.960442\n","Train Epoch: 10 [640/12000 (5.3%)]\tLoss: 1.923311\n","Train Epoch: 10 [1280/12000 (10.7%)]\tLoss: 1.111750\n","Train Epoch: 10 [1920/12000 (16.0%)]\tLoss: 1.227984\n","Train Epoch: 10 [2560/12000 (21.3%)]\tLoss: 1.608819\n","Train Epoch: 10 [3200/12000 (26.7%)]\tLoss: 1.043840\n","Train Epoch: 10 [3840/12000 (32.0%)]\tLoss: 1.379601\n","Train Epoch: 10 [4480/12000 (37.3%)]\tLoss: 1.721928\n","Train Epoch: 10 [5120/12000 (42.7%)]\tLoss: 1.452094\n","Train Epoch: 10 [5760/12000 (48.0%)]\tLoss: 1.354947\n","Train Epoch: 10 [6400/12000 (53.3%)]\tLoss: 1.701468\n","Train Epoch: 10 [7040/12000 (58.7%)]\tLoss: 1.948701\n","Train Epoch: 10 [7680/12000 (64.0%)]\tLoss: 1.607500\n","Train Epoch: 10 [8320/12000 (69.3%)]\tLoss: 1.761308\n","Train Epoch: 10 [8960/12000 (74.7%)]\tLoss: 1.592795\n","Train Epoch: 10 [9600/12000 (80.0%)]\tLoss: 1.919116\n","Train Epoch: 10 [10240/12000 (85.3%)]\tLoss: 2.207605\n","Train Epoch: 10 [10880/12000 (90.7%)]\tLoss: 1.486151\n","Train Epoch: 10 [11520/12000 (96.0%)]\tLoss: 1.799092\n","\n","Test set: Average loss: 5.0386, Accuracy: 1010/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 11 [0/12000 (0.0%)]\tLoss: 1.063663\n","Train Epoch: 11 [640/12000 (5.3%)]\tLoss: 1.208930\n","Train Epoch: 11 [1280/12000 (10.7%)]\tLoss: 0.633389\n","Train Epoch: 11 [1920/12000 (16.0%)]\tLoss: 1.220616\n","Train Epoch: 11 [2560/12000 (21.3%)]\tLoss: 1.121749\n","Train Epoch: 11 [3200/12000 (26.7%)]\tLoss: 1.874880\n","Train Epoch: 11 [3840/12000 (32.0%)]\tLoss: 0.786180\n","Train Epoch: 11 [4480/12000 (37.3%)]\tLoss: 1.340230\n","Train Epoch: 11 [5120/12000 (42.7%)]\tLoss: 1.631349\n","Train Epoch: 11 [5760/12000 (48.0%)]\tLoss: 1.297748\n","Train Epoch: 11 [6400/12000 (53.3%)]\tLoss: 1.867763\n","Train Epoch: 11 [7040/12000 (58.7%)]\tLoss: 1.744521\n","Train Epoch: 11 [7680/12000 (64.0%)]\tLoss: 2.465435\n","Train Epoch: 11 [8320/12000 (69.3%)]\tLoss: 1.357741\n","Train Epoch: 11 [8960/12000 (74.7%)]\tLoss: 1.100986\n","Train Epoch: 11 [9600/12000 (80.0%)]\tLoss: 1.201949\n","Train Epoch: 11 [10240/12000 (85.3%)]\tLoss: 1.471942\n","Train Epoch: 11 [10880/12000 (90.7%)]\tLoss: 1.345231\n","Train Epoch: 11 [11520/12000 (96.0%)]\tLoss: 2.028378\n","\n","Test set: Average loss: 5.2827, Accuracy: 935/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 12 [0/12000 (0.0%)]\tLoss: 1.355524\n","Train Epoch: 12 [640/12000 (5.3%)]\tLoss: 1.470757\n","Train Epoch: 12 [1280/12000 (10.7%)]\tLoss: 1.485551\n","Train Epoch: 12 [1920/12000 (16.0%)]\tLoss: 1.345050\n","Train Epoch: 12 [2560/12000 (21.3%)]\tLoss: 0.711447\n","Train Epoch: 12 [3200/12000 (26.7%)]\tLoss: 0.941484\n","Train Epoch: 12 [3840/12000 (32.0%)]\tLoss: 1.034929\n","Train Epoch: 12 [4480/12000 (37.3%)]\tLoss: 1.908020\n","Train Epoch: 12 [5120/12000 (42.7%)]\tLoss: 2.178956\n","Train Epoch: 12 [5760/12000 (48.0%)]\tLoss: 1.859366\n","Train Epoch: 12 [6400/12000 (53.3%)]\tLoss: 1.085545\n","Train Epoch: 12 [7040/12000 (58.7%)]\tLoss: 0.894252\n","Train Epoch: 12 [7680/12000 (64.0%)]\tLoss: 1.015431\n","Train Epoch: 12 [8320/12000 (69.3%)]\tLoss: 1.632956\n","Train Epoch: 12 [8960/12000 (74.7%)]\tLoss: 1.369966\n","Train Epoch: 12 [9600/12000 (80.0%)]\tLoss: 1.285294\n","Train Epoch: 12 [10240/12000 (85.3%)]\tLoss: 1.168180\n","Train Epoch: 12 [10880/12000 (90.7%)]\tLoss: 1.534547\n","Train Epoch: 12 [11520/12000 (96.0%)]\tLoss: 1.779484\n","\n","Test set: Average loss: 5.3985, Accuracy: 924/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 13 [0/12000 (0.0%)]\tLoss: 1.573284\n","Train Epoch: 13 [640/12000 (5.3%)]\tLoss: 0.967340\n","Train Epoch: 13 [1280/12000 (10.7%)]\tLoss: 0.918512\n","Train Epoch: 13 [1920/12000 (16.0%)]\tLoss: 0.681974\n","Train Epoch: 13 [2560/12000 (21.3%)]\tLoss: 1.103325\n","Train Epoch: 13 [3200/12000 (26.7%)]\tLoss: 1.214041\n","Train Epoch: 13 [3840/12000 (32.0%)]\tLoss: 1.742530\n","Train Epoch: 13 [4480/12000 (37.3%)]\tLoss: 1.224650\n","Train Epoch: 13 [5120/12000 (42.7%)]\tLoss: 0.832179\n","Train Epoch: 13 [5760/12000 (48.0%)]\tLoss: 1.000853\n","Train Epoch: 13 [6400/12000 (53.3%)]\tLoss: 0.985907\n","Train Epoch: 13 [7040/12000 (58.7%)]\tLoss: 1.191107\n","Train Epoch: 13 [7680/12000 (64.0%)]\tLoss: 0.893029\n","Train Epoch: 13 [8320/12000 (69.3%)]\tLoss: 2.000132\n","Train Epoch: 13 [8960/12000 (74.7%)]\tLoss: 0.913840\n","Train Epoch: 13 [9600/12000 (80.0%)]\tLoss: 1.982250\n","Train Epoch: 13 [10240/12000 (85.3%)]\tLoss: 1.547828\n","Train Epoch: 13 [10880/12000 (90.7%)]\tLoss: 1.286154\n","Train Epoch: 13 [11520/12000 (96.0%)]\tLoss: 1.398952\n","\n","Test set: Average loss: 5.6402, Accuracy: 966/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 14 [0/12000 (0.0%)]\tLoss: 1.104928\n","Train Epoch: 14 [640/12000 (5.3%)]\tLoss: 1.103671\n","Train Epoch: 14 [1280/12000 (10.7%)]\tLoss: 0.906623\n","Train Epoch: 14 [1920/12000 (16.0%)]\tLoss: 0.791638\n","Train Epoch: 14 [2560/12000 (21.3%)]\tLoss: 1.035186\n","Train Epoch: 14 [3200/12000 (26.7%)]\tLoss: 1.368568\n","Train Epoch: 14 [3840/12000 (32.0%)]\tLoss: 1.641337\n","Train Epoch: 14 [4480/12000 (37.3%)]\tLoss: 1.143181\n","Train Epoch: 14 [5120/12000 (42.7%)]\tLoss: 0.750526\n","Train Epoch: 14 [5760/12000 (48.0%)]\tLoss: 1.211236\n","Train Epoch: 14 [6400/12000 (53.3%)]\tLoss: 1.659634\n","Train Epoch: 14 [7040/12000 (58.7%)]\tLoss: 1.652323\n","Train Epoch: 14 [7680/12000 (64.0%)]\tLoss: 2.012183\n","Train Epoch: 14 [8320/12000 (69.3%)]\tLoss: 1.125774\n","Train Epoch: 14 [8960/12000 (74.7%)]\tLoss: 0.961003\n","Train Epoch: 14 [9600/12000 (80.0%)]\tLoss: 0.793011\n","Train Epoch: 14 [10240/12000 (85.3%)]\tLoss: 0.742175\n","Train Epoch: 14 [10880/12000 (90.7%)]\tLoss: 0.825090\n","Train Epoch: 14 [11520/12000 (96.0%)]\tLoss: 1.317722\n","\n","Test set: Average loss: 5.6118, Accuracy: 873/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 15 [0/12000 (0.0%)]\tLoss: 1.170682\n","Train Epoch: 15 [640/12000 (5.3%)]\tLoss: 0.436005\n","Train Epoch: 15 [1280/12000 (10.7%)]\tLoss: 0.814838\n","Train Epoch: 15 [1920/12000 (16.0%)]\tLoss: 1.209378\n","Train Epoch: 15 [2560/12000 (21.3%)]\tLoss: 1.224536\n","Train Epoch: 15 [3200/12000 (26.7%)]\tLoss: 0.734818\n","Train Epoch: 15 [3840/12000 (32.0%)]\tLoss: 1.527569\n","Train Epoch: 15 [4480/12000 (37.3%)]\tLoss: 1.039903\n","Train Epoch: 15 [5120/12000 (42.7%)]\tLoss: 0.853614\n","Train Epoch: 15 [5760/12000 (48.0%)]\tLoss: 1.324732\n","Train Epoch: 15 [6400/12000 (53.3%)]\tLoss: 1.225741\n","Train Epoch: 15 [7040/12000 (58.7%)]\tLoss: 0.882349\n","Train Epoch: 15 [7680/12000 (64.0%)]\tLoss: 0.912741\n","Train Epoch: 15 [8320/12000 (69.3%)]\tLoss: 0.905276\n","Train Epoch: 15 [8960/12000 (74.7%)]\tLoss: 1.464184\n","Train Epoch: 15 [9600/12000 (80.0%)]\tLoss: 0.815706\n","Train Epoch: 15 [10240/12000 (85.3%)]\tLoss: 0.930284\n","Train Epoch: 15 [10880/12000 (90.7%)]\tLoss: 1.691620\n","Train Epoch: 15 [11520/12000 (96.0%)]\tLoss: 1.074996\n","\n","Test set: Average loss: 5.6144, Accuracy: 941/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 16 [0/12000 (0.0%)]\tLoss: 0.611608\n","Train Epoch: 16 [640/12000 (5.3%)]\tLoss: 0.827739\n","Train Epoch: 16 [1280/12000 (10.7%)]\tLoss: 0.373744\n","Train Epoch: 16 [1920/12000 (16.0%)]\tLoss: 0.650301\n","Train Epoch: 16 [2560/12000 (21.3%)]\tLoss: 0.960885\n","Train Epoch: 16 [3200/12000 (26.7%)]\tLoss: 0.796951\n","Train Epoch: 16 [3840/12000 (32.0%)]\tLoss: 0.851080\n","Train Epoch: 16 [4480/12000 (37.3%)]\tLoss: 1.040938\n","Train Epoch: 16 [5120/12000 (42.7%)]\tLoss: 1.601756\n","Train Epoch: 16 [5760/12000 (48.0%)]\tLoss: 1.092314\n","Train Epoch: 16 [6400/12000 (53.3%)]\tLoss: 1.187495\n","Train Epoch: 16 [7040/12000 (58.7%)]\tLoss: 1.813725\n","Train Epoch: 16 [7680/12000 (64.0%)]\tLoss: 0.863027\n","Train Epoch: 16 [8320/12000 (69.3%)]\tLoss: 1.526937\n","Train Epoch: 16 [8960/12000 (74.7%)]\tLoss: 1.122212\n","Train Epoch: 16 [9600/12000 (80.0%)]\tLoss: 1.333598\n","Train Epoch: 16 [10240/12000 (85.3%)]\tLoss: 1.065834\n","Train Epoch: 16 [10880/12000 (90.7%)]\tLoss: 1.555708\n","Train Epoch: 16 [11520/12000 (96.0%)]\tLoss: 0.788763\n","\n","Test set: Average loss: 5.7868, Accuracy: 969/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 17 [0/12000 (0.0%)]\tLoss: 0.468580\n","Train Epoch: 17 [640/12000 (5.3%)]\tLoss: 0.497125\n","Train Epoch: 17 [1280/12000 (10.7%)]\tLoss: 0.921886\n","Train Epoch: 17 [1920/12000 (16.0%)]\tLoss: 0.664390\n","Train Epoch: 17 [2560/12000 (21.3%)]\tLoss: 0.368408\n","Train Epoch: 17 [3200/12000 (26.7%)]\tLoss: 0.748515\n","Train Epoch: 17 [3840/12000 (32.0%)]\tLoss: 0.941819\n","Train Epoch: 17 [4480/12000 (37.3%)]\tLoss: 0.851684\n","Train Epoch: 17 [5120/12000 (42.7%)]\tLoss: 0.534910\n","Train Epoch: 17 [5760/12000 (48.0%)]\tLoss: 0.392217\n","Train Epoch: 17 [6400/12000 (53.3%)]\tLoss: 0.664438\n","Train Epoch: 17 [7040/12000 (58.7%)]\tLoss: 1.259257\n","Train Epoch: 17 [7680/12000 (64.0%)]\tLoss: 0.905143\n","Train Epoch: 17 [8320/12000 (69.3%)]\tLoss: 0.759515\n","Train Epoch: 17 [8960/12000 (74.7%)]\tLoss: 1.321881\n","Train Epoch: 17 [9600/12000 (80.0%)]\tLoss: 0.943841\n","Train Epoch: 17 [10240/12000 (85.3%)]\tLoss: 0.518288\n","Train Epoch: 17 [10880/12000 (90.7%)]\tLoss: 1.273533\n","Train Epoch: 17 [11520/12000 (96.0%)]\tLoss: 1.083256\n","\n","Test set: Average loss: 6.0886, Accuracy: 879/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 18 [0/12000 (0.0%)]\tLoss: 0.729319\n","Train Epoch: 18 [640/12000 (5.3%)]\tLoss: 0.579935\n","Train Epoch: 18 [1280/12000 (10.7%)]\tLoss: 0.560561\n","Train Epoch: 18 [1920/12000 (16.0%)]\tLoss: 0.723431\n","Train Epoch: 18 [2560/12000 (21.3%)]\tLoss: 0.746001\n","Train Epoch: 18 [3200/12000 (26.7%)]\tLoss: 0.931642\n","Train Epoch: 18 [3840/12000 (32.0%)]\tLoss: 0.955504\n","Train Epoch: 18 [4480/12000 (37.3%)]\tLoss: 0.771251\n","Train Epoch: 18 [5120/12000 (42.7%)]\tLoss: 0.807011\n","Train Epoch: 18 [5760/12000 (48.0%)]\tLoss: 0.716063\n","Train Epoch: 18 [6400/12000 (53.3%)]\tLoss: 0.806374\n","Train Epoch: 18 [7040/12000 (58.7%)]\tLoss: 0.375285\n","Train Epoch: 18 [7680/12000 (64.0%)]\tLoss: 0.810193\n","Train Epoch: 18 [8320/12000 (69.3%)]\tLoss: 0.679766\n","Train Epoch: 18 [8960/12000 (74.7%)]\tLoss: 0.621005\n","Train Epoch: 18 [9600/12000 (80.0%)]\tLoss: 0.705924\n","Train Epoch: 18 [10240/12000 (85.3%)]\tLoss: 1.380654\n","Train Epoch: 18 [10880/12000 (90.7%)]\tLoss: 1.155360\n","Train Epoch: 18 [11520/12000 (96.0%)]\tLoss: 0.563227\n","\n","Test set: Average loss: 6.1950, Accuracy: 955/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 19 [0/12000 (0.0%)]\tLoss: 0.485676\n","Train Epoch: 19 [640/12000 (5.3%)]\tLoss: 0.775060\n","Train Epoch: 19 [1280/12000 (10.7%)]\tLoss: 1.005631\n","Train Epoch: 19 [1920/12000 (16.0%)]\tLoss: 0.841509\n","Train Epoch: 19 [2560/12000 (21.3%)]\tLoss: 1.249279\n","Train Epoch: 19 [3200/12000 (26.7%)]\tLoss: 0.727383\n","Train Epoch: 19 [3840/12000 (32.0%)]\tLoss: 0.773573\n","Train Epoch: 19 [4480/12000 (37.3%)]\tLoss: 0.734558\n","Train Epoch: 19 [5120/12000 (42.7%)]\tLoss: 0.866470\n","Train Epoch: 19 [5760/12000 (48.0%)]\tLoss: 1.197066\n","Train Epoch: 19 [6400/12000 (53.3%)]\tLoss: 1.104382\n","Train Epoch: 19 [7040/12000 (58.7%)]\tLoss: 0.932969\n","Train Epoch: 19 [7680/12000 (64.0%)]\tLoss: 1.149420\n","Train Epoch: 19 [8320/12000 (69.3%)]\tLoss: 0.739466\n","Train Epoch: 19 [8960/12000 (74.7%)]\tLoss: 1.103547\n","Train Epoch: 19 [9600/12000 (80.0%)]\tLoss: 1.259186\n","Train Epoch: 19 [10240/12000 (85.3%)]\tLoss: 0.664545\n","Train Epoch: 19 [10880/12000 (90.7%)]\tLoss: 0.557507\n","Train Epoch: 19 [11520/12000 (96.0%)]\tLoss: 1.276170\n","\n","Test set: Average loss: 6.2770, Accuracy: 941/8580 (10.00%), F1: 0.08\n","\n","Train Epoch: 20 [0/12000 (0.0%)]\tLoss: 0.395363\n","Train Epoch: 20 [640/12000 (5.3%)]\tLoss: 0.630013\n","Train Epoch: 20 [1280/12000 (10.7%)]\tLoss: 0.331856\n","Train Epoch: 20 [1920/12000 (16.0%)]\tLoss: 0.614798\n","Train Epoch: 20 [2560/12000 (21.3%)]\tLoss: 0.455957\n","Train Epoch: 20 [3200/12000 (26.7%)]\tLoss: 0.236665\n","Train Epoch: 20 [3840/12000 (32.0%)]\tLoss: 0.185645\n","Train Epoch: 20 [4480/12000 (37.3%)]\tLoss: 0.483033\n","Train Epoch: 20 [5120/12000 (42.7%)]\tLoss: 0.875530\n","Train Epoch: 20 [5760/12000 (48.0%)]\tLoss: 0.228409\n","Train Epoch: 20 [6400/12000 (53.3%)]\tLoss: 0.427325\n","Train Epoch: 20 [7040/12000 (58.7%)]\tLoss: 0.447313\n","Train Epoch: 20 [7680/12000 (64.0%)]\tLoss: 0.137288\n","Train Epoch: 20 [8320/12000 (69.3%)]\tLoss: 0.048423\n","Train Epoch: 20 [8960/12000 (74.7%)]\tLoss: 0.322343\n","Train Epoch: 20 [9600/12000 (80.0%)]\tLoss: 0.275778\n","Train Epoch: 20 [10240/12000 (85.3%)]\tLoss: 0.055755\n","Train Epoch: 20 [10880/12000 (90.7%)]\tLoss: 0.442131\n","Train Epoch: 20 [11520/12000 (96.0%)]\tLoss: 0.736012\n","\n","Test set: Average loss: 5.6831, Accuracy: 1186/8580 (13.00%), F1: 0.11\n","\n","Train Epoch: 21 [0/12000 (0.0%)]\tLoss: 0.189965\n","Train Epoch: 21 [640/12000 (5.3%)]\tLoss: 0.173053\n","Train Epoch: 21 [1280/12000 (10.7%)]\tLoss: 0.257681\n","Train Epoch: 21 [1920/12000 (16.0%)]\tLoss: 0.207019\n","Train Epoch: 21 [2560/12000 (21.3%)]\tLoss: 0.194358\n","Train Epoch: 21 [3200/12000 (26.7%)]\tLoss: 0.166985\n","Train Epoch: 21 [3840/12000 (32.0%)]\tLoss: 0.103240\n","Train Epoch: 21 [4480/12000 (37.3%)]\tLoss: 0.217436\n","Train Epoch: 21 [5120/12000 (42.7%)]\tLoss: 0.117509\n","Train Epoch: 21 [5760/12000 (48.0%)]\tLoss: 0.056908\n","Train Epoch: 21 [6400/12000 (53.3%)]\tLoss: 0.377944\n","Train Epoch: 21 [7040/12000 (58.7%)]\tLoss: 0.150280\n","Train Epoch: 21 [7680/12000 (64.0%)]\tLoss: 0.225872\n","Train Epoch: 21 [8320/12000 (69.3%)]\tLoss: 0.089304\n","Train Epoch: 21 [8960/12000 (74.7%)]\tLoss: 0.182994\n","Train Epoch: 21 [9600/12000 (80.0%)]\tLoss: 0.101989\n","Train Epoch: 21 [10240/12000 (85.3%)]\tLoss: 0.271312\n","Train Epoch: 21 [10880/12000 (90.7%)]\tLoss: 0.055815\n","Train Epoch: 21 [11520/12000 (96.0%)]\tLoss: 0.062076\n","\n","Test set: Average loss: 5.7425, Accuracy: 1215/8580 (14.00%), F1: 0.08\n","\n","Train Epoch: 22 [0/12000 (0.0%)]\tLoss: 0.101528\n","Train Epoch: 22 [640/12000 (5.3%)]\tLoss: 0.162495\n","Train Epoch: 22 [1280/12000 (10.7%)]\tLoss: 0.057233\n","Train Epoch: 22 [1920/12000 (16.0%)]\tLoss: 0.031353\n","Train Epoch: 22 [2560/12000 (21.3%)]\tLoss: 0.249545\n","Train Epoch: 22 [3200/12000 (26.7%)]\tLoss: 0.086086\n","Train Epoch: 22 [3840/12000 (32.0%)]\tLoss: 0.126070\n","Train Epoch: 22 [4480/12000 (37.3%)]\tLoss: 0.066195\n","Train Epoch: 22 [5120/12000 (42.7%)]\tLoss: 0.028623\n","Train Epoch: 22 [5760/12000 (48.0%)]\tLoss: 0.219400\n","Train Epoch: 22 [6400/12000 (53.3%)]\tLoss: 0.043566\n","Train Epoch: 22 [7040/12000 (58.7%)]\tLoss: 0.042993\n","Train Epoch: 22 [7680/12000 (64.0%)]\tLoss: 0.173369\n","Train Epoch: 22 [8320/12000 (69.3%)]\tLoss: 0.014057\n","Train Epoch: 22 [8960/12000 (74.7%)]\tLoss: 0.038072\n","Train Epoch: 22 [9600/12000 (80.0%)]\tLoss: 0.081010\n","Train Epoch: 22 [10240/12000 (85.3%)]\tLoss: 0.082458\n","Train Epoch: 22 [10880/12000 (90.7%)]\tLoss: 0.123453\n","Train Epoch: 22 [11520/12000 (96.0%)]\tLoss: 0.174063\n","\n","Test set: Average loss: 5.9107, Accuracy: 1228/8580 (14.00%), F1: 0.12\n","\n","Train Epoch: 23 [0/12000 (0.0%)]\tLoss: 0.079034\n","Train Epoch: 23 [640/12000 (5.3%)]\tLoss: 0.025492\n","Train Epoch: 23 [1280/12000 (10.7%)]\tLoss: 0.027543\n","Train Epoch: 23 [1920/12000 (16.0%)]\tLoss: 0.195038\n","Train Epoch: 23 [2560/12000 (21.3%)]\tLoss: 0.041336\n","Train Epoch: 23 [3200/12000 (26.7%)]\tLoss: 0.114173\n","Train Epoch: 23 [3840/12000 (32.0%)]\tLoss: 0.074325\n","Train Epoch: 23 [4480/12000 (37.3%)]\tLoss: 0.030271\n","Train Epoch: 23 [5120/12000 (42.7%)]\tLoss: 0.086659\n","Train Epoch: 23 [5760/12000 (48.0%)]\tLoss: 0.235821\n","Train Epoch: 23 [6400/12000 (53.3%)]\tLoss: 0.085911\n","Train Epoch: 23 [7040/12000 (58.7%)]\tLoss: 0.078236\n","Train Epoch: 23 [7680/12000 (64.0%)]\tLoss: 0.084006\n","Train Epoch: 23 [8320/12000 (69.3%)]\tLoss: 0.014996\n","Train Epoch: 23 [8960/12000 (74.7%)]\tLoss: 0.030075\n","Train Epoch: 23 [9600/12000 (80.0%)]\tLoss: 0.184715\n","Train Epoch: 23 [10240/12000 (85.3%)]\tLoss: 0.129751\n","Train Epoch: 23 [10880/12000 (90.7%)]\tLoss: 0.091097\n","Train Epoch: 23 [11520/12000 (96.0%)]\tLoss: 0.328897\n","\n","Test set: Average loss: 5.9692, Accuracy: 1252/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 24 [0/12000 (0.0%)]\tLoss: 0.056401\n","Train Epoch: 24 [640/12000 (5.3%)]\tLoss: 0.072724\n","Train Epoch: 24 [1280/12000 (10.7%)]\tLoss: 0.037189\n","Train Epoch: 24 [1920/12000 (16.0%)]\tLoss: 0.187138\n","Train Epoch: 24 [2560/12000 (21.3%)]\tLoss: 0.015004\n","Train Epoch: 24 [3200/12000 (26.7%)]\tLoss: 0.093062\n","Train Epoch: 24 [3840/12000 (32.0%)]\tLoss: 0.024314\n","Train Epoch: 24 [4480/12000 (37.3%)]\tLoss: 0.202777\n","Train Epoch: 24 [5120/12000 (42.7%)]\tLoss: 0.031785\n","Train Epoch: 24 [5760/12000 (48.0%)]\tLoss: 0.015978\n","Train Epoch: 24 [6400/12000 (53.3%)]\tLoss: 0.104011\n","Train Epoch: 24 [7040/12000 (58.7%)]\tLoss: 0.171273\n","Train Epoch: 24 [7680/12000 (64.0%)]\tLoss: 0.057260\n","Train Epoch: 24 [8320/12000 (69.3%)]\tLoss: 0.015905\n","Train Epoch: 24 [8960/12000 (74.7%)]\tLoss: 0.039226\n","Train Epoch: 24 [9600/12000 (80.0%)]\tLoss: 0.079293\n","Train Epoch: 24 [10240/12000 (85.3%)]\tLoss: 0.046642\n","Train Epoch: 24 [10880/12000 (90.7%)]\tLoss: 0.023842\n","Train Epoch: 24 [11520/12000 (96.0%)]\tLoss: 0.055470\n","\n","Test set: Average loss: 5.9969, Accuracy: 1270/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 25 [0/12000 (0.0%)]\tLoss: 0.244644\n","Train Epoch: 25 [640/12000 (5.3%)]\tLoss: 0.011682\n","Train Epoch: 25 [1280/12000 (10.7%)]\tLoss: 0.097347\n","Train Epoch: 25 [1920/12000 (16.0%)]\tLoss: 0.040762\n","Train Epoch: 25 [2560/12000 (21.3%)]\tLoss: 0.031303\n","Train Epoch: 25 [3200/12000 (26.7%)]\tLoss: 0.029800\n","Train Epoch: 25 [3840/12000 (32.0%)]\tLoss: 0.082736\n","Train Epoch: 25 [4480/12000 (37.3%)]\tLoss: 0.017432\n","Train Epoch: 25 [5120/12000 (42.7%)]\tLoss: 0.389539\n","Train Epoch: 25 [5760/12000 (48.0%)]\tLoss: 0.043033\n","Train Epoch: 25 [6400/12000 (53.3%)]\tLoss: 0.043208\n","Train Epoch: 25 [7040/12000 (58.7%)]\tLoss: 0.126811\n","Train Epoch: 25 [7680/12000 (64.0%)]\tLoss: 0.006443\n","Train Epoch: 25 [8320/12000 (69.3%)]\tLoss: 0.011302\n","Train Epoch: 25 [8960/12000 (74.7%)]\tLoss: 0.044986\n","Train Epoch: 25 [9600/12000 (80.0%)]\tLoss: 0.011723\n","Train Epoch: 25 [10240/12000 (85.3%)]\tLoss: 0.127320\n","Train Epoch: 25 [10880/12000 (90.7%)]\tLoss: 0.056159\n","Train Epoch: 25 [11520/12000 (96.0%)]\tLoss: 0.032344\n","\n","Test set: Average loss: 5.9889, Accuracy: 1269/8580 (14.00%), F1: 0.10\n","\n","Train Epoch: 26 [0/12000 (0.0%)]\tLoss: 0.052084\n","Train Epoch: 26 [640/12000 (5.3%)]\tLoss: 0.006778\n","Train Epoch: 26 [1280/12000 (10.7%)]\tLoss: 0.193802\n","Train Epoch: 26 [1920/12000 (16.0%)]\tLoss: 0.019679\n","Train Epoch: 26 [2560/12000 (21.3%)]\tLoss: 0.022985\n","Train Epoch: 26 [3200/12000 (26.7%)]\tLoss: 0.073447\n","Train Epoch: 26 [3840/12000 (32.0%)]\tLoss: 0.066523\n","Train Epoch: 26 [4480/12000 (37.3%)]\tLoss: 0.125388\n","Train Epoch: 26 [5120/12000 (42.7%)]\tLoss: 0.018514\n","Train Epoch: 26 [5760/12000 (48.0%)]\tLoss: 0.008533\n","Train Epoch: 26 [6400/12000 (53.3%)]\tLoss: 0.030921\n","Train Epoch: 26 [7040/12000 (58.7%)]\tLoss: 0.037171\n","Train Epoch: 26 [7680/12000 (64.0%)]\tLoss: 0.042385\n","Train Epoch: 26 [8320/12000 (69.3%)]\tLoss: 0.162056\n","Train Epoch: 26 [8960/12000 (74.7%)]\tLoss: 0.029704\n","Train Epoch: 26 [9600/12000 (80.0%)]\tLoss: 0.024951\n","Train Epoch: 26 [10240/12000 (85.3%)]\tLoss: 0.115410\n","Train Epoch: 26 [10880/12000 (90.7%)]\tLoss: 0.054730\n","Train Epoch: 26 [11520/12000 (96.0%)]\tLoss: 0.007332\n","\n","Test set: Average loss: 6.0790, Accuracy: 1274/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 27 [0/12000 (0.0%)]\tLoss: 0.024073\n","Train Epoch: 27 [640/12000 (5.3%)]\tLoss: 0.024557\n","Train Epoch: 27 [1280/12000 (10.7%)]\tLoss: 0.046715\n","Train Epoch: 27 [1920/12000 (16.0%)]\tLoss: 0.015374\n","Train Epoch: 27 [2560/12000 (21.3%)]\tLoss: 0.018083\n","Train Epoch: 27 [3200/12000 (26.7%)]\tLoss: 0.018600\n","Train Epoch: 27 [3840/12000 (32.0%)]\tLoss: 0.003655\n","Train Epoch: 27 [4480/12000 (37.3%)]\tLoss: 0.016667\n","Train Epoch: 27 [5120/12000 (42.7%)]\tLoss: 0.040601\n","Train Epoch: 27 [5760/12000 (48.0%)]\tLoss: 0.019985\n","Train Epoch: 27 [6400/12000 (53.3%)]\tLoss: 0.051322\n","Train Epoch: 27 [7040/12000 (58.7%)]\tLoss: 0.016579\n","Train Epoch: 27 [7680/12000 (64.0%)]\tLoss: 0.107655\n","Train Epoch: 27 [8320/12000 (69.3%)]\tLoss: 0.039721\n","Train Epoch: 27 [8960/12000 (74.7%)]\tLoss: 0.024318\n","Train Epoch: 27 [9600/12000 (80.0%)]\tLoss: 0.040465\n","Train Epoch: 27 [10240/12000 (85.3%)]\tLoss: 0.011091\n","Train Epoch: 27 [10880/12000 (90.7%)]\tLoss: 0.032819\n","Train Epoch: 27 [11520/12000 (96.0%)]\tLoss: 0.246273\n","\n","Test set: Average loss: 6.1126, Accuracy: 1232/8580 (14.00%), F1: 0.10\n","\n","Train Epoch: 28 [0/12000 (0.0%)]\tLoss: 0.093359\n","Train Epoch: 28 [640/12000 (5.3%)]\tLoss: 0.027133\n","Train Epoch: 28 [1280/12000 (10.7%)]\tLoss: 0.004330\n","Train Epoch: 28 [1920/12000 (16.0%)]\tLoss: 0.054429\n","Train Epoch: 28 [2560/12000 (21.3%)]\tLoss: 0.001849\n","Train Epoch: 28 [3200/12000 (26.7%)]\tLoss: 0.052557\n","Train Epoch: 28 [3840/12000 (32.0%)]\tLoss: 0.005376\n","Train Epoch: 28 [4480/12000 (37.3%)]\tLoss: 0.021782\n","Train Epoch: 28 [5120/12000 (42.7%)]\tLoss: 0.036647\n","Train Epoch: 28 [5760/12000 (48.0%)]\tLoss: 0.073358\n","Train Epoch: 28 [6400/12000 (53.3%)]\tLoss: 0.016662\n","Train Epoch: 28 [7040/12000 (58.7%)]\tLoss: 0.047063\n","Train Epoch: 28 [7680/12000 (64.0%)]\tLoss: 0.109641\n","Train Epoch: 28 [8320/12000 (69.3%)]\tLoss: 0.008532\n","Train Epoch: 28 [8960/12000 (74.7%)]\tLoss: 0.067026\n","Train Epoch: 28 [9600/12000 (80.0%)]\tLoss: 0.027243\n","Train Epoch: 28 [10240/12000 (85.3%)]\tLoss: 0.016324\n","Train Epoch: 28 [10880/12000 (90.7%)]\tLoss: 0.008503\n","Train Epoch: 28 [11520/12000 (96.0%)]\tLoss: 0.022583\n","\n","Test set: Average loss: 6.0881, Accuracy: 1299/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 29 [0/12000 (0.0%)]\tLoss: 0.018365\n","Train Epoch: 29 [640/12000 (5.3%)]\tLoss: 0.004434\n","Train Epoch: 29 [1280/12000 (10.7%)]\tLoss: 0.003503\n","Train Epoch: 29 [1920/12000 (16.0%)]\tLoss: 0.018447\n","Train Epoch: 29 [2560/12000 (21.3%)]\tLoss: 0.010903\n","Train Epoch: 29 [3200/12000 (26.7%)]\tLoss: 0.047180\n","Train Epoch: 29 [3840/12000 (32.0%)]\tLoss: 0.047653\n","Train Epoch: 29 [4480/12000 (37.3%)]\tLoss: 0.011613\n","Train Epoch: 29 [5120/12000 (42.7%)]\tLoss: 0.041309\n","Train Epoch: 29 [5760/12000 (48.0%)]\tLoss: 0.017109\n","Train Epoch: 29 [6400/12000 (53.3%)]\tLoss: 0.061199\n","Train Epoch: 29 [7040/12000 (58.7%)]\tLoss: 0.017028\n","Train Epoch: 29 [7680/12000 (64.0%)]\tLoss: 0.072458\n","Train Epoch: 29 [8320/12000 (69.3%)]\tLoss: 0.010738\n","Train Epoch: 29 [8960/12000 (74.7%)]\tLoss: 0.080282\n","Train Epoch: 29 [9600/12000 (80.0%)]\tLoss: 0.005149\n","Train Epoch: 29 [10240/12000 (85.3%)]\tLoss: 0.003030\n","Train Epoch: 29 [10880/12000 (90.7%)]\tLoss: 0.070989\n","Train Epoch: 29 [11520/12000 (96.0%)]\tLoss: 0.042879\n","\n","Test set: Average loss: 6.1687, Accuracy: 1270/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 30 [0/12000 (0.0%)]\tLoss: 0.059037\n","Train Epoch: 30 [640/12000 (5.3%)]\tLoss: 0.092227\n","Train Epoch: 30 [1280/12000 (10.7%)]\tLoss: 0.018134\n","Train Epoch: 30 [1920/12000 (16.0%)]\tLoss: 0.014270\n","Train Epoch: 30 [2560/12000 (21.3%)]\tLoss: 0.087921\n","Train Epoch: 30 [3200/12000 (26.7%)]\tLoss: 0.036866\n","Train Epoch: 30 [3840/12000 (32.0%)]\tLoss: 0.068709\n","Train Epoch: 30 [4480/12000 (37.3%)]\tLoss: 0.102358\n","Train Epoch: 30 [5120/12000 (42.7%)]\tLoss: 0.011030\n","Train Epoch: 30 [5760/12000 (48.0%)]\tLoss: 0.113231\n","Train Epoch: 30 [6400/12000 (53.3%)]\tLoss: 0.011506\n","Train Epoch: 30 [7040/12000 (58.7%)]\tLoss: 0.060214\n","Train Epoch: 30 [7680/12000 (64.0%)]\tLoss: 0.020987\n","Train Epoch: 30 [8320/12000 (69.3%)]\tLoss: 0.022146\n","Train Epoch: 30 [8960/12000 (74.7%)]\tLoss: 0.007343\n","Train Epoch: 30 [9600/12000 (80.0%)]\tLoss: 0.067344\n","Train Epoch: 30 [10240/12000 (85.3%)]\tLoss: 0.010579\n","Train Epoch: 30 [10880/12000 (90.7%)]\tLoss: 0.005825\n","Train Epoch: 30 [11520/12000 (96.0%)]\tLoss: 0.010889\n","\n","Test set: Average loss: 6.1272, Accuracy: 1283/8580 (14.00%), F1: 0.09\n","\n","Train Epoch: 31 [0/12000 (0.0%)]\tLoss: 0.025533\n","Train Epoch: 31 [640/12000 (5.3%)]\tLoss: 0.035407\n","Train Epoch: 31 [1280/12000 (10.7%)]\tLoss: 0.083020\n","Train Epoch: 31 [1920/12000 (16.0%)]\tLoss: 0.015601\n","Train Epoch: 31 [2560/12000 (21.3%)]\tLoss: 0.020935\n","Train Epoch: 31 [3200/12000 (26.7%)]\tLoss: 0.013830\n","Train Epoch: 31 [3840/12000 (32.0%)]\tLoss: 0.004820\n","Train Epoch: 31 [4480/12000 (37.3%)]\tLoss: 0.006423\n","Train Epoch: 31 [5120/12000 (42.7%)]\tLoss: 0.011365\n","Train Epoch: 31 [5760/12000 (48.0%)]\tLoss: 0.060084\n","Train Epoch: 31 [6400/12000 (53.3%)]\tLoss: 0.026947\n","Train Epoch: 31 [7040/12000 (58.7%)]\tLoss: 0.009637\n","Train Epoch: 31 [7680/12000 (64.0%)]\tLoss: 0.029639\n","Train Epoch: 31 [8320/12000 (69.3%)]\tLoss: 0.253167\n","Train Epoch: 31 [8960/12000 (74.7%)]\tLoss: 0.011828\n","Train Epoch: 31 [9600/12000 (80.0%)]\tLoss: 0.006271\n","Train Epoch: 31 [10240/12000 (85.3%)]\tLoss: 0.028415\n","Train Epoch: 31 [10880/12000 (90.7%)]\tLoss: 0.054729\n","Train Epoch: 31 [11520/12000 (96.0%)]\tLoss: 0.045784\n","\n","Test set: Average loss: 6.0872, Accuracy: 1269/8580 (14.00%), F1: 0.11\n","\n","Train Epoch: 32 [0/12000 (0.0%)]\tLoss: 0.021662\n","Train Epoch: 32 [640/12000 (5.3%)]\tLoss: 0.019702\n","Train Epoch: 32 [1280/12000 (10.7%)]\tLoss: 0.038048\n","Train Epoch: 32 [1920/12000 (16.0%)]\tLoss: 0.001727\n","Train Epoch: 32 [2560/12000 (21.3%)]\tLoss: 0.007558\n","Train Epoch: 32 [3200/12000 (26.7%)]\tLoss: 0.011208\n","Train Epoch: 32 [3840/12000 (32.0%)]\tLoss: 0.046918\n","Train Epoch: 32 [4480/12000 (37.3%)]\tLoss: 0.013041\n","Train Epoch: 32 [5120/12000 (42.7%)]\tLoss: 0.005130\n","Train Epoch: 32 [5760/12000 (48.0%)]\tLoss: 0.008232\n","Train Epoch: 32 [6400/12000 (53.3%)]\tLoss: 0.012971\n","Train Epoch: 32 [7040/12000 (58.7%)]\tLoss: 0.050218\n","Train Epoch: 32 [7680/12000 (64.0%)]\tLoss: 0.016367\n","Train Epoch: 32 [8320/12000 (69.3%)]\tLoss: 0.031436\n","Train Epoch: 32 [8960/12000 (74.7%)]\tLoss: 0.017761\n","Train Epoch: 32 [9600/12000 (80.0%)]\tLoss: 0.011829\n","Train Epoch: 32 [10240/12000 (85.3%)]\tLoss: 0.002660\n","Train Epoch: 32 [10880/12000 (90.7%)]\tLoss: 0.014933\n","Train Epoch: 32 [11520/12000 (96.0%)]\tLoss: 0.019859\n","\n","Test set: Average loss: 6.0960, Accuracy: 1291/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 33 [0/12000 (0.0%)]\tLoss: 0.011074\n","Train Epoch: 33 [640/12000 (5.3%)]\tLoss: 0.003364\n","Train Epoch: 33 [1280/12000 (10.7%)]\tLoss: 0.004035\n","Train Epoch: 33 [1920/12000 (16.0%)]\tLoss: 0.055237\n","Train Epoch: 33 [2560/12000 (21.3%)]\tLoss: 0.011582\n","Train Epoch: 33 [3200/12000 (26.7%)]\tLoss: 0.007726\n","Train Epoch: 33 [3840/12000 (32.0%)]\tLoss: 0.013596\n","Train Epoch: 33 [4480/12000 (37.3%)]\tLoss: 0.065850\n","Train Epoch: 33 [5120/12000 (42.7%)]\tLoss: 0.051615\n","Train Epoch: 33 [5760/12000 (48.0%)]\tLoss: 0.010589\n","Train Epoch: 33 [6400/12000 (53.3%)]\tLoss: 0.029296\n","Train Epoch: 33 [7040/12000 (58.7%)]\tLoss: 0.026366\n","Train Epoch: 33 [7680/12000 (64.0%)]\tLoss: 0.024554\n","Train Epoch: 33 [8320/12000 (69.3%)]\tLoss: 0.049320\n","Train Epoch: 33 [8960/12000 (74.7%)]\tLoss: 0.005793\n","Train Epoch: 33 [9600/12000 (80.0%)]\tLoss: 0.002466\n","Train Epoch: 33 [10240/12000 (85.3%)]\tLoss: 0.016075\n","Train Epoch: 33 [10880/12000 (90.7%)]\tLoss: 0.025559\n","Train Epoch: 33 [11520/12000 (96.0%)]\tLoss: 0.005808\n","\n","Test set: Average loss: 6.0643, Accuracy: 1296/8580 (15.00%), F1: 0.13\n","\n","Train Epoch: 34 [0/12000 (0.0%)]\tLoss: 0.031357\n","Train Epoch: 34 [640/12000 (5.3%)]\tLoss: 0.009162\n","Train Epoch: 34 [1280/12000 (10.7%)]\tLoss: 0.074077\n","Train Epoch: 34 [1920/12000 (16.0%)]\tLoss: 0.012373\n","Train Epoch: 34 [2560/12000 (21.3%)]\tLoss: 0.005840\n","Train Epoch: 34 [3200/12000 (26.7%)]\tLoss: 0.002965\n","Train Epoch: 34 [3840/12000 (32.0%)]\tLoss: 0.041135\n","Train Epoch: 34 [4480/12000 (37.3%)]\tLoss: 0.027659\n","Train Epoch: 34 [5120/12000 (42.7%)]\tLoss: 0.012407\n","Train Epoch: 34 [5760/12000 (48.0%)]\tLoss: 0.004069\n","Train Epoch: 34 [6400/12000 (53.3%)]\tLoss: 0.015491\n","Train Epoch: 34 [7040/12000 (58.7%)]\tLoss: 0.028498\n","Train Epoch: 34 [7680/12000 (64.0%)]\tLoss: 0.007470\n","Train Epoch: 34 [8320/12000 (69.3%)]\tLoss: 0.003329\n","Train Epoch: 34 [8960/12000 (74.7%)]\tLoss: 0.003878\n","Train Epoch: 34 [9600/12000 (80.0%)]\tLoss: 0.040701\n","Train Epoch: 34 [10240/12000 (85.3%)]\tLoss: 0.044994\n","Train Epoch: 34 [10880/12000 (90.7%)]\tLoss: 0.013433\n","Train Epoch: 34 [11520/12000 (96.0%)]\tLoss: 0.014807\n","\n","Test set: Average loss: 6.0907, Accuracy: 1288/8580 (15.00%), F1: 0.09\n","\n","Train Epoch: 35 [0/12000 (0.0%)]\tLoss: 0.010033\n","Train Epoch: 35 [640/12000 (5.3%)]\tLoss: 0.007347\n","Train Epoch: 35 [1280/12000 (10.7%)]\tLoss: 0.007885\n","Train Epoch: 35 [1920/12000 (16.0%)]\tLoss: 0.055499\n","Train Epoch: 35 [2560/12000 (21.3%)]\tLoss: 0.019941\n","Train Epoch: 35 [3200/12000 (26.7%)]\tLoss: 0.015043\n","Train Epoch: 35 [3840/12000 (32.0%)]\tLoss: 0.001948\n","Train Epoch: 35 [4480/12000 (37.3%)]\tLoss: 0.043497\n","Train Epoch: 35 [5120/12000 (42.7%)]\tLoss: 0.066057\n","Train Epoch: 35 [5760/12000 (48.0%)]\tLoss: 0.006549\n","Train Epoch: 35 [6400/12000 (53.3%)]\tLoss: 0.019272\n","Train Epoch: 35 [7040/12000 (58.7%)]\tLoss: 0.009298\n","Train Epoch: 35 [7680/12000 (64.0%)]\tLoss: 0.012274\n","Train Epoch: 35 [8320/12000 (69.3%)]\tLoss: 0.019099\n","Train Epoch: 35 [8960/12000 (74.7%)]\tLoss: 0.002387\n","Train Epoch: 35 [9600/12000 (80.0%)]\tLoss: 0.012651\n","Train Epoch: 35 [10240/12000 (85.3%)]\tLoss: 0.021306\n","Train Epoch: 35 [10880/12000 (90.7%)]\tLoss: 0.010559\n","Train Epoch: 35 [11520/12000 (96.0%)]\tLoss: 0.003705\n","\n","Test set: Average loss: 6.0865, Accuracy: 1287/8580 (15.00%), F1: 0.11\n","\n","Train Epoch: 36 [0/12000 (0.0%)]\tLoss: 0.013442\n","Train Epoch: 36 [640/12000 (5.3%)]\tLoss: 0.123169\n","Train Epoch: 36 [1280/12000 (10.7%)]\tLoss: 0.031568\n","Train Epoch: 36 [1920/12000 (16.0%)]\tLoss: 0.125733\n","Train Epoch: 36 [2560/12000 (21.3%)]\tLoss: 0.002916\n","Train Epoch: 36 [3200/12000 (26.7%)]\tLoss: 0.053350\n","Train Epoch: 36 [3840/12000 (32.0%)]\tLoss: 0.009854\n","Train Epoch: 36 [4480/12000 (37.3%)]\tLoss: 0.018686\n","Train Epoch: 36 [5120/12000 (42.7%)]\tLoss: 0.003936\n","Train Epoch: 36 [5760/12000 (48.0%)]\tLoss: 0.025654\n","Train Epoch: 36 [6400/12000 (53.3%)]\tLoss: 0.062181\n","Train Epoch: 36 [7040/12000 (58.7%)]\tLoss: 0.035204\n","Train Epoch: 36 [7680/12000 (64.0%)]\tLoss: 0.008130\n","Train Epoch: 36 [8320/12000 (69.3%)]\tLoss: 0.023770\n","Train Epoch: 36 [8960/12000 (74.7%)]\tLoss: 0.011083\n","Train Epoch: 36 [9600/12000 (80.0%)]\tLoss: 0.009290\n","Train Epoch: 36 [10240/12000 (85.3%)]\tLoss: 0.015057\n","Train Epoch: 36 [10880/12000 (90.7%)]\tLoss: 0.077152\n","Train Epoch: 36 [11520/12000 (96.0%)]\tLoss: 0.022528\n","\n","Test set: Average loss: 6.1415, Accuracy: 1273/8580 (14.00%), F1: 0.13\n","\n","Train Epoch: 37 [0/12000 (0.0%)]\tLoss: 0.091976\n","Train Epoch: 37 [640/12000 (5.3%)]\tLoss: 0.001289\n","Train Epoch: 37 [1280/12000 (10.7%)]\tLoss: 0.052978\n","Train Epoch: 37 [1920/12000 (16.0%)]\tLoss: 0.023585\n","Train Epoch: 37 [2560/12000 (21.3%)]\tLoss: 0.010682\n","Train Epoch: 37 [3200/12000 (26.7%)]\tLoss: 0.082123\n","Train Epoch: 37 [3840/12000 (32.0%)]\tLoss: 0.037041\n","Train Epoch: 37 [4480/12000 (37.3%)]\tLoss: 0.015341\n","Train Epoch: 37 [5120/12000 (42.7%)]\tLoss: 0.021090\n","Train Epoch: 37 [5760/12000 (48.0%)]\tLoss: 0.020887\n","Train Epoch: 37 [6400/12000 (53.3%)]\tLoss: 0.061316\n","Train Epoch: 37 [7040/12000 (58.7%)]\tLoss: 0.035647\n","Train Epoch: 37 [7680/12000 (64.0%)]\tLoss: 0.048935\n","Train Epoch: 37 [8320/12000 (69.3%)]\tLoss: 0.004647\n","Train Epoch: 37 [8960/12000 (74.7%)]\tLoss: 0.030268\n","Train Epoch: 37 [9600/12000 (80.0%)]\tLoss: 0.153772\n","Train Epoch: 37 [10240/12000 (85.3%)]\tLoss: 0.005507\n","Train Epoch: 37 [10880/12000 (90.7%)]\tLoss: 0.029295\n","Train Epoch: 37 [11520/12000 (96.0%)]\tLoss: 0.005327\n","\n","Test set: Average loss: 6.1561, Accuracy: 1289/8580 (15.00%), F1: 0.12\n","\n","Train Epoch: 38 [0/12000 (0.0%)]\tLoss: 0.054244\n","Train Epoch: 38 [640/12000 (5.3%)]\tLoss: 0.016437\n","Train Epoch: 38 [1280/12000 (10.7%)]\tLoss: 0.042604\n","Train Epoch: 38 [1920/12000 (16.0%)]\tLoss: 0.031204\n","Train Epoch: 38 [2560/12000 (21.3%)]\tLoss: 0.105845\n","Train Epoch: 38 [3200/12000 (26.7%)]\tLoss: 0.005233\n","Train Epoch: 38 [3840/12000 (32.0%)]\tLoss: 0.007887\n","Train Epoch: 38 [4480/12000 (37.3%)]\tLoss: 0.103805\n","Train Epoch: 38 [5120/12000 (42.7%)]\tLoss: 0.006037\n","Train Epoch: 38 [5760/12000 (48.0%)]\tLoss: 0.041775\n","Train Epoch: 38 [6400/12000 (53.3%)]\tLoss: 0.001655\n","Train Epoch: 38 [7040/12000 (58.7%)]\tLoss: 0.035483\n","Train Epoch: 38 [7680/12000 (64.0%)]\tLoss: 0.070671\n","Train Epoch: 38 [8320/12000 (69.3%)]\tLoss: 0.006790\n","Train Epoch: 38 [8960/12000 (74.7%)]\tLoss: 0.060947\n","Train Epoch: 38 [9600/12000 (80.0%)]\tLoss: 0.060743\n","Train Epoch: 38 [10240/12000 (85.3%)]\tLoss: 0.009820\n","Train Epoch: 38 [10880/12000 (90.7%)]\tLoss: 0.002996\n","Train Epoch: 38 [11520/12000 (96.0%)]\tLoss: 0.030215\n","\n","Test set: Average loss: 6.1736, Accuracy: 1291/8580 (15.00%), F1: 0.15\n","\n","Train Epoch: 39 [0/12000 (0.0%)]\tLoss: 0.036864\n","Train Epoch: 39 [640/12000 (5.3%)]\tLoss: 0.010654\n","Train Epoch: 39 [1280/12000 (10.7%)]\tLoss: 0.071740\n","Train Epoch: 39 [1920/12000 (16.0%)]\tLoss: 0.006910\n","Train Epoch: 39 [2560/12000 (21.3%)]\tLoss: 0.026170\n","Train Epoch: 39 [3200/12000 (26.7%)]\tLoss: 0.005587\n","Train Epoch: 39 [3840/12000 (32.0%)]\tLoss: 0.011077\n","Train Epoch: 39 [4480/12000 (37.3%)]\tLoss: 0.010635\n","Train Epoch: 39 [5120/12000 (42.7%)]\tLoss: 0.108474\n","Train Epoch: 39 [5760/12000 (48.0%)]\tLoss: 0.005822\n","Train Epoch: 39 [6400/12000 (53.3%)]\tLoss: 0.068571\n","Train Epoch: 39 [7040/12000 (58.7%)]\tLoss: 0.020428\n","Train Epoch: 39 [7680/12000 (64.0%)]\tLoss: 0.033938\n","Train Epoch: 39 [8320/12000 (69.3%)]\tLoss: 0.015808\n","Train Epoch: 39 [8960/12000 (74.7%)]\tLoss: 0.026937\n","Train Epoch: 39 [9600/12000 (80.0%)]\tLoss: 0.009020\n","Train Epoch: 39 [10240/12000 (85.3%)]\tLoss: 0.008912\n","Train Epoch: 39 [10880/12000 (90.7%)]\tLoss: 0.010078\n","Train Epoch: 39 [11520/12000 (96.0%)]\tLoss: 0.021527\n","\n","Test set: Average loss: 6.0537, Accuracy: 1260/8580 (14.00%), F1: 0.11\n","\n","[INFO] Method:  scratchE\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/scratchE/modelA500_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new trasfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.838215\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.523954\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.988637\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 5.079625\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.728930\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.705261\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.357798\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.708573\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.340662\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.482130\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.445547\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 4.492495\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.328741\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 4.065875\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.123610\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.324297\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.222260\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.208129\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 3.890881\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","\n","Test set: Average loss: 4.1672, Accuracy: 646/8580 (7.00%), F1: 0.05\n","\n","Train Epoch: 1 [0/12000 (0.0%)]\tLoss: 4.082260\n","Train Epoch: 1 [640/12000 (5.3%)]\tLoss: 3.934776\n","Train Epoch: 1 [1280/12000 (10.7%)]\tLoss: 3.752941\n","Train Epoch: 1 [1920/12000 (16.0%)]\tLoss: 3.804335\n","Train Epoch: 1 [2560/12000 (21.3%)]\tLoss: 4.077505\n","Train Epoch: 1 [3200/12000 (26.7%)]\tLoss: 4.127241\n","Train Epoch: 1 [3840/12000 (32.0%)]\tLoss: 3.868355\n","Train Epoch: 1 [4480/12000 (37.3%)]\tLoss: 4.334706\n","Train Epoch: 1 [5120/12000 (42.7%)]\tLoss: 4.050394\n","Train Epoch: 1 [5760/12000 (48.0%)]\tLoss: 3.928042\n","Train Epoch: 1 [6400/12000 (53.3%)]\tLoss: 4.147878\n","Train Epoch: 1 [7040/12000 (58.7%)]\tLoss: 4.145665\n","Train Epoch: 1 [7680/12000 (64.0%)]\tLoss: 4.015904\n","Train Epoch: 1 [8320/12000 (69.3%)]\tLoss: 3.937772\n","Train Epoch: 1 [8960/12000 (74.7%)]\tLoss: 4.040449\n","Train Epoch: 1 [9600/12000 (80.0%)]\tLoss: 3.841176\n","Train Epoch: 1 [10240/12000 (85.3%)]\tLoss: 3.983212\n","Train Epoch: 1 [10880/12000 (90.7%)]\tLoss: 4.123879\n","Train Epoch: 1 [11520/12000 (96.0%)]\tLoss: 4.047446\n","\n","Test set: Average loss: 3.9977, Accuracy: 771/8580 (8.00%), F1: 0.08\n","\n","Train Epoch: 2 [0/12000 (0.0%)]\tLoss: 3.861224\n","Train Epoch: 2 [640/12000 (5.3%)]\tLoss: 3.508662\n","Train Epoch: 2 [1280/12000 (10.7%)]\tLoss: 3.248765\n","Train Epoch: 2 [1920/12000 (16.0%)]\tLoss: 4.092702\n","Train Epoch: 2 [2560/12000 (21.3%)]\tLoss: 3.603029\n","Train Epoch: 2 [3200/12000 (26.7%)]\tLoss: 3.702490\n","Train Epoch: 2 [3840/12000 (32.0%)]\tLoss: 3.825881\n","Train Epoch: 2 [4480/12000 (37.3%)]\tLoss: 3.958091\n","Train Epoch: 2 [5120/12000 (42.7%)]\tLoss: 3.559798\n","Train Epoch: 2 [5760/12000 (48.0%)]\tLoss: 3.700421\n","Train Epoch: 2 [6400/12000 (53.3%)]\tLoss: 3.898786\n","Train Epoch: 2 [7040/12000 (58.7%)]\tLoss: 3.872562\n","Train Epoch: 2 [7680/12000 (64.0%)]\tLoss: 3.921809\n","Train Epoch: 2 [8320/12000 (69.3%)]\tLoss: 3.428622\n","Train Epoch: 2 [8960/12000 (74.7%)]\tLoss: 3.569828\n","Train Epoch: 2 [9600/12000 (80.0%)]\tLoss: 3.641808\n","Train Epoch: 2 [10240/12000 (85.3%)]\tLoss: 3.662676\n","Train Epoch: 2 [10880/12000 (90.7%)]\tLoss: 3.734256\n","Train Epoch: 2 [11520/12000 (96.0%)]\tLoss: 3.842074\n","\n","Test set: Average loss: 3.8768, Accuracy: 898/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 3 [0/12000 (0.0%)]\tLoss: 3.091735\n","Train Epoch: 3 [640/12000 (5.3%)]\tLoss: 3.255462\n","Train Epoch: 3 [1280/12000 (10.7%)]\tLoss: 3.134516\n","Train Epoch: 3 [1920/12000 (16.0%)]\tLoss: 3.049857\n","Train Epoch: 3 [2560/12000 (21.3%)]\tLoss: 3.616545\n","Train Epoch: 3 [3200/12000 (26.7%)]\tLoss: 3.345688\n","Train Epoch: 3 [3840/12000 (32.0%)]\tLoss: 2.904064\n","Train Epoch: 3 [4480/12000 (37.3%)]\tLoss: 3.708904\n","Train Epoch: 3 [5120/12000 (42.7%)]\tLoss: 3.676569\n","Train Epoch: 3 [5760/12000 (48.0%)]\tLoss: 2.955998\n","Train Epoch: 3 [6400/12000 (53.3%)]\tLoss: 3.663093\n","Train Epoch: 3 [7040/12000 (58.7%)]\tLoss: 3.326687\n","Train Epoch: 3 [7680/12000 (64.0%)]\tLoss: 3.278756\n","Train Epoch: 3 [8320/12000 (69.3%)]\tLoss: 3.345348\n","Train Epoch: 3 [8960/12000 (74.7%)]\tLoss: 3.713297\n","Train Epoch: 3 [9600/12000 (80.0%)]\tLoss: 3.515210\n","Train Epoch: 3 [10240/12000 (85.3%)]\tLoss: 3.518625\n","Train Epoch: 3 [10880/12000 (90.7%)]\tLoss: 3.419125\n","Train Epoch: 3 [11520/12000 (96.0%)]\tLoss: 3.407539\n","\n","Test set: Average loss: 3.9391, Accuracy: 959/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 4 [0/12000 (0.0%)]\tLoss: 2.704507\n","Train Epoch: 4 [640/12000 (5.3%)]\tLoss: 3.079609\n","Train Epoch: 4 [1280/12000 (10.7%)]\tLoss: 3.299051\n","Train Epoch: 4 [1920/12000 (16.0%)]\tLoss: 2.538142\n","Train Epoch: 4 [2560/12000 (21.3%)]\tLoss: 3.144367\n","Train Epoch: 4 [3200/12000 (26.7%)]\tLoss: 2.957622\n","Train Epoch: 4 [3840/12000 (32.0%)]\tLoss: 3.354344\n","Train Epoch: 4 [4480/12000 (37.3%)]\tLoss: 2.806453\n","Train Epoch: 4 [5120/12000 (42.7%)]\tLoss: 3.338472\n","Train Epoch: 4 [5760/12000 (48.0%)]\tLoss: 3.270961\n","Train Epoch: 4 [6400/12000 (53.3%)]\tLoss: 3.607124\n","Train Epoch: 4 [7040/12000 (58.7%)]\tLoss: 2.775383\n","Train Epoch: 4 [7680/12000 (64.0%)]\tLoss: 2.911388\n","Train Epoch: 4 [8320/12000 (69.3%)]\tLoss: 2.943121\n","Train Epoch: 4 [8960/12000 (74.7%)]\tLoss: 3.339554\n","Train Epoch: 4 [9600/12000 (80.0%)]\tLoss: 3.336347\n","Train Epoch: 4 [10240/12000 (85.3%)]\tLoss: 2.911235\n","Train Epoch: 4 [10880/12000 (90.7%)]\tLoss: 3.289722\n","Train Epoch: 4 [11520/12000 (96.0%)]\tLoss: 3.237891\n","\n","Test set: Average loss: 4.0073, Accuracy: 953/8580 (11.00%), F1: 0.05\n","\n","Train Epoch: 5 [0/12000 (0.0%)]\tLoss: 2.331459\n","Train Epoch: 5 [640/12000 (5.3%)]\tLoss: 2.341927\n","Train Epoch: 5 [1280/12000 (10.7%)]\tLoss: 2.950955\n","Train Epoch: 5 [1920/12000 (16.0%)]\tLoss: 2.651316\n","Train Epoch: 5 [2560/12000 (21.3%)]\tLoss: 2.562518\n","Train Epoch: 5 [3200/12000 (26.7%)]\tLoss: 3.010924\n","Train Epoch: 5 [3840/12000 (32.0%)]\tLoss: 2.605490\n","Train Epoch: 5 [4480/12000 (37.3%)]\tLoss: 2.708563\n","Train Epoch: 5 [5120/12000 (42.7%)]\tLoss: 2.837600\n","Train Epoch: 5 [5760/12000 (48.0%)]\tLoss: 2.169113\n","Train Epoch: 5 [6400/12000 (53.3%)]\tLoss: 2.923596\n","Train Epoch: 5 [7040/12000 (58.7%)]\tLoss: 2.543212\n","Train Epoch: 5 [7680/12000 (64.0%)]\tLoss: 2.489563\n","Train Epoch: 5 [8320/12000 (69.3%)]\tLoss: 3.549547\n","Train Epoch: 5 [8960/12000 (74.7%)]\tLoss: 2.978942\n","Train Epoch: 5 [9600/12000 (80.0%)]\tLoss: 2.662080\n","Train Epoch: 5 [10240/12000 (85.3%)]\tLoss: 2.984629\n","Train Epoch: 5 [10880/12000 (90.7%)]\tLoss: 3.051358\n","Train Epoch: 5 [11520/12000 (96.0%)]\tLoss: 2.919198\n","\n","Test set: Average loss: 4.1765, Accuracy: 973/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 6 [0/12000 (0.0%)]\tLoss: 2.504475\n","Train Epoch: 6 [640/12000 (5.3%)]\tLoss: 2.365691\n","Train Epoch: 6 [1280/12000 (10.7%)]\tLoss: 2.645247\n","Train Epoch: 6 [1920/12000 (16.0%)]\tLoss: 2.198176\n","Train Epoch: 6 [2560/12000 (21.3%)]\tLoss: 2.675375\n","Train Epoch: 6 [3200/12000 (26.7%)]\tLoss: 2.509138\n","Train Epoch: 6 [3840/12000 (32.0%)]\tLoss: 2.585006\n","Train Epoch: 6 [4480/12000 (37.3%)]\tLoss: 2.594194\n","Train Epoch: 6 [5120/12000 (42.7%)]\tLoss: 2.289321\n","Train Epoch: 6 [5760/12000 (48.0%)]\tLoss: 2.721001\n","Train Epoch: 6 [6400/12000 (53.3%)]\tLoss: 2.251022\n","Train Epoch: 6 [7040/12000 (58.7%)]\tLoss: 2.463446\n","Train Epoch: 6 [7680/12000 (64.0%)]\tLoss: 2.861502\n","Train Epoch: 6 [8320/12000 (69.3%)]\tLoss: 2.892190\n","Train Epoch: 6 [8960/12000 (74.7%)]\tLoss: 2.383687\n","Train Epoch: 6 [9600/12000 (80.0%)]\tLoss: 2.684537\n","Train Epoch: 6 [10240/12000 (85.3%)]\tLoss: 3.077240\n","Train Epoch: 6 [10880/12000 (90.7%)]\tLoss: 3.007514\n","Train Epoch: 6 [11520/12000 (96.0%)]\tLoss: 2.879052\n","\n","Test set: Average loss: 4.3056, Accuracy: 1027/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 7 [0/12000 (0.0%)]\tLoss: 1.980910\n","Train Epoch: 7 [640/12000 (5.3%)]\tLoss: 2.586321\n","Train Epoch: 7 [1280/12000 (10.7%)]\tLoss: 1.655172\n","Train Epoch: 7 [1920/12000 (16.0%)]\tLoss: 2.263050\n","Train Epoch: 7 [2560/12000 (21.3%)]\tLoss: 2.583041\n","Train Epoch: 7 [3200/12000 (26.7%)]\tLoss: 1.597534\n","Train Epoch: 7 [3840/12000 (32.0%)]\tLoss: 2.408349\n","Train Epoch: 7 [4480/12000 (37.3%)]\tLoss: 2.826995\n","Train Epoch: 7 [5120/12000 (42.7%)]\tLoss: 2.235647\n","Train Epoch: 7 [5760/12000 (48.0%)]\tLoss: 2.117180\n","Train Epoch: 7 [6400/12000 (53.3%)]\tLoss: 2.163368\n","Train Epoch: 7 [7040/12000 (58.7%)]\tLoss: 2.544743\n","Train Epoch: 7 [7680/12000 (64.0%)]\tLoss: 2.252189\n","Train Epoch: 7 [8320/12000 (69.3%)]\tLoss: 2.816339\n","Train Epoch: 7 [8960/12000 (74.7%)]\tLoss: 2.125484\n","Train Epoch: 7 [9600/12000 (80.0%)]\tLoss: 1.982895\n","Train Epoch: 7 [10240/12000 (85.3%)]\tLoss: 3.169270\n","Train Epoch: 7 [10880/12000 (90.7%)]\tLoss: 2.701613\n","Train Epoch: 7 [11520/12000 (96.0%)]\tLoss: 2.210361\n","\n","Test set: Average loss: 4.4197, Accuracy: 980/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 8 [0/12000 (0.0%)]\tLoss: 1.499493\n","Train Epoch: 8 [640/12000 (5.3%)]\tLoss: 2.133311\n","Train Epoch: 8 [1280/12000 (10.7%)]\tLoss: 2.300357\n","Train Epoch: 8 [1920/12000 (16.0%)]\tLoss: 1.568982\n","Train Epoch: 8 [2560/12000 (21.3%)]\tLoss: 2.140570\n","Train Epoch: 8 [3200/12000 (26.7%)]\tLoss: 1.496450\n","Train Epoch: 8 [3840/12000 (32.0%)]\tLoss: 2.135802\n","Train Epoch: 8 [4480/12000 (37.3%)]\tLoss: 1.898198\n","Train Epoch: 8 [5120/12000 (42.7%)]\tLoss: 2.827038\n","Train Epoch: 8 [5760/12000 (48.0%)]\tLoss: 1.932295\n","Train Epoch: 8 [6400/12000 (53.3%)]\tLoss: 1.752184\n","Train Epoch: 8 [7040/12000 (58.7%)]\tLoss: 1.678251\n","Train Epoch: 8 [7680/12000 (64.0%)]\tLoss: 2.031315\n","Train Epoch: 8 [8320/12000 (69.3%)]\tLoss: 2.443337\n","Train Epoch: 8 [8960/12000 (74.7%)]\tLoss: 2.479793\n","Train Epoch: 8 [9600/12000 (80.0%)]\tLoss: 1.941930\n","Train Epoch: 8 [10240/12000 (85.3%)]\tLoss: 3.162802\n","Train Epoch: 8 [10880/12000 (90.7%)]\tLoss: 1.613390\n","Train Epoch: 8 [11520/12000 (96.0%)]\tLoss: 1.860137\n","\n","Test set: Average loss: 4.6263, Accuracy: 1016/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 9 [0/12000 (0.0%)]\tLoss: 2.035464\n","Train Epoch: 9 [640/12000 (5.3%)]\tLoss: 1.351393\n","Train Epoch: 9 [1280/12000 (10.7%)]\tLoss: 1.519511\n","Train Epoch: 9 [1920/12000 (16.0%)]\tLoss: 1.615840\n","Train Epoch: 9 [2560/12000 (21.3%)]\tLoss: 0.974937\n","Train Epoch: 9 [3200/12000 (26.7%)]\tLoss: 1.505881\n","Train Epoch: 9 [3840/12000 (32.0%)]\tLoss: 1.745612\n","Train Epoch: 9 [4480/12000 (37.3%)]\tLoss: 2.462193\n","Train Epoch: 9 [5120/12000 (42.7%)]\tLoss: 1.822529\n","Train Epoch: 9 [5760/12000 (48.0%)]\tLoss: 2.283356\n","Train Epoch: 9 [6400/12000 (53.3%)]\tLoss: 1.611489\n","Train Epoch: 9 [7040/12000 (58.7%)]\tLoss: 1.473774\n","Train Epoch: 9 [7680/12000 (64.0%)]\tLoss: 2.201932\n","Train Epoch: 9 [8320/12000 (69.3%)]\tLoss: 2.052193\n","Train Epoch: 9 [8960/12000 (74.7%)]\tLoss: 1.805202\n","Train Epoch: 9 [9600/12000 (80.0%)]\tLoss: 1.874088\n","Train Epoch: 9 [10240/12000 (85.3%)]\tLoss: 1.763397\n","Train Epoch: 9 [10880/12000 (90.7%)]\tLoss: 1.899304\n","Train Epoch: 9 [11520/12000 (96.0%)]\tLoss: 2.080879\n","\n","Test set: Average loss: 4.7617, Accuracy: 969/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 10 [0/12000 (0.0%)]\tLoss: 0.960442\n","Train Epoch: 10 [640/12000 (5.3%)]\tLoss: 1.923311\n","Train Epoch: 10 [1280/12000 (10.7%)]\tLoss: 1.111750\n","Train Epoch: 10 [1920/12000 (16.0%)]\tLoss: 1.227984\n","Train Epoch: 10 [2560/12000 (21.3%)]\tLoss: 1.608819\n","Train Epoch: 10 [3200/12000 (26.7%)]\tLoss: 1.043840\n","Train Epoch: 10 [3840/12000 (32.0%)]\tLoss: 1.379601\n","Train Epoch: 10 [4480/12000 (37.3%)]\tLoss: 1.721928\n","Train Epoch: 10 [5120/12000 (42.7%)]\tLoss: 1.452094\n","Train Epoch: 10 [5760/12000 (48.0%)]\tLoss: 1.354947\n","Train Epoch: 10 [6400/12000 (53.3%)]\tLoss: 1.701468\n","Train Epoch: 10 [7040/12000 (58.7%)]\tLoss: 1.948701\n","Train Epoch: 10 [7680/12000 (64.0%)]\tLoss: 1.607500\n","Train Epoch: 10 [8320/12000 (69.3%)]\tLoss: 1.761308\n","Train Epoch: 10 [8960/12000 (74.7%)]\tLoss: 1.592795\n","Train Epoch: 10 [9600/12000 (80.0%)]\tLoss: 1.919116\n","Train Epoch: 10 [10240/12000 (85.3%)]\tLoss: 2.207605\n","Train Epoch: 10 [10880/12000 (90.7%)]\tLoss: 1.486151\n","Train Epoch: 10 [11520/12000 (96.0%)]\tLoss: 1.799092\n","\n","Test set: Average loss: 5.0386, Accuracy: 1010/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 11 [0/12000 (0.0%)]\tLoss: 1.063663\n","Train Epoch: 11 [640/12000 (5.3%)]\tLoss: 1.208930\n","Train Epoch: 11 [1280/12000 (10.7%)]\tLoss: 0.633389\n","Train Epoch: 11 [1920/12000 (16.0%)]\tLoss: 1.220616\n","Train Epoch: 11 [2560/12000 (21.3%)]\tLoss: 1.121749\n","Train Epoch: 11 [3200/12000 (26.7%)]\tLoss: 1.874880\n","Train Epoch: 11 [3840/12000 (32.0%)]\tLoss: 0.786180\n","Train Epoch: 11 [4480/12000 (37.3%)]\tLoss: 1.340230\n","Train Epoch: 11 [5120/12000 (42.7%)]\tLoss: 1.631349\n","Train Epoch: 11 [5760/12000 (48.0%)]\tLoss: 1.297748\n","Train Epoch: 11 [6400/12000 (53.3%)]\tLoss: 1.867763\n","Train Epoch: 11 [7040/12000 (58.7%)]\tLoss: 1.744521\n","Train Epoch: 11 [7680/12000 (64.0%)]\tLoss: 2.465435\n","Train Epoch: 11 [8320/12000 (69.3%)]\tLoss: 1.357741\n","Train Epoch: 11 [8960/12000 (74.7%)]\tLoss: 1.100986\n","Train Epoch: 11 [9600/12000 (80.0%)]\tLoss: 1.201949\n","Train Epoch: 11 [10240/12000 (85.3%)]\tLoss: 1.471942\n","Train Epoch: 11 [10880/12000 (90.7%)]\tLoss: 1.345231\n","Train Epoch: 11 [11520/12000 (96.0%)]\tLoss: 2.028378\n","\n","Test set: Average loss: 5.2827, Accuracy: 935/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 12 [0/12000 (0.0%)]\tLoss: 1.355524\n","Train Epoch: 12 [640/12000 (5.3%)]\tLoss: 1.470757\n","Train Epoch: 12 [1280/12000 (10.7%)]\tLoss: 1.485551\n","Train Epoch: 12 [1920/12000 (16.0%)]\tLoss: 1.345050\n","Train Epoch: 12 [2560/12000 (21.3%)]\tLoss: 0.711447\n","Train Epoch: 12 [3200/12000 (26.7%)]\tLoss: 0.941484\n","Train Epoch: 12 [3840/12000 (32.0%)]\tLoss: 1.034929\n","Train Epoch: 12 [4480/12000 (37.3%)]\tLoss: 1.908020\n","Train Epoch: 12 [5120/12000 (42.7%)]\tLoss: 2.178956\n","Train Epoch: 12 [5760/12000 (48.0%)]\tLoss: 1.859366\n","Train Epoch: 12 [6400/12000 (53.3%)]\tLoss: 1.085545\n","Train Epoch: 12 [7040/12000 (58.7%)]\tLoss: 0.894252\n","Train Epoch: 12 [7680/12000 (64.0%)]\tLoss: 1.015431\n","Train Epoch: 12 [8320/12000 (69.3%)]\tLoss: 1.632956\n","Train Epoch: 12 [8960/12000 (74.7%)]\tLoss: 1.369966\n","Train Epoch: 12 [9600/12000 (80.0%)]\tLoss: 1.285294\n","Train Epoch: 12 [10240/12000 (85.3%)]\tLoss: 1.168180\n","Train Epoch: 12 [10880/12000 (90.7%)]\tLoss: 1.534547\n","Train Epoch: 12 [11520/12000 (96.0%)]\tLoss: 1.779484\n","\n","Test set: Average loss: 5.3985, Accuracy: 924/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 13 [0/12000 (0.0%)]\tLoss: 1.573284\n","Train Epoch: 13 [640/12000 (5.3%)]\tLoss: 0.967340\n","Train Epoch: 13 [1280/12000 (10.7%)]\tLoss: 0.918512\n","Train Epoch: 13 [1920/12000 (16.0%)]\tLoss: 0.681974\n","Train Epoch: 13 [2560/12000 (21.3%)]\tLoss: 1.103325\n","Train Epoch: 13 [3200/12000 (26.7%)]\tLoss: 1.214041\n","Train Epoch: 13 [3840/12000 (32.0%)]\tLoss: 1.742530\n","Train Epoch: 13 [4480/12000 (37.3%)]\tLoss: 1.224650\n","Train Epoch: 13 [5120/12000 (42.7%)]\tLoss: 0.832179\n","Train Epoch: 13 [5760/12000 (48.0%)]\tLoss: 1.000853\n","Train Epoch: 13 [6400/12000 (53.3%)]\tLoss: 0.985907\n","Train Epoch: 13 [7040/12000 (58.7%)]\tLoss: 1.191107\n","Train Epoch: 13 [7680/12000 (64.0%)]\tLoss: 0.893029\n","Train Epoch: 13 [8320/12000 (69.3%)]\tLoss: 2.000132\n","Train Epoch: 13 [8960/12000 (74.7%)]\tLoss: 0.913840\n","Train Epoch: 13 [9600/12000 (80.0%)]\tLoss: 1.982250\n","Train Epoch: 13 [10240/12000 (85.3%)]\tLoss: 1.547828\n","Train Epoch: 13 [10880/12000 (90.7%)]\tLoss: 1.286154\n","Train Epoch: 13 [11520/12000 (96.0%)]\tLoss: 1.398952\n","\n","Test set: Average loss: 5.6402, Accuracy: 966/8580 (11.00%), F1: 0.08\n","\n","Train Epoch: 14 [0/12000 (0.0%)]\tLoss: 1.104928\n","Train Epoch: 14 [640/12000 (5.3%)]\tLoss: 1.103671\n","Train Epoch: 14 [1280/12000 (10.7%)]\tLoss: 0.906623\n","Train Epoch: 14 [1920/12000 (16.0%)]\tLoss: 0.791638\n","Train Epoch: 14 [2560/12000 (21.3%)]\tLoss: 1.035186\n","Train Epoch: 14 [3200/12000 (26.7%)]\tLoss: 1.368568\n","Train Epoch: 14 [3840/12000 (32.0%)]\tLoss: 1.641337\n","Train Epoch: 14 [4480/12000 (37.3%)]\tLoss: 1.143181\n","Train Epoch: 14 [5120/12000 (42.7%)]\tLoss: 0.750526\n","Train Epoch: 14 [5760/12000 (48.0%)]\tLoss: 1.211236\n","Train Epoch: 14 [6400/12000 (53.3%)]\tLoss: 1.659634\n","Train Epoch: 14 [7040/12000 (58.7%)]\tLoss: 1.652323\n","Train Epoch: 14 [7680/12000 (64.0%)]\tLoss: 2.012183\n","Train Epoch: 14 [8320/12000 (69.3%)]\tLoss: 1.125774\n","Train Epoch: 14 [8960/12000 (74.7%)]\tLoss: 0.961003\n","Train Epoch: 14 [9600/12000 (80.0%)]\tLoss: 0.793011\n","Train Epoch: 14 [10240/12000 (85.3%)]\tLoss: 0.742175\n","Train Epoch: 14 [10880/12000 (90.7%)]\tLoss: 0.825090\n","Train Epoch: 14 [11520/12000 (96.0%)]\tLoss: 1.317722\n","\n","Test set: Average loss: 5.6118, Accuracy: 873/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 15 [0/12000 (0.0%)]\tLoss: 1.170682\n","Train Epoch: 15 [640/12000 (5.3%)]\tLoss: 0.436005\n","Train Epoch: 15 [1280/12000 (10.7%)]\tLoss: 0.814838\n","Train Epoch: 15 [1920/12000 (16.0%)]\tLoss: 1.209378\n","Train Epoch: 15 [2560/12000 (21.3%)]\tLoss: 1.224536\n","Train Epoch: 15 [3200/12000 (26.7%)]\tLoss: 0.734818\n","Train Epoch: 15 [3840/12000 (32.0%)]\tLoss: 1.527569\n","Train Epoch: 15 [4480/12000 (37.3%)]\tLoss: 1.039903\n","Train Epoch: 15 [5120/12000 (42.7%)]\tLoss: 0.853614\n","Train Epoch: 15 [5760/12000 (48.0%)]\tLoss: 1.324732\n","Train Epoch: 15 [6400/12000 (53.3%)]\tLoss: 1.225741\n","Train Epoch: 15 [7040/12000 (58.7%)]\tLoss: 0.882349\n","Train Epoch: 15 [7680/12000 (64.0%)]\tLoss: 0.912741\n","Train Epoch: 15 [8320/12000 (69.3%)]\tLoss: 0.905276\n","Train Epoch: 15 [8960/12000 (74.7%)]\tLoss: 1.464184\n","Train Epoch: 15 [9600/12000 (80.0%)]\tLoss: 0.815706\n","Train Epoch: 15 [10240/12000 (85.3%)]\tLoss: 0.930284\n","Train Epoch: 15 [10880/12000 (90.7%)]\tLoss: 1.691620\n","Train Epoch: 15 [11520/12000 (96.0%)]\tLoss: 1.074996\n","\n","Test set: Average loss: 5.6144, Accuracy: 941/8580 (10.00%), F1: 0.09\n","\n","Train Epoch: 16 [0/12000 (0.0%)]\tLoss: 0.611608\n","Train Epoch: 16 [640/12000 (5.3%)]\tLoss: 0.827739\n","Train Epoch: 16 [1280/12000 (10.7%)]\tLoss: 0.373744\n","Train Epoch: 16 [1920/12000 (16.0%)]\tLoss: 0.650301\n","Train Epoch: 16 [2560/12000 (21.3%)]\tLoss: 0.960885\n","Train Epoch: 16 [3200/12000 (26.7%)]\tLoss: 0.796951\n","Train Epoch: 16 [3840/12000 (32.0%)]\tLoss: 0.851080\n","Train Epoch: 16 [4480/12000 (37.3%)]\tLoss: 1.040938\n","Train Epoch: 16 [5120/12000 (42.7%)]\tLoss: 1.601756\n","Train Epoch: 16 [5760/12000 (48.0%)]\tLoss: 1.092314\n","Train Epoch: 16 [6400/12000 (53.3%)]\tLoss: 1.187495\n","Train Epoch: 16 [7040/12000 (58.7%)]\tLoss: 1.813725\n","Train Epoch: 16 [7680/12000 (64.0%)]\tLoss: 0.863027\n","Train Epoch: 16 [8320/12000 (69.3%)]\tLoss: 1.526937\n","Train Epoch: 16 [8960/12000 (74.7%)]\tLoss: 1.122212\n","Train Epoch: 16 [9600/12000 (80.0%)]\tLoss: 1.333598\n","Train Epoch: 16 [10240/12000 (85.3%)]\tLoss: 1.065834\n","Train Epoch: 16 [10880/12000 (90.7%)]\tLoss: 1.555708\n","Train Epoch: 16 [11520/12000 (96.0%)]\tLoss: 0.788763\n","\n","Test set: Average loss: 5.7868, Accuracy: 969/8580 (11.00%), F1: 0.09\n","\n","Train Epoch: 17 [0/12000 (0.0%)]\tLoss: 0.468580\n","Train Epoch: 17 [640/12000 (5.3%)]\tLoss: 0.497125\n","Train Epoch: 17 [1280/12000 (10.7%)]\tLoss: 0.921886\n","Train Epoch: 17 [1920/12000 (16.0%)]\tLoss: 0.664390\n","Train Epoch: 17 [2560/12000 (21.3%)]\tLoss: 0.368408\n","Train Epoch: 17 [3200/12000 (26.7%)]\tLoss: 0.748515\n","Train Epoch: 17 [3840/12000 (32.0%)]\tLoss: 0.941819\n","Train Epoch: 17 [4480/12000 (37.3%)]\tLoss: 0.851684\n","Train Epoch: 17 [5120/12000 (42.7%)]\tLoss: 0.534910\n","Train Epoch: 17 [5760/12000 (48.0%)]\tLoss: 0.392217\n","Train Epoch: 17 [6400/12000 (53.3%)]\tLoss: 0.664438\n","Train Epoch: 17 [7040/12000 (58.7%)]\tLoss: 1.259257\n","Train Epoch: 17 [7680/12000 (64.0%)]\tLoss: 0.905143\n","Train Epoch: 17 [8320/12000 (69.3%)]\tLoss: 0.759515\n","Train Epoch: 17 [8960/12000 (74.7%)]\tLoss: 1.321881\n","Train Epoch: 17 [9600/12000 (80.0%)]\tLoss: 0.943841\n","Train Epoch: 17 [10240/12000 (85.3%)]\tLoss: 0.518288\n","Train Epoch: 17 [10880/12000 (90.7%)]\tLoss: 1.273533\n","Train Epoch: 17 [11520/12000 (96.0%)]\tLoss: 1.083256\n","\n","Test set: Average loss: 6.0886, Accuracy: 879/8580 (10.00%), F1: 0.10\n","\n","Train Epoch: 18 [0/12000 (0.0%)]\tLoss: 0.729319\n","Train Epoch: 18 [640/12000 (5.3%)]\tLoss: 0.579935\n","Train Epoch: 18 [1280/12000 (10.7%)]\tLoss: 0.560561\n","Train Epoch: 18 [1920/12000 (16.0%)]\tLoss: 0.723431\n","Train Epoch: 18 [2560/12000 (21.3%)]\tLoss: 0.746001\n","Train Epoch: 18 [3200/12000 (26.7%)]\tLoss: 0.931642\n","Train Epoch: 18 [3840/12000 (32.0%)]\tLoss: 0.955504\n","Train Epoch: 18 [4480/12000 (37.3%)]\tLoss: 0.771251\n","Train Epoch: 18 [5120/12000 (42.7%)]\tLoss: 0.807011\n","Train Epoch: 18 [5760/12000 (48.0%)]\tLoss: 0.716063\n","Train Epoch: 18 [6400/12000 (53.3%)]\tLoss: 0.806374\n","Train Epoch: 18 [7040/12000 (58.7%)]\tLoss: 0.375285\n","Train Epoch: 18 [7680/12000 (64.0%)]\tLoss: 0.810193\n","Train Epoch: 18 [8320/12000 (69.3%)]\tLoss: 0.679766\n","Train Epoch: 18 [8960/12000 (74.7%)]\tLoss: 0.621005\n","Train Epoch: 18 [9600/12000 (80.0%)]\tLoss: 0.705924\n","Train Epoch: 18 [10240/12000 (85.3%)]\tLoss: 1.380654\n","Train Epoch: 18 [10880/12000 (90.7%)]\tLoss: 1.155360\n","Train Epoch: 18 [11520/12000 (96.0%)]\tLoss: 0.563227\n","\n","Test set: Average loss: 6.1950, Accuracy: 955/8580 (11.00%), F1: 0.07\n","\n","Train Epoch: 19 [0/12000 (0.0%)]\tLoss: 0.485676\n","Train Epoch: 19 [640/12000 (5.3%)]\tLoss: 0.775060\n","Train Epoch: 19 [1280/12000 (10.7%)]\tLoss: 1.005631\n","Train Epoch: 19 [1920/12000 (16.0%)]\tLoss: 0.841509\n","Train Epoch: 19 [2560/12000 (21.3%)]\tLoss: 1.249279\n","Train Epoch: 19 [3200/12000 (26.7%)]\tLoss: 0.727383\n","Train Epoch: 19 [3840/12000 (32.0%)]\tLoss: 0.773573\n","Train Epoch: 19 [4480/12000 (37.3%)]\tLoss: 0.734558\n","Train Epoch: 19 [5120/12000 (42.7%)]\tLoss: 0.866470\n","Train Epoch: 19 [5760/12000 (48.0%)]\tLoss: 1.197066\n","Train Epoch: 19 [6400/12000 (53.3%)]\tLoss: 1.104382\n","Train Epoch: 19 [7040/12000 (58.7%)]\tLoss: 0.932969\n","Train Epoch: 19 [7680/12000 (64.0%)]\tLoss: 1.149420\n","Train Epoch: 19 [8320/12000 (69.3%)]\tLoss: 0.739466\n","Train Epoch: 19 [8960/12000 (74.7%)]\tLoss: 1.103547\n","Train Epoch: 19 [9600/12000 (80.0%)]\tLoss: 1.259186\n","Train Epoch: 19 [10240/12000 (85.3%)]\tLoss: 0.664545\n","Train Epoch: 19 [10880/12000 (90.7%)]\tLoss: 0.557507\n","Train Epoch: 19 [11520/12000 (96.0%)]\tLoss: 1.276170\n","\n","Test set: Average loss: 6.2770, Accuracy: 941/8580 (10.00%), F1: 0.08\n","\n","Train Epoch: 20 [0/12000 (0.0%)]\tLoss: 0.395363\n","Train Epoch: 20 [640/12000 (5.3%)]\tLoss: 0.630013\n","Train Epoch: 20 [1280/12000 (10.7%)]\tLoss: 0.331856\n","Train Epoch: 20 [1920/12000 (16.0%)]\tLoss: 0.614798\n","Train Epoch: 20 [2560/12000 (21.3%)]\tLoss: 0.455957\n","Train Epoch: 20 [3200/12000 (26.7%)]\tLoss: 0.236665\n","Train Epoch: 20 [3840/12000 (32.0%)]\tLoss: 0.185645\n","Train Epoch: 20 [4480/12000 (37.3%)]\tLoss: 0.483033\n","Train Epoch: 20 [5120/12000 (42.7%)]\tLoss: 0.875530\n","Train Epoch: 20 [5760/12000 (48.0%)]\tLoss: 0.228409\n","Train Epoch: 20 [6400/12000 (53.3%)]\tLoss: 0.427325\n","Train Epoch: 20 [7040/12000 (58.7%)]\tLoss: 0.447313\n","Train Epoch: 20 [7680/12000 (64.0%)]\tLoss: 0.137288\n","Train Epoch: 20 [8320/12000 (69.3%)]\tLoss: 0.048423\n","Train Epoch: 20 [8960/12000 (74.7%)]\tLoss: 0.322343\n","Train Epoch: 20 [9600/12000 (80.0%)]\tLoss: 0.275778\n","Train Epoch: 20 [10240/12000 (85.3%)]\tLoss: 0.055755\n","Train Epoch: 20 [10880/12000 (90.7%)]\tLoss: 0.442131\n","Train Epoch: 20 [11520/12000 (96.0%)]\tLoss: 0.736012\n","\n","Test set: Average loss: 5.6831, Accuracy: 1186/8580 (13.00%), F1: 0.11\n","\n","Train Epoch: 21 [0/12000 (0.0%)]\tLoss: 0.189965\n","Train Epoch: 21 [640/12000 (5.3%)]\tLoss: 0.173053\n","Train Epoch: 21 [1280/12000 (10.7%)]\tLoss: 0.257681\n","Train Epoch: 21 [1920/12000 (16.0%)]\tLoss: 0.207019\n","Train Epoch: 21 [2560/12000 (21.3%)]\tLoss: 0.194358\n","Train Epoch: 21 [3200/12000 (26.7%)]\tLoss: 0.166985\n","Train Epoch: 21 [3840/12000 (32.0%)]\tLoss: 0.103240\n","Train Epoch: 21 [4480/12000 (37.3%)]\tLoss: 0.217436\n","Train Epoch: 21 [5120/12000 (42.7%)]\tLoss: 0.117509\n","Train Epoch: 21 [5760/12000 (48.0%)]\tLoss: 0.056908\n","Train Epoch: 21 [6400/12000 (53.3%)]\tLoss: 0.377944\n","Train Epoch: 21 [7040/12000 (58.7%)]\tLoss: 0.150280\n","Train Epoch: 21 [7680/12000 (64.0%)]\tLoss: 0.225872\n","Train Epoch: 21 [8320/12000 (69.3%)]\tLoss: 0.089304\n","Train Epoch: 21 [8960/12000 (74.7%)]\tLoss: 0.182994\n","Train Epoch: 21 [9600/12000 (80.0%)]\tLoss: 0.101989\n","Train Epoch: 21 [10240/12000 (85.3%)]\tLoss: 0.271312\n","Train Epoch: 21 [10880/12000 (90.7%)]\tLoss: 0.055815\n","Train Epoch: 21 [11520/12000 (96.0%)]\tLoss: 0.062076\n","\n","Test set: Average loss: 5.7425, Accuracy: 1215/8580 (14.00%), F1: 0.08\n","\n","Train Epoch: 22 [0/12000 (0.0%)]\tLoss: 0.101528\n","Train Epoch: 22 [640/12000 (5.3%)]\tLoss: 0.162495\n","Train Epoch: 22 [1280/12000 (10.7%)]\tLoss: 0.057233\n","Train Epoch: 22 [1920/12000 (16.0%)]\tLoss: 0.031353\n","Train Epoch: 22 [2560/12000 (21.3%)]\tLoss: 0.249545\n","Train Epoch: 22 [3200/12000 (26.7%)]\tLoss: 0.086086\n","Train Epoch: 22 [3840/12000 (32.0%)]\tLoss: 0.126070\n","Train Epoch: 22 [4480/12000 (37.3%)]\tLoss: 0.066195\n","Train Epoch: 22 [5120/12000 (42.7%)]\tLoss: 0.028623\n","Train Epoch: 22 [5760/12000 (48.0%)]\tLoss: 0.219400\n","Train Epoch: 22 [6400/12000 (53.3%)]\tLoss: 0.043566\n","Train Epoch: 22 [7040/12000 (58.7%)]\tLoss: 0.042993\n","Train Epoch: 22 [7680/12000 (64.0%)]\tLoss: 0.173369\n","Train Epoch: 22 [8320/12000 (69.3%)]\tLoss: 0.014057\n","Train Epoch: 22 [8960/12000 (74.7%)]\tLoss: 0.038072\n","Train Epoch: 22 [9600/12000 (80.0%)]\tLoss: 0.081010\n","Train Epoch: 22 [10240/12000 (85.3%)]\tLoss: 0.082458\n","Train Epoch: 22 [10880/12000 (90.7%)]\tLoss: 0.123453\n","Train Epoch: 22 [11520/12000 (96.0%)]\tLoss: 0.174063\n","\n","Test set: Average loss: 5.9107, Accuracy: 1228/8580 (14.00%), F1: 0.12\n","\n","Train Epoch: 23 [0/12000 (0.0%)]\tLoss: 0.079034\n","Train Epoch: 23 [640/12000 (5.3%)]\tLoss: 0.025492\n","Train Epoch: 23 [1280/12000 (10.7%)]\tLoss: 0.027543\n","Train Epoch: 23 [1920/12000 (16.0%)]\tLoss: 0.195038\n","Train Epoch: 23 [2560/12000 (21.3%)]\tLoss: 0.041336\n","Train Epoch: 23 [3200/12000 (26.7%)]\tLoss: 0.114173\n","Train Epoch: 23 [3840/12000 (32.0%)]\tLoss: 0.074325\n","Train Epoch: 23 [4480/12000 (37.3%)]\tLoss: 0.030271\n","Train Epoch: 23 [5120/12000 (42.7%)]\tLoss: 0.086659\n","Train Epoch: 23 [5760/12000 (48.0%)]\tLoss: 0.235821\n","Train Epoch: 23 [6400/12000 (53.3%)]\tLoss: 0.085911\n","Train Epoch: 23 [7040/12000 (58.7%)]\tLoss: 0.078236\n","Train Epoch: 23 [7680/12000 (64.0%)]\tLoss: 0.084006\n","Train Epoch: 23 [8320/12000 (69.3%)]\tLoss: 0.014996\n","Train Epoch: 23 [8960/12000 (74.7%)]\tLoss: 0.030075\n","Train Epoch: 23 [9600/12000 (80.0%)]\tLoss: 0.184715\n","Train Epoch: 23 [10240/12000 (85.3%)]\tLoss: 0.129751\n","Train Epoch: 23 [10880/12000 (90.7%)]\tLoss: 0.091097\n","Train Epoch: 23 [11520/12000 (96.0%)]\tLoss: 0.328897\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ICbwQAOwgYn","colab_type":"code","colab":{}},"source":["%cd l1-norm-pruning/\n","!python main_transfer.py --dataset cifar10 --scratch modelB100_best.pth.tar --method 2 --dist B100\n","!python main_transfer.py --dataset cifar10 --scratch modelB200_best.pth.tar --method 2 --dist B200\n","!python main_transfer.py --dataset cifar10 --scratch modelB500_best.pth.tar --method 2 --dist B500"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-evXTtVwqag","colab_type":"code","outputId":"5cdaf620-2c88-41aa-fd29-d1172c82dab1","colab":{"base_uri":"https://localhost:8080/","height":2680}},"source":["%cd l1-norm-pruning/\n","!python main_transfer.py --dataset cifar10 --scratch modelC100_best.pth.tar --method 2 --dist C100\n","!python main_transfer.py --dataset cifar10 --scratch modelC200_best.pth.tar --method 2 --dist C200\n","!python main_transfer.py --dataset cifar10 --scratch modelC500_best.pth.tar --method 2 --dist C500"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/dsfinal/l1-norm-pruning\n","[INFO] Method:  scratchE\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/scratchE/modelC100_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new trasfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.850427\n","Train Epoch: 0 [320/12000 (2.7%)]\tLoss: 6.951565\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.135056\n","Train Epoch: 0 [960/12000 (8.0%)]\tLoss: 4.865924\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.765867\n","Train Epoch: 0 [1600/12000 (13.3%)]\tLoss: 4.812977\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 4.988323\n","Train Epoch: 0 [2240/12000 (18.7%)]\tLoss: 4.589236\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.749329\n","Train Epoch: 0 [2880/12000 (24.0%)]\tLoss: 4.676220\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.523232\n","Train Epoch: 0 [3520/12000 (29.3%)]\tLoss: 4.336748\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.323466\n","Train Epoch: 0 [4160/12000 (34.7%)]\tLoss: 4.812343\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.765581\n","Train Epoch: 0 [4800/12000 (40.0%)]\tLoss: 4.502354\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.321786\n","Train Epoch: 0 [5440/12000 (45.3%)]\tLoss: 4.838242\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.791489\n","Train Epoch: 0 [6080/12000 (50.7%)]\tLoss: 4.575122\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.502256\n","Train Epoch: 0 [6720/12000 (56.0%)]\tLoss: 4.516448\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 4.526406\n","Train Epoch: 0 [7360/12000 (61.3%)]\tLoss: 4.638691\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.333708\n","Train Epoch: 0 [8000/12000 (66.7%)]\tLoss: 4.564387\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 4.218964\n","Train Epoch: 0 [8640/12000 (72.0%)]\tLoss: 4.204693\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.376284\n","Train Epoch: 0 [9280/12000 (77.3%)]\tLoss: 4.302850\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.338678\n","Train Epoch: 0 [9920/12000 (82.7%)]\tLoss: 4.284909\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.277685\n","Train Epoch: 0 [10560/12000 (88.0%)]\tLoss: 4.446763\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.398315\n","Train Epoch: 0 [11200/12000 (93.3%)]\tLoss: 4.409575\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 3.990656\n","Train Epoch: 0 [11840/12000 (98.7%)]\tLoss: 4.097061\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","\n","Test set: Average loss: 4.3126, Accuracy: 497/8580 (5.00%), F1: 0.03\n","\n","Train Epoch: 1 [0/12000 (0.0%)]\tLoss: 4.422451\n","Train Epoch: 1 [320/12000 (2.7%)]\tLoss: 4.145627\n","Train Epoch: 1 [640/12000 (5.3%)]\tLoss: 4.046640\n","Train Epoch: 1 [960/12000 (8.0%)]\tLoss: 4.292397\n","Train Epoch: 1 [1280/12000 (10.7%)]\tLoss: 4.017320\n","Train Epoch: 1 [1600/12000 (13.3%)]\tLoss: 4.469896\n","Train Epoch: 1 [1920/12000 (16.0%)]\tLoss: 4.070619\n","Train Epoch: 1 [2240/12000 (18.7%)]\tLoss: 4.236689\n","Train Epoch: 1 [2560/12000 (21.3%)]\tLoss: 4.156142\n","Train Epoch: 1 [2880/12000 (24.0%)]\tLoss: 4.079129\n","Train Epoch: 1 [3200/12000 (26.7%)]\tLoss: 4.510548\n","Train Epoch: 1 [3520/12000 (29.3%)]\tLoss: 4.685614\n","Train Epoch: 1 [3840/12000 (32.0%)]\tLoss: 4.182551\n","Train Epoch: 1 [4160/12000 (34.7%)]\tLoss: 4.173735\n","Train Epoch: 1 [4480/12000 (37.3%)]\tLoss: 4.442518\n","Train Epoch: 1 [4800/12000 (40.0%)]\tLoss: 4.452925\n","Train Epoch: 1 [5120/12000 (42.7%)]\tLoss: 4.167745\n","Train Epoch: 1 [5440/12000 (45.3%)]\tLoss: 3.706187\n","Train Epoch: 1 [5760/12000 (48.0%)]\tLoss: 4.138371\n","Train Epoch: 1 [6080/12000 (50.7%)]\tLoss: 4.155167\n","Train Epoch: 1 [6400/12000 (53.3%)]\tLoss: 4.741102\n","Train Epoch: 1 [6720/12000 (56.0%)]\tLoss: 4.174510\n","Train Epoch: 1 [7040/12000 (58.7%)]\tLoss: 4.250442\n","Train Epoch: 1 [7360/12000 (61.3%)]\tLoss: 4.182694\n","Train Epoch: 1 [7680/12000 (64.0%)]\tLoss: 3.954310\n","Train Epoch: 1 [8000/12000 (66.7%)]\tLoss: 4.427028\n","Train Epoch: 1 [8320/12000 (69.3%)]\tLoss: 3.699891\n","Train Epoch: 1 [8640/12000 (72.0%)]\tLoss: 4.339635\n","Train Epoch: 1 [8960/12000 (74.7%)]\tLoss: 4.370238\n","Train Epoch: 1 [9280/12000 (77.3%)]\tLoss: 4.025128\n","Train Epoch: 1 [9600/12000 (80.0%)]\tLoss: 3.748375\n","Train Epoch: 1 [9920/12000 (82.7%)]\tLoss: 3.864225\n","Train Epoch: 1 [10240/12000 (85.3%)]\tLoss: 3.939890\n","Train Epoch: 1 [10560/12000 (88.0%)]\tLoss: 4.310527\n","Train Epoch: 1 [10880/12000 (90.7%)]\tLoss: 4.304241\n","Train Epoch: 1 [11200/12000 (93.3%)]\tLoss: 4.029334\n","Train Epoch: 1 [11520/12000 (96.0%)]\tLoss: 4.437482\n","Train Epoch: 1 [11840/12000 (98.7%)]\tLoss: 4.308578\n","\n","Test set: Average loss: 4.1334, Accuracy: 593/8580 (6.00%), F1: 0.04\n","\n","Train Epoch: 2 [0/12000 (0.0%)]\tLoss: 4.298614\n","Train Epoch: 2 [320/12000 (2.7%)]\tLoss: 4.271805\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aNyLm39ChWUU","colab_type":"code","outputId":"fb0dda78-65f7-42f6-d376-e491ff028a42","colab":{"base_uri":"https://localhost:8080/","height":16178}},"source":["%cd l1-norm-pruning/\n","!python main_transfer.py --dataset cifar10 --scratch modelB500_best.pth.tar --method 2 --dist B500\n","!python main_transfer.py --dataset cifar10 --scratch modelC500_best.pth.tar --method 2 --dist C500\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/dsfinal/l1-norm-pruning\n","[INFO] Method:  scratchE\n","[INFO] Start creating datasets\n","[INFO] Creating dataloader\n","[INFO] Return dataloaders\n","[INFO] Loading model from /content/Drive/My Drive/Colab Notebooks/models/scratchE/modelB500_best.pth.tar\n","Old model features:  10\n","[INFO] In Features 1024\n","Get the new transfer learning model vgg(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace)\n","    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace)\n","    (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace)\n","    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=16384, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Linear(in_features=4096, out_features=1024, bias=True)\n","    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): Linear(in_features=1024, out_features=120, bias=True)\n","  )\n",")\n","THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n","Train Epoch: 0 [0/12000 (0.0%)]\tLoss: 4.850427\n","Train Epoch: 0 [320/12000 (2.7%)]\tLoss: 6.951565\n","Train Epoch: 0 [640/12000 (5.3%)]\tLoss: 5.135056\n","Train Epoch: 0 [960/12000 (8.0%)]\tLoss: 4.865924\n","Train Epoch: 0 [1280/12000 (10.7%)]\tLoss: 4.765867\n","Train Epoch: 0 [1600/12000 (13.3%)]\tLoss: 4.812977\n","Train Epoch: 0 [1920/12000 (16.0%)]\tLoss: 4.988323\n","Train Epoch: 0 [2240/12000 (18.7%)]\tLoss: 4.589236\n","Train Epoch: 0 [2560/12000 (21.3%)]\tLoss: 4.749329\n","Train Epoch: 0 [2880/12000 (24.0%)]\tLoss: 4.676220\n","Train Epoch: 0 [3200/12000 (26.7%)]\tLoss: 4.523232\n","Train Epoch: 0 [3520/12000 (29.3%)]\tLoss: 4.336748\n","Train Epoch: 0 [3840/12000 (32.0%)]\tLoss: 4.323466\n","Train Epoch: 0 [4160/12000 (34.7%)]\tLoss: 4.812343\n","Train Epoch: 0 [4480/12000 (37.3%)]\tLoss: 4.765581\n","Train Epoch: 0 [4800/12000 (40.0%)]\tLoss: 4.502354\n","Train Epoch: 0 [5120/12000 (42.7%)]\tLoss: 4.321786\n","Train Epoch: 0 [5440/12000 (45.3%)]\tLoss: 4.838242\n","Train Epoch: 0 [5760/12000 (48.0%)]\tLoss: 4.791489\n","Train Epoch: 0 [6080/12000 (50.7%)]\tLoss: 4.575122\n","Train Epoch: 0 [6400/12000 (53.3%)]\tLoss: 4.502256\n","Train Epoch: 0 [6720/12000 (56.0%)]\tLoss: 4.516448\n","Train Epoch: 0 [7040/12000 (58.7%)]\tLoss: 4.526406\n","Train Epoch: 0 [7360/12000 (61.3%)]\tLoss: 4.638691\n","Train Epoch: 0 [7680/12000 (64.0%)]\tLoss: 4.333708\n","Train Epoch: 0 [8000/12000 (66.7%)]\tLoss: 4.564387\n","Train Epoch: 0 [8320/12000 (69.3%)]\tLoss: 4.218964\n","Train Epoch: 0 [8640/12000 (72.0%)]\tLoss: 4.204693\n","Train Epoch: 0 [8960/12000 (74.7%)]\tLoss: 4.376284\n","Train Epoch: 0 [9280/12000 (77.3%)]\tLoss: 4.302850\n","Train Epoch: 0 [9600/12000 (80.0%)]\tLoss: 4.338678\n","Train Epoch: 0 [9920/12000 (82.7%)]\tLoss: 4.284909\n","Train Epoch: 0 [10240/12000 (85.3%)]\tLoss: 4.277685\n","Train Epoch: 0 [10560/12000 (88.0%)]\tLoss: 4.446763\n","Train Epoch: 0 [10880/12000 (90.7%)]\tLoss: 4.398315\n","Train Epoch: 0 [11200/12000 (93.3%)]\tLoss: 4.409575\n","Train Epoch: 0 [11520/12000 (96.0%)]\tLoss: 3.990656\n","Train Epoch: 0 [11840/12000 (98.7%)]\tLoss: 4.097061\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","\n","Test set: Average loss: 4.3126, Accuracy: 497/8580 (5.00%), F1: 0.03\n","\n","Train Epoch: 1 [0/12000 (0.0%)]\tLoss: 4.422451\n","Train Epoch: 1 [320/12000 (2.7%)]\tLoss: 4.145627\n","Train Epoch: 1 [640/12000 (5.3%)]\tLoss: 4.046640\n","Train Epoch: 1 [960/12000 (8.0%)]\tLoss: 4.292397\n","Train Epoch: 1 [1280/12000 (10.7%)]\tLoss: 4.017320\n","Train Epoch: 1 [1600/12000 (13.3%)]\tLoss: 4.469896\n","Train Epoch: 1 [1920/12000 (16.0%)]\tLoss: 4.070619\n","Train Epoch: 1 [2240/12000 (18.7%)]\tLoss: 4.236689\n","Train Epoch: 1 [2560/12000 (21.3%)]\tLoss: 4.156142\n","Train Epoch: 1 [2880/12000 (24.0%)]\tLoss: 4.079129\n","Train Epoch: 1 [3200/12000 (26.7%)]\tLoss: 4.510548\n","Train Epoch: 1 [3520/12000 (29.3%)]\tLoss: 4.685614\n","Train Epoch: 1 [3840/12000 (32.0%)]\tLoss: 4.182551\n","Train Epoch: 1 [4160/12000 (34.7%)]\tLoss: 4.173735\n","Train Epoch: 1 [4480/12000 (37.3%)]\tLoss: 4.442518\n","Train Epoch: 1 [4800/12000 (40.0%)]\tLoss: 4.452925\n","Train Epoch: 1 [5120/12000 (42.7%)]\tLoss: 4.167745\n","Train Epoch: 1 [5440/12000 (45.3%)]\tLoss: 3.706187\n","Train Epoch: 1 [5760/12000 (48.0%)]\tLoss: 4.138371\n","Train Epoch: 1 [6080/12000 (50.7%)]\tLoss: 4.155167\n","Train Epoch: 1 [6400/12000 (53.3%)]\tLoss: 4.741102\n","Train Epoch: 1 [6720/12000 (56.0%)]\tLoss: 4.174510\n","Train Epoch: 1 [7040/12000 (58.7%)]\tLoss: 4.250442\n","Train Epoch: 1 [7360/12000 (61.3%)]\tLoss: 4.182694\n","Train Epoch: 1 [7680/12000 (64.0%)]\tLoss: 3.954310\n","Train Epoch: 1 [8000/12000 (66.7%)]\tLoss: 4.427028\n","Train Epoch: 1 [8320/12000 (69.3%)]\tLoss: 3.699891\n","Train Epoch: 1 [8640/12000 (72.0%)]\tLoss: 4.339635\n","Train Epoch: 1 [8960/12000 (74.7%)]\tLoss: 4.370238\n","Train Epoch: 1 [9280/12000 (77.3%)]\tLoss: 4.025128\n","Train Epoch: 1 [9600/12000 (80.0%)]\tLoss: 3.748375\n","Train Epoch: 1 [9920/12000 (82.7%)]\tLoss: 3.864225\n","Train Epoch: 1 [10240/12000 (85.3%)]\tLoss: 3.939890\n","Train Epoch: 1 [10560/12000 (88.0%)]\tLoss: 4.310527\n","Train Epoch: 1 [10880/12000 (90.7%)]\tLoss: 4.304241\n","Train Epoch: 1 [11200/12000 (93.3%)]\tLoss: 4.029334\n","Train Epoch: 1 [11520/12000 (96.0%)]\tLoss: 4.437482\n","Train Epoch: 1 [11840/12000 (98.7%)]\tLoss: 4.308578\n","\n","Test set: Average loss: 4.1334, Accuracy: 593/8580 (6.00%), F1: 0.04\n","\n","Train Epoch: 2 [0/12000 (0.0%)]\tLoss: 4.298614\n","Train Epoch: 2 [320/12000 (2.7%)]\tLoss: 4.271805\n","Train Epoch: 2 [640/12000 (5.3%)]\tLoss: 3.865330\n","Train Epoch: 2 [960/12000 (8.0%)]\tLoss: 4.457892\n","Train Epoch: 2 [1280/12000 (10.7%)]\tLoss: 3.753899\n","Train Epoch: 2 [1600/12000 (13.3%)]\tLoss: 3.841472\n","Train Epoch: 2 [1920/12000 (16.0%)]\tLoss: 5.123995\n","Train Epoch: 2 [2240/12000 (18.7%)]\tLoss: 3.913518\n","Train Epoch: 2 [2560/12000 (21.3%)]\tLoss: 4.442689\n","Train Epoch: 2 [2880/12000 (24.0%)]\tLoss: 4.289768\n","Train Epoch: 2 [3200/12000 (26.7%)]\tLoss: 4.189661\n","Train Epoch: 2 [3520/12000 (29.3%)]\tLoss: 4.034265\n","Train Epoch: 2 [3840/12000 (32.0%)]\tLoss: 4.622890\n","Train Epoch: 2 [4160/12000 (34.7%)]\tLoss: 4.162589\n","Train Epoch: 2 [4480/12000 (37.3%)]\tLoss: 4.241567\n","Train Epoch: 2 [4800/12000 (40.0%)]\tLoss: 4.084607\n","Train Epoch: 2 [5120/12000 (42.7%)]\tLoss: 4.107827\n","Train Epoch: 2 [5440/12000 (45.3%)]\tLoss: 4.123692\n","Train Epoch: 2 [5760/12000 (48.0%)]\tLoss: 4.196384\n","Train Epoch: 2 [6080/12000 (50.7%)]\tLoss: 3.907529\n","Train Epoch: 2 [6400/12000 (53.3%)]\tLoss: 4.211584\n","Train Epoch: 2 [6720/12000 (56.0%)]\tLoss: 4.591831\n","Train Epoch: 2 [7040/12000 (58.7%)]\tLoss: 4.104841\n","Train Epoch: 2 [7360/12000 (61.3%)]\tLoss: 4.004068\n","Train Epoch: 2 [7680/12000 (64.0%)]\tLoss: 3.879756\n","Train Epoch: 2 [8000/12000 (66.7%)]\tLoss: 3.945763\n","Train Epoch: 2 [8320/12000 (69.3%)]\tLoss: 4.154979\n","Train Epoch: 2 [8640/12000 (72.0%)]\tLoss: 3.926299\n","Train Epoch: 2 [8960/12000 (74.7%)]\tLoss: 4.100641\n","Train Epoch: 2 [9280/12000 (77.3%)]\tLoss: 4.276362\n","Train Epoch: 2 [9600/12000 (80.0%)]\tLoss: 3.645260\n","Train Epoch: 2 [9920/12000 (82.7%)]\tLoss: 4.103304\n","Train Epoch: 2 [10240/12000 (85.3%)]\tLoss: 3.758711\n","Train Epoch: 2 [10560/12000 (88.0%)]\tLoss: 3.882385\n","Train Epoch: 2 [10880/12000 (90.7%)]\tLoss: 4.397069\n","Train Epoch: 2 [11200/12000 (93.3%)]\tLoss: 3.816550\n","Train Epoch: 2 [11520/12000 (96.0%)]\tLoss: 4.374526\n","Train Epoch: 2 [11840/12000 (98.7%)]\tLoss: 3.904672\n","\n","Test set: Average loss: 4.0000, Accuracy: 771/8580 (8.00%), F1: 0.06\n","\n","Train Epoch: 3 [0/12000 (0.0%)]\tLoss: 3.167792\n","Train Epoch: 3 [320/12000 (2.7%)]\tLoss: 4.081625\n","Train Epoch: 3 [640/12000 (5.3%)]\tLoss: 4.196856\n","Train Epoch: 3 [960/12000 (8.0%)]\tLoss: 3.268177\n","Train Epoch: 3 [1280/12000 (10.7%)]\tLoss: 4.308016\n","Train Epoch: 3 [1600/12000 (13.3%)]\tLoss: 4.002702\n","Train Epoch: 3 [1920/12000 (16.0%)]\tLoss: 4.234451\n","Train Epoch: 3 [2240/12000 (18.7%)]\tLoss: 3.704900\n","Train Epoch: 3 [2560/12000 (21.3%)]\tLoss: 4.140430\n","Train Epoch: 3 [2880/12000 (24.0%)]\tLoss: 3.766356\n","Train Epoch: 3 [3200/12000 (26.7%)]\tLoss: 4.119877\n","Train Epoch: 3 [3520/12000 (29.3%)]\tLoss: 3.902966\n","Train Epoch: 3 [3840/12000 (32.0%)]\tLoss: 3.719911\n","Train Epoch: 3 [4160/12000 (34.7%)]\tLoss: 4.402930\n","Train Epoch: 3 [4480/12000 (37.3%)]\tLoss: 3.783738\n","Train Epoch: 3 [4800/12000 (40.0%)]\tLoss: 4.250958\n","Train Epoch: 3 [5120/12000 (42.7%)]\tLoss: 4.035814\n","Train Epoch: 3 [5440/12000 (45.3%)]\tLoss: 4.269402\n","Train Epoch: 3 [5760/12000 (48.0%)]\tLoss: 3.730417\n","Train Epoch: 3 [6080/12000 (50.7%)]\tLoss: 3.815709\n","Train Epoch: 3 [6400/12000 (53.3%)]\tLoss: 4.265093\n","Train Epoch: 3 [6720/12000 (56.0%)]\tLoss: 3.646477\n","Train Epoch: 3 [7040/12000 (58.7%)]\tLoss: 4.038140\n","Train Epoch: 3 [7360/12000 (61.3%)]\tLoss: 3.208712\n","Train Epoch: 3 [7680/12000 (64.0%)]\tLoss: 4.144572\n","Train Epoch: 3 [8000/12000 (66.7%)]\tLoss: 4.229014\n","Train Epoch: 3 [8320/12000 (69.3%)]\tLoss: 4.059137\n","Train Epoch: 3 [8640/12000 (72.0%)]\tLoss: 4.316164\n","Train Epoch: 3 [8960/12000 (74.7%)]\tLoss: 4.535899\n","Train Epoch: 3 [9280/12000 (77.3%)]\tLoss: 3.650662\n","Train Epoch: 3 [9600/12000 (80.0%)]\tLoss: 3.755596\n","Train Epoch: 3 [9920/12000 (82.7%)]\tLoss: 3.876723\n","Train Epoch: 3 [10240/12000 (85.3%)]\tLoss: 3.754435\n","Train Epoch: 3 [10560/12000 (88.0%)]\tLoss: 3.854126\n","Train Epoch: 3 [10880/12000 (90.7%)]\tLoss: 4.360445\n","Train Epoch: 3 [11200/12000 (93.3%)]\tLoss: 4.283967\n","Train Epoch: 3 [11520/12000 (96.0%)]\tLoss: 3.284196\n","Train Epoch: 3 [11840/12000 (98.7%)]\tLoss: 4.100196\n","\n","Test set: Average loss: 4.0009, Accuracy: 803/8580 (9.00%), F1: 0.06\n","\n","Train Epoch: 4 [0/12000 (0.0%)]\tLoss: 3.755117\n","Train Epoch: 4 [320/12000 (2.7%)]\tLoss: 3.749594\n","Train Epoch: 4 [640/12000 (5.3%)]\tLoss: 3.849638\n","Train Epoch: 4 [960/12000 (8.0%)]\tLoss: 3.392523\n","Train Epoch: 4 [1280/12000 (10.7%)]\tLoss: 3.943923\n","Train Epoch: 4 [1600/12000 (13.3%)]\tLoss: 3.438942\n","Train Epoch: 4 [1920/12000 (16.0%)]\tLoss: 3.455471\n","Train Epoch: 4 [2240/12000 (18.7%)]\tLoss: 3.611207\n","Train Epoch: 4 [2560/12000 (21.3%)]\tLoss: 4.280502\n","Train Epoch: 4 [2880/12000 (24.0%)]\tLoss: 3.849715\n","Train Epoch: 4 [3200/12000 (26.7%)]\tLoss: 3.691857\n","Train Epoch: 4 [3520/12000 (29.3%)]\tLoss: 3.809793\n","Train Epoch: 4 [3840/12000 (32.0%)]\tLoss: 3.758122\n","Train Epoch: 4 [4160/12000 (34.7%)]\tLoss: 3.231567\n","Train Epoch: 4 [4480/12000 (37.3%)]\tLoss: 3.512922\n","Train Epoch: 4 [4800/12000 (40.0%)]\tLoss: 3.430352\n","Train Epoch: 4 [5120/12000 (42.7%)]\tLoss: 4.013701\n","Train Epoch: 4 [5440/12000 (45.3%)]\tLoss: 3.386066\n","Train Epoch: 4 [5760/12000 (48.0%)]\tLoss: 3.643597\n","Train Epoch: 4 [6080/12000 (50.7%)]\tLoss: 3.923612\n","Train Epoch: 4 [6400/12000 (53.3%)]\tLoss: 4.498328\n","Train Epoch: 4 [6720/12000 (56.0%)]\tLoss: 3.273256\n","Train Epoch: 4 [7040/12000 (58.7%)]\tLoss: 3.716268\n","Train Epoch: 4 [7360/12000 (61.3%)]\tLoss: 4.249864\n","Train Epoch: 4 [7680/12000 (64.0%)]\tLoss: 3.953113\n","Train Epoch: 4 [8000/12000 (66.7%)]\tLoss: 4.098416\n","Train Epoch: 4 [8320/12000 (69.3%)]\tLoss: 3.008372\n","Train Epoch: 4 [8640/12000 (72.0%)]\tLoss: 3.272026\n","Train Epoch: 4 [8960/12000 (74.7%)]\tLoss: 3.326303\n","Train Epoch: 4 [9280/12000 (77.3%)]\tLoss: 3.943744\n","Train Epoch: 4 [9600/12000 (80.0%)]\tLoss: 3.537810\n","Train Epoch: 4 [9920/12000 (82.7%)]\tLoss: 3.807398\n","Train Epoch: 4 [10240/12000 (85.3%)]\tLoss: 3.675059\n","Train Epoch: 4 [10560/12000 (88.0%)]\tLoss: 3.532673\n","Train Epoch: 4 [10880/12000 (90.7%)]\tLoss: 3.954620\n","Train Epoch: 4 [11200/12000 (93.3%)]\tLoss: 4.092207\n","Train Epoch: 4 [11520/12000 (96.0%)]\tLoss: 4.180316\n","Train Epoch: 4 [11840/12000 (98.7%)]\tLoss: 4.028932\n","\n","Test set: Average loss: 4.0837, Accuracy: 782/8580 (9.00%), F1: 0.06\n","\n","Train Epoch: 5 [0/12000 (0.0%)]\tLoss: 3.608940\n","Train Epoch: 5 [320/12000 (2.7%)]\tLoss: 3.274673\n","Train Epoch: 5 [640/12000 (5.3%)]\tLoss: 3.330116\n","Train Epoch: 5 [960/12000 (8.0%)]\tLoss: 3.988001\n","Train Epoch: 5 [1280/12000 (10.7%)]\tLoss: 3.721717\n","Train Epoch: 5 [1600/12000 (13.3%)]\tLoss: 3.480925\n","Train Epoch: 5 [1920/12000 (16.0%)]\tLoss: 4.202232\n","Train Epoch: 5 [2240/12000 (18.7%)]\tLoss: 2.804643\n","Train Epoch: 5 [2560/12000 (21.3%)]\tLoss: 3.065501\n","Train Epoch: 5 [2880/12000 (24.0%)]\tLoss: 3.415066\n","Train Epoch: 5 [3200/12000 (26.7%)]\tLoss: 3.814586\n","Train Epoch: 5 [3520/12000 (29.3%)]\tLoss: 2.969116\n","Train Epoch: 5 [3840/12000 (32.0%)]\tLoss: 3.857030\n","Train Epoch: 5 [4160/12000 (34.7%)]\tLoss: 3.767087\n","Train Epoch: 5 [4480/12000 (37.3%)]\tLoss: 3.078506\n","Train Epoch: 5 [4800/12000 (40.0%)]\tLoss: 3.552062\n","Train Epoch: 5 [5120/12000 (42.7%)]\tLoss: 3.773545\n","Train Epoch: 5 [5440/12000 (45.3%)]\tLoss: 3.294804\n","Train Epoch: 5 [5760/12000 (48.0%)]\tLoss: 3.496938\n","Train Epoch: 5 [6080/12000 (50.7%)]\tLoss: 3.497699\n","Train Epoch: 5 [6400/12000 (53.3%)]\tLoss: 4.497121\n","Train Epoch: 5 [6720/12000 (56.0%)]\tLoss: 3.187165\n","Train Epoch: 5 [7040/12000 (58.7%)]\tLoss: 3.239577\n","Train Epoch: 5 [7360/12000 (61.3%)]\tLoss: 4.361759\n","Train Epoch: 5 [7680/12000 (64.0%)]\tLoss: 3.564170\n","Train Epoch: 5 [8000/12000 (66.7%)]\tLoss: 4.272725\n","Train Epoch: 5 [8320/12000 (69.3%)]\tLoss: 3.171154\n","Train Epoch: 5 [8640/12000 (72.0%)]\tLoss: 3.925065\n","Train Epoch: 5 [8960/12000 (74.7%)]\tLoss: 3.552111\n","Train Epoch: 5 [9280/12000 (77.3%)]\tLoss: 3.495170\n","Train Epoch: 5 [9600/12000 (80.0%)]\tLoss: 3.760614\n","Train Epoch: 5 [9920/12000 (82.7%)]\tLoss: 2.879464\n","Train Epoch: 5 [10240/12000 (85.3%)]\tLoss: 3.605649\n","Train Epoch: 5 [10560/12000 (88.0%)]\tLoss: 3.847436\n","Train Epoch: 5 [10880/12000 (90.7%)]\tLoss: 3.909188\n","Train Epoch: 5 [11200/12000 (93.3%)]\tLoss: 3.997149\n","Train Epoch: 5 [11520/12000 (96.0%)]\tLoss: 3.521999\n","Train Epoch: 5 [11840/12000 (98.7%)]\tLoss: 3.682538\n","\n","Test set: Average loss: 4.0097, Accuracy: 857/8580 (9.00%), F1: 0.08\n","\n","Train Epoch: 6 [0/12000 (0.0%)]\tLoss: 3.822112\n","Train Epoch: 6 [320/12000 (2.7%)]\tLoss: 3.384192\n","Train Epoch: 6 [640/12000 (5.3%)]\tLoss: 3.674689\n","Train Epoch: 6 [960/12000 (8.0%)]\tLoss: 3.690306\n","Train Epoch: 6 [1280/12000 (10.7%)]\tLoss: 3.298091\n","Train Epoch: 6 [1600/12000 (13.3%)]\tLoss: 3.637214\n","Train Epoch: 6 [1920/12000 (16.0%)]\tLoss: 2.980290\n","Train Epoch: 6 [2240/12000 (18.7%)]\tLoss: 3.848337\n","Train Epoch: 6 [2560/12000 (21.3%)]\tLoss: 3.970259\n","Train Epoch: 6 [2880/12000 (24.0%)]\tLoss: 3.414396\n","Train Epoch: 6 [3200/12000 (26.7%)]\tLoss: 3.675658\n","Train Epoch: 6 [3520/12000 (29.3%)]\tLoss: 3.772412\n","Train Epoch: 6 [3840/12000 (32.0%)]\tLoss: 3.670097\n","Train Epoch: 6 [4160/12000 (34.7%)]\tLoss: 4.260206\n","Train Epoch: 6 [4480/12000 (37.3%)]\tLoss: 3.627307\n","Train Epoch: 6 [4800/12000 (40.0%)]\tLoss: 3.140278\n","Train Epoch: 6 [5120/12000 (42.7%)]\tLoss: 3.386792\n","Train Epoch: 6 [5440/12000 (45.3%)]\tLoss: 3.481750\n","Train Epoch: 6 [5760/12000 (48.0%)]\tLoss: 4.045129\n","Train Epoch: 6 [6080/12000 (50.7%)]\tLoss: 3.418108\n","Train Epoch: 6 [6400/12000 (53.3%)]\tLoss: 3.500425\n","Train Epoch: 6 [6720/12000 (56.0%)]\tLoss: 3.668227\n","Train Epoch: 6 [7040/12000 (58.7%)]\tLoss: 3.424564\n","Train Epoch: 6 [7360/12000 (61.3%)]\tLoss: 3.325061\n","Train Epoch: 6 [7680/12000 (64.0%)]\tLoss: 3.877480\n","Train Epoch: 6 [8000/12000 (66.7%)]\tLoss: 3.400125\n","Train Epoch: 6 [8320/12000 (69.3%)]\tLoss: 3.936907\n","Train Epoch: 6 [8640/12000 (72.0%)]\tLoss: 3.925176\n","Train Epoch: 6 [8960/12000 (74.7%)]\tLoss: 3.884208\n","Train Epoch: 6 [9280/12000 (77.3%)]\tLoss: 3.960393\n","Train Epoch: 6 [9600/12000 (80.0%)]\tLoss: 4.020957\n","Train Epoch: 6 [9920/12000 (82.7%)]\tLoss: 3.955925\n","Train Epoch: 6 [10240/12000 (85.3%)]\tLoss: 3.590740\n","Train Epoch: 6 [10560/12000 (88.0%)]\tLoss: 3.981925\n","Train Epoch: 6 [10880/12000 (90.7%)]\tLoss: 3.821034\n","Train Epoch: 6 [11200/12000 (93.3%)]\tLoss: 3.396402\n","Train Epoch: 6 [11520/12000 (96.0%)]\tLoss: 3.794802\n","Train Epoch: 6 [11840/12000 (98.7%)]\tLoss: 3.919797\n","\n","Test set: Average loss: 3.9862, Accuracy: 864/8580 (10.00%), F1: 0.05\n","\n","Train Epoch: 7 [0/12000 (0.0%)]\tLoss: 3.653855\n","Train Epoch: 7 [320/12000 (2.7%)]\tLoss: 2.866947\n","Train Epoch: 7 [640/12000 (5.3%)]\tLoss: 3.642111\n","Train Epoch: 7 [960/12000 (8.0%)]\tLoss: 3.061083\n","Train Epoch: 7 [1280/12000 (10.7%)]\tLoss: 3.965857\n","Train Epoch: 7 [1600/12000 (13.3%)]\tLoss: 3.970056\n","Train Epoch: 7 [1920/12000 (16.0%)]\tLoss: 3.552876\n","Train Epoch: 7 [2240/12000 (18.7%)]\tLoss: 2.851228\n","Train Epoch: 7 [2560/12000 (21.3%)]\tLoss: 3.249549\n","Train Epoch: 7 [2880/12000 (24.0%)]\tLoss: 3.734476\n","Train Epoch: 7 [3200/12000 (26.7%)]\tLoss: 3.327981\n","Train Epoch: 7 [3520/12000 (29.3%)]\tLoss: 3.648584\n","Train Epoch: 7 [3840/12000 (32.0%)]\tLoss: 3.699194\n","Train Epoch: 7 [4160/12000 (34.7%)]\tLoss: 3.800312\n","Train Epoch: 7 [4480/12000 (37.3%)]\tLoss: 3.770643\n","Train Epoch: 7 [4800/12000 (40.0%)]\tLoss: 3.817118\n","Train Epoch: 7 [5120/12000 (42.7%)]\tLoss: 3.374451\n","Train Epoch: 7 [5440/12000 (45.3%)]\tLoss: 3.979736\n","Train Epoch: 7 [5760/12000 (48.0%)]\tLoss: 3.161506\n","Train Epoch: 7 [6080/12000 (50.7%)]\tLoss: 3.182517\n","Train Epoch: 7 [6400/12000 (53.3%)]\tLoss: 3.702801\n","Train Epoch: 7 [6720/12000 (56.0%)]\tLoss: 3.628766\n","Train Epoch: 7 [7040/12000 (58.7%)]\tLoss: 4.337046\n","Train Epoch: 7 [7360/12000 (61.3%)]\tLoss: 3.965748\n","Train Epoch: 7 [7680/12000 (64.0%)]\tLoss: 2.995498\n","Train Epoch: 7 [8000/12000 (66.7%)]\tLoss: 4.169247\n","Train Epoch: 7 [8320/12000 (69.3%)]\tLoss: 4.010445\n","Train Epoch: 7 [8640/12000 (72.0%)]\tLoss: 3.494792\n","Train Epoch: 7 [8960/12000 (74.7%)]\tLoss: 3.300452\n","Train Epoch: 7 [9280/12000 (77.3%)]\tLoss: 3.584006\n","Train Epoch: 7 [9600/12000 (80.0%)]\tLoss: 2.921579\n","Train Epoch: 7 [9920/12000 (82.7%)]\tLoss: 3.727141\n","Train Epoch: 7 [10240/12000 (85.3%)]\tLoss: 3.408984\n","Train Epoch: 7 [10560/12000 (88.0%)]\tLoss: 3.471505\n","Train Epoch: 7 [10880/12000 (90.7%)]\tLoss: 3.748343\n","Train Epoch: 7 [11200/12000 (93.3%)]\tLoss: 3.599654\n","Train Epoch: 7 [11520/12000 (96.0%)]\tLoss: 3.259456\n","Train Epoch: 7 [11840/12000 (98.7%)]\tLoss: 4.119037\n","\n","Test set: Average loss: 3.9545, Accuracy: 846/8580 (9.00%), F1: 0.06\n","\n","Train Epoch: 8 [0/12000 (0.0%)]\tLoss: 3.130083\n","Train Epoch: 8 [320/12000 (2.7%)]\tLoss: 3.292377\n","Train Epoch: 8 [640/12000 (5.3%)]\tLoss: 3.200140\n","Train Epoch: 8 [960/12000 (8.0%)]\tLoss: 3.484232\n","Train Epoch: 8 [1280/12000 (10.7%)]\tLoss: 4.109318\n","Train Epoch: 8 [1600/12000 (13.3%)]\tLoss: 3.733718\n","Train Epoch: 8 [1920/12000 (16.0%)]\tLoss: 3.264760\n","Train Epoch: 8 [2240/12000 (18.7%)]\tLoss: 2.886529\n","Train Epoch: 8 [2560/12000 (21.3%)]\tLoss: 3.245411\n","Train Epoch: 8 [2880/12000 (24.0%)]\tLoss: 2.765069\n","Train Epoch: 8 [3200/12000 (26.7%)]\tLoss: 3.126838\n","Train Epoch: 8 [3520/12000 (29.3%)]\tLoss: 4.205054\n","Train Epoch: 8 [3840/12000 (32.0%)]\tLoss: 3.743592\n","Train Epoch: 8 [4160/12000 (34.7%)]\tLoss: 4.208236\n","Train Epoch: 8 [4480/12000 (37.3%)]\tLoss: 3.781081\n","Train Epoch: 8 [4800/12000 (40.0%)]\tLoss: 3.257008\n","Train Epoch: 8 [5120/12000 (42.7%)]\tLoss: 3.339573\n","Train Epoch: 8 [5440/12000 (45.3%)]\tLoss: 3.189235\n","Train Epoch: 8 [5760/12000 (48.0%)]\tLoss: 3.313513\n","Train Epoch: 8 [6080/12000 (50.7%)]\tLoss: 3.791809\n","Train Epoch: 8 [6400/12000 (53.3%)]\tLoss: 3.149634\n","Train Epoch: 8 [6720/12000 (56.0%)]\tLoss: 3.528628\n","Train Epoch: 8 [7040/12000 (58.7%)]\tLoss: 3.833163\n","Train Epoch: 8 [7360/12000 (61.3%)]\tLoss: 3.106821\n","Train Epoch: 8 [7680/12000 (64.0%)]\tLoss: 3.303717\n","Train Epoch: 8 [8000/12000 (66.7%)]\tLoss: 3.344683\n","Train Epoch: 8 [8320/12000 (69.3%)]\tLoss: 3.607306\n","Train Epoch: 8 [8640/12000 (72.0%)]\tLoss: 3.783019\n","Train Epoch: 8 [8960/12000 (74.7%)]\tLoss: 3.812593\n","Train Epoch: 8 [9280/12000 (77.3%)]\tLoss: 3.666854\n","Train Epoch: 8 [9600/12000 (80.0%)]\tLoss: 3.611938\n","Train Epoch: 8 [9920/12000 (82.7%)]\tLoss: 4.049012\n","Train Epoch: 8 [10240/12000 (85.3%)]\tLoss: 3.910731\n","Train Epoch: 8 [10560/12000 (88.0%)]\tLoss: 3.830837\n","Train Epoch: 8 [10880/12000 (90.7%)]\tLoss: 3.172005\n","Train Epoch: 8 [11200/12000 (93.3%)]\tLoss: 3.956339\n","Train Epoch: 8 [11520/12000 (96.0%)]\tLoss: 2.565238\n","Train Epoch: 8 [11840/12000 (98.7%)]\tLoss: 3.462022\n","\n","Test set: Average loss: 4.1742, Accuracy: 893/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 9 [0/12000 (0.0%)]\tLoss: 3.835834\n","Train Epoch: 9 [320/12000 (2.7%)]\tLoss: 2.716539\n","Train Epoch: 9 [640/12000 (5.3%)]\tLoss: 3.737550\n","Train Epoch: 9 [960/12000 (8.0%)]\tLoss: 3.423344\n","Train Epoch: 9 [1280/12000 (10.7%)]\tLoss: 4.557509\n","Train Epoch: 9 [1600/12000 (13.3%)]\tLoss: 3.456495\n","Train Epoch: 9 [1920/12000 (16.0%)]\tLoss: 3.402626\n","Train Epoch: 9 [2240/12000 (18.7%)]\tLoss: 3.490536\n","Train Epoch: 9 [2560/12000 (21.3%)]\tLoss: 3.588531\n","Train Epoch: 9 [2880/12000 (24.0%)]\tLoss: 4.083872\n","Train Epoch: 9 [3200/12000 (26.7%)]\tLoss: 3.951617\n","Train Epoch: 9 [3520/12000 (29.3%)]\tLoss: 3.184161\n","Train Epoch: 9 [3840/12000 (32.0%)]\tLoss: 3.575593\n","Train Epoch: 9 [4160/12000 (34.7%)]\tLoss: 3.316093\n","Train Epoch: 9 [4480/12000 (37.3%)]\tLoss: 3.345232\n","Train Epoch: 9 [4800/12000 (40.0%)]\tLoss: 3.220517\n","Train Epoch: 9 [5120/12000 (42.7%)]\tLoss: 3.004636\n","Train Epoch: 9 [5440/12000 (45.3%)]\tLoss: 4.704224\n","Train Epoch: 9 [5760/12000 (48.0%)]\tLoss: 3.794460\n","Train Epoch: 9 [6080/12000 (50.7%)]\tLoss: 3.413653\n","Train Epoch: 9 [6400/12000 (53.3%)]\tLoss: 3.391258\n","Train Epoch: 9 [6720/12000 (56.0%)]\tLoss: 2.871523\n","Train Epoch: 9 [7040/12000 (58.7%)]\tLoss: 3.255469\n","Train Epoch: 9 [7360/12000 (61.3%)]\tLoss: 4.383173\n","Train Epoch: 9 [7680/12000 (64.0%)]\tLoss: 3.389119\n","Train Epoch: 9 [8000/12000 (66.7%)]\tLoss: 3.566272\n","Train Epoch: 9 [8320/12000 (69.3%)]\tLoss: 4.523180\n","Train Epoch: 9 [8640/12000 (72.0%)]\tLoss: 4.437735\n","Train Epoch: 9 [8960/12000 (74.7%)]\tLoss: 3.919893\n","Train Epoch: 9 [9280/12000 (77.3%)]\tLoss: 3.203508\n","Train Epoch: 9 [9600/12000 (80.0%)]\tLoss: 3.450789\n","Train Epoch: 9 [9920/12000 (82.7%)]\tLoss: 3.490751\n","Train Epoch: 9 [10240/12000 (85.3%)]\tLoss: 3.318117\n","Train Epoch: 9 [10560/12000 (88.0%)]\tLoss: 3.837729\n","Train Epoch: 9 [10880/12000 (90.7%)]\tLoss: 3.958051\n","Train Epoch: 9 [11200/12000 (93.3%)]\tLoss: 3.964999\n","Train Epoch: 9 [11520/12000 (96.0%)]\tLoss: 3.027028\n","Train Epoch: 9 [11840/12000 (98.7%)]\tLoss: 3.591003\n","\n","Test set: Average loss: 4.1107, Accuracy: 902/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 10 [0/12000 (0.0%)]\tLoss: 3.368280\n","Train Epoch: 10 [320/12000 (2.7%)]\tLoss: 3.212740\n","Train Epoch: 10 [640/12000 (5.3%)]\tLoss: 4.049885\n","Train Epoch: 10 [960/12000 (8.0%)]\tLoss: 3.072240\n","Train Epoch: 10 [1280/12000 (10.7%)]\tLoss: 2.941278\n","Train Epoch: 10 [1600/12000 (13.3%)]\tLoss: 3.891452\n","Train Epoch: 10 [1920/12000 (16.0%)]\tLoss: 2.408549\n","Train Epoch: 10 [2240/12000 (18.7%)]\tLoss: 3.332809\n","Train Epoch: 10 [2560/12000 (21.3%)]\tLoss: 2.818664\n","Train Epoch: 10 [2880/12000 (24.0%)]\tLoss: 3.937072\n","Train Epoch: 10 [3200/12000 (26.7%)]\tLoss: 3.169580\n","Train Epoch: 10 [3520/12000 (29.3%)]\tLoss: 3.658025\n","Train Epoch: 10 [3840/12000 (32.0%)]\tLoss: 3.399457\n","Train Epoch: 10 [4160/12000 (34.7%)]\tLoss: 3.776039\n","Train Epoch: 10 [4480/12000 (37.3%)]\tLoss: 3.088550\n","Train Epoch: 10 [4800/12000 (40.0%)]\tLoss: 3.811112\n","Train Epoch: 10 [5120/12000 (42.7%)]\tLoss: 3.724954\n","Train Epoch: 10 [5440/12000 (45.3%)]\tLoss: 3.689452\n","Train Epoch: 10 [5760/12000 (48.0%)]\tLoss: 3.287479\n","Train Epoch: 10 [6080/12000 (50.7%)]\tLoss: 3.429906\n","Train Epoch: 10 [6400/12000 (53.3%)]\tLoss: 3.608602\n","Train Epoch: 10 [6720/12000 (56.0%)]\tLoss: 3.691962\n","Train Epoch: 10 [7040/12000 (58.7%)]\tLoss: 3.558165\n","Train Epoch: 10 [7360/12000 (61.3%)]\tLoss: 3.810566\n","Train Epoch: 10 [7680/12000 (64.0%)]\tLoss: 2.332480\n","Train Epoch: 10 [8000/12000 (66.7%)]\tLoss: 3.624593\n","Train Epoch: 10 [8320/12000 (69.3%)]\tLoss: 3.343141\n","Train Epoch: 10 [8640/12000 (72.0%)]\tLoss: 3.447765\n","Train Epoch: 10 [8960/12000 (74.7%)]\tLoss: 3.373637\n","Train Epoch: 10 [9280/12000 (77.3%)]\tLoss: 2.729262\n","Train Epoch: 10 [9600/12000 (80.0%)]\tLoss: 3.571586\n","Train Epoch: 10 [9920/12000 (82.7%)]\tLoss: 4.131907\n","Train Epoch: 10 [10240/12000 (85.3%)]\tLoss: 4.107601\n","Train Epoch: 10 [10560/12000 (88.0%)]\tLoss: 3.077055\n","Train Epoch: 10 [10880/12000 (90.7%)]\tLoss: 3.126243\n","Train Epoch: 10 [11200/12000 (93.3%)]\tLoss: 3.701244\n","Train Epoch: 10 [11520/12000 (96.0%)]\tLoss: 2.990670\n","Train Epoch: 10 [11840/12000 (98.7%)]\tLoss: 2.966533\n","\n","Test set: Average loss: 4.1575, Accuracy: 898/8580 (10.00%), F1: 0.08\n","\n","Train Epoch: 11 [0/12000 (0.0%)]\tLoss: 2.825130\n","Train Epoch: 11 [320/12000 (2.7%)]\tLoss: 3.102792\n","Train Epoch: 11 [640/12000 (5.3%)]\tLoss: 3.685705\n","Train Epoch: 11 [960/12000 (8.0%)]\tLoss: 2.361493\n","Train Epoch: 11 [1280/12000 (10.7%)]\tLoss: 2.819026\n","Train Epoch: 11 [1600/12000 (13.3%)]\tLoss: 3.748308\n","Train Epoch: 11 [1920/12000 (16.0%)]\tLoss: 3.531765\n","Train Epoch: 11 [2240/12000 (18.7%)]\tLoss: 3.231646\n","Train Epoch: 11 [2560/12000 (21.3%)]\tLoss: 3.315709\n","Train Epoch: 11 [2880/12000 (24.0%)]\tLoss: 3.695236\n","Train Epoch: 11 [3200/12000 (26.7%)]\tLoss: 3.897763\n","Train Epoch: 11 [3520/12000 (29.3%)]\tLoss: 3.320155\n","Train Epoch: 11 [3840/12000 (32.0%)]\tLoss: 3.407426\n","Train Epoch: 11 [4160/12000 (34.7%)]\tLoss: 2.971663\n","Train Epoch: 11 [4480/12000 (37.3%)]\tLoss: 2.643324\n","Train Epoch: 11 [4800/12000 (40.0%)]\tLoss: 3.348311\n","Train Epoch: 11 [5120/12000 (42.7%)]\tLoss: 3.589002\n","Train Epoch: 11 [5440/12000 (45.3%)]\tLoss: 2.987588\n","Train Epoch: 11 [5760/12000 (48.0%)]\tLoss: 4.033349\n","Train Epoch: 11 [6080/12000 (50.7%)]\tLoss: 3.873714\n","Train Epoch: 11 [6400/12000 (53.3%)]\tLoss: 3.274010\n","Train Epoch: 11 [6720/12000 (56.0%)]\tLoss: 3.415548\n","Train Epoch: 11 [7040/12000 (58.7%)]\tLoss: 3.976337\n","Train Epoch: 11 [7360/12000 (61.3%)]\tLoss: 3.832443\n","Train Epoch: 11 [7680/12000 (64.0%)]\tLoss: 3.833882\n","Train Epoch: 11 [8000/12000 (66.7%)]\tLoss: 3.701732\n","Train Epoch: 11 [8320/12000 (69.3%)]\tLoss: 3.531653\n","Train Epoch: 11 [8640/12000 (72.0%)]\tLoss: 3.117902\n","Train Epoch: 11 [8960/12000 (74.7%)]\tLoss: 3.094673\n","Train Epoch: 11 [9280/12000 (77.3%)]\tLoss: 2.969871\n","Train Epoch: 11 [9600/12000 (80.0%)]\tLoss: 3.094289\n","Train Epoch: 11 [9920/12000 (82.7%)]\tLoss: 3.170386\n","Train Epoch: 11 [10240/12000 (85.3%)]\tLoss: 3.412122\n","Train Epoch: 11 [10560/12000 (88.0%)]\tLoss: 4.271173\n","Train Epoch: 11 [10880/12000 (90.7%)]\tLoss: 3.283980\n","Train Epoch: 11 [11200/12000 (93.3%)]\tLoss: 3.964287\n","Train Epoch: 11 [11520/12000 (96.0%)]\tLoss: 4.073720\n","Train Epoch: 11 [11840/12000 (98.7%)]\tLoss: 3.172781\n","\n","Test set: Average loss: 4.0994, Accuracy: 870/8580 (10.00%), F1: 0.08\n","\n","Train Epoch: 12 [0/12000 (0.0%)]\tLoss: 3.129501\n","Train Epoch: 12 [320/12000 (2.7%)]\tLoss: 3.314686\n","Train Epoch: 12 [640/12000 (5.3%)]\tLoss: 3.639106\n","Train Epoch: 12 [960/12000 (8.0%)]\tLoss: 3.370913\n","Train Epoch: 12 [1280/12000 (10.7%)]\tLoss: 3.848410\n","Train Epoch: 12 [1600/12000 (13.3%)]\tLoss: 2.843543\n","Train Epoch: 12 [1920/12000 (16.0%)]\tLoss: 3.446508\n","Train Epoch: 12 [2240/12000 (18.7%)]\tLoss: 2.895053\n","Train Epoch: 12 [2560/12000 (21.3%)]\tLoss: 2.974633\n","Train Epoch: 12 [2880/12000 (24.0%)]\tLoss: 3.016802\n","Train Epoch: 12 [3200/12000 (26.7%)]\tLoss: 2.984067\n","Train Epoch: 12 [3520/12000 (29.3%)]\tLoss: 3.166915\n","Train Epoch: 12 [3840/12000 (32.0%)]\tLoss: 2.763452\n","Train Epoch: 12 [4160/12000 (34.7%)]\tLoss: 3.124547\n","Train Epoch: 12 [4480/12000 (37.3%)]\tLoss: 4.226877\n","Train Epoch: 12 [4800/12000 (40.0%)]\tLoss: 3.703410\n","Train Epoch: 12 [5120/12000 (42.7%)]\tLoss: 3.647959\n","Train Epoch: 12 [5440/12000 (45.3%)]\tLoss: 3.047781\n","Train Epoch: 12 [5760/12000 (48.0%)]\tLoss: 3.592328\n","Train Epoch: 12 [6080/12000 (50.7%)]\tLoss: 3.412508\n","Train Epoch: 12 [6400/12000 (53.3%)]\tLoss: 4.257440\n","Train Epoch: 12 [6720/12000 (56.0%)]\tLoss: 3.017744\n","Train Epoch: 12 [7040/12000 (58.7%)]\tLoss: 3.246154\n","Train Epoch: 12 [7360/12000 (61.3%)]\tLoss: 3.444249\n","Train Epoch: 12 [7680/12000 (64.0%)]\tLoss: 3.051754\n","Train Epoch: 12 [8000/12000 (66.7%)]\tLoss: 3.983006\n","Train Epoch: 12 [8320/12000 (69.3%)]\tLoss: 3.677621\n","Train Epoch: 12 [8640/12000 (72.0%)]\tLoss: 4.167447\n","Train Epoch: 12 [8960/12000 (74.7%)]\tLoss: 3.428434\n","Train Epoch: 12 [9280/12000 (77.3%)]\tLoss: 3.770310\n","Train Epoch: 12 [9600/12000 (80.0%)]\tLoss: 3.065766\n","Train Epoch: 12 [9920/12000 (82.7%)]\tLoss: 3.038786\n","Train Epoch: 12 [10240/12000 (85.3%)]\tLoss: 3.506402\n","Train Epoch: 12 [10560/12000 (88.0%)]\tLoss: 3.560641\n","Train Epoch: 12 [10880/12000 (90.7%)]\tLoss: 4.195959\n","Train Epoch: 12 [11200/12000 (93.3%)]\tLoss: 4.092312\n","Train Epoch: 12 [11520/12000 (96.0%)]\tLoss: 3.083356\n","Train Epoch: 12 [11840/12000 (98.7%)]\tLoss: 3.420138\n","\n","Test set: Average loss: 4.1086, Accuracy: 983/8580 (11.00%), F1: 0.06\n","\n","Train Epoch: 13 [0/12000 (0.0%)]\tLoss: 3.232249\n","Train Epoch: 13 [320/12000 (2.7%)]\tLoss: 3.323365\n","Train Epoch: 13 [640/12000 (5.3%)]\tLoss: 3.463546\n","Train Epoch: 13 [960/12000 (8.0%)]\tLoss: 3.133217\n","Train Epoch: 13 [1280/12000 (10.7%)]\tLoss: 2.607856\n","Train Epoch: 13 [1600/12000 (13.3%)]\tLoss: 3.439416\n","Train Epoch: 13 [1920/12000 (16.0%)]\tLoss: 2.194185\n","Train Epoch: 13 [2240/12000 (18.7%)]\tLoss: 3.882611\n","Train Epoch: 13 [2560/12000 (21.3%)]\tLoss: 3.199627\n","Train Epoch: 13 [2880/12000 (24.0%)]\tLoss: 3.074508\n","Train Epoch: 13 [3200/12000 (26.7%)]\tLoss: 3.384133\n","Train Epoch: 13 [3520/12000 (29.3%)]\tLoss: 4.401463\n","Train Epoch: 13 [3840/12000 (32.0%)]\tLoss: 3.093570\n","Train Epoch: 13 [4160/12000 (34.7%)]\tLoss: 2.978210\n","Train Epoch: 13 [4480/12000 (37.3%)]\tLoss: 3.288871\n","Train Epoch: 13 [4800/12000 (40.0%)]\tLoss: 3.226396\n","Train Epoch: 13 [5120/12000 (42.7%)]\tLoss: 3.415622\n","Train Epoch: 13 [5440/12000 (45.3%)]\tLoss: 3.164768\n","Train Epoch: 13 [5760/12000 (48.0%)]\tLoss: 2.917744\n","Train Epoch: 13 [6080/12000 (50.7%)]\tLoss: 3.432838\n","Train Epoch: 13 [6400/12000 (53.3%)]\tLoss: 2.873133\n","Train Epoch: 13 [6720/12000 (56.0%)]\tLoss: 3.423038\n","Train Epoch: 13 [7040/12000 (58.7%)]\tLoss: 3.023765\n","Train Epoch: 13 [7360/12000 (61.3%)]\tLoss: 3.408398\n","Train Epoch: 13 [7680/12000 (64.0%)]\tLoss: 3.353739\n","Train Epoch: 13 [8000/12000 (66.7%)]\tLoss: 2.727832\n","Train Epoch: 13 [8320/12000 (69.3%)]\tLoss: 3.155578\n","Train Epoch: 13 [8640/12000 (72.0%)]\tLoss: 4.483374\n","Train Epoch: 13 [8960/12000 (74.7%)]\tLoss: 3.625568\n","Train Epoch: 13 [9280/12000 (77.3%)]\tLoss: 3.306772\n","Train Epoch: 13 [9600/12000 (80.0%)]\tLoss: 3.055018\n","Train Epoch: 13 [9920/12000 (82.7%)]\tLoss: 2.546777\n","Train Epoch: 13 [10240/12000 (85.3%)]\tLoss: 3.892955\n","Train Epoch: 13 [10560/12000 (88.0%)]\tLoss: 3.521243\n","Train Epoch: 13 [10880/12000 (90.7%)]\tLoss: 3.251176\n","Train Epoch: 13 [11200/12000 (93.3%)]\tLoss: 3.684779\n","Train Epoch: 13 [11520/12000 (96.0%)]\tLoss: 3.669131\n","Train Epoch: 13 [11840/12000 (98.7%)]\tLoss: 3.239612\n","\n","Test set: Average loss: 4.3351, Accuracy: 833/8580 (9.00%), F1: 0.07\n","\n","Train Epoch: 14 [0/12000 (0.0%)]\tLoss: 3.016028\n","Train Epoch: 14 [320/12000 (2.7%)]\tLoss: 3.423619\n","Train Epoch: 14 [640/12000 (5.3%)]\tLoss: 3.797686\n","Train Epoch: 14 [960/12000 (8.0%)]\tLoss: 3.381937\n","Train Epoch: 14 [1280/12000 (10.7%)]\tLoss: 3.009827\n","Train Epoch: 14 [1600/12000 (13.3%)]\tLoss: 3.288757\n","Train Epoch: 14 [1920/12000 (16.0%)]\tLoss: 3.505780\n","Train Epoch: 14 [2240/12000 (18.7%)]\tLoss: 3.471724\n","Train Epoch: 14 [2560/12000 (21.3%)]\tLoss: 2.969254\n","Train Epoch: 14 [2880/12000 (24.0%)]\tLoss: 3.491583\n","Train Epoch: 14 [3200/12000 (26.7%)]\tLoss: 2.865442\n","Train Epoch: 14 [3520/12000 (29.3%)]\tLoss: 2.840376\n","Train Epoch: 14 [3840/12000 (32.0%)]\tLoss: 3.328722\n","Train Epoch: 14 [4160/12000 (34.7%)]\tLoss: 3.480389\n","Train Epoch: 14 [4480/12000 (37.3%)]\tLoss: 2.749823\n","Train Epoch: 14 [4800/12000 (40.0%)]\tLoss: 3.158703\n","Train Epoch: 14 [5120/12000 (42.7%)]\tLoss: 3.383522\n","Train Epoch: 14 [5440/12000 (45.3%)]\tLoss: 2.921909\n","Train Epoch: 14 [5760/12000 (48.0%)]\tLoss: 2.631429\n","Train Epoch: 14 [6080/12000 (50.7%)]\tLoss: 3.029744\n","Train Epoch: 14 [6400/12000 (53.3%)]\tLoss: 3.235044\n","Train Epoch: 14 [6720/12000 (56.0%)]\tLoss: 3.162508\n","Train Epoch: 14 [7040/12000 (58.7%)]\tLoss: 4.383225\n","Train Epoch: 14 [7360/12000 (61.3%)]\tLoss: 2.788231\n","Train Epoch: 14 [7680/12000 (64.0%)]\tLoss: 3.584054\n","Train Epoch: 14 [8000/12000 (66.7%)]\tLoss: 3.856907\n","Train Epoch: 14 [8320/12000 (69.3%)]\tLoss: 3.207866\n","Train Epoch: 14 [8640/12000 (72.0%)]\tLoss: 3.393579\n","Train Epoch: 14 [8960/12000 (74.7%)]\tLoss: 3.074724\n","Train Epoch: 14 [9280/12000 (77.3%)]\tLoss: 3.956007\n","Train Epoch: 14 [9600/12000 (80.0%)]\tLoss: 3.656111\n","Train Epoch: 14 [9920/12000 (82.7%)]\tLoss: 2.835915\n","Train Epoch: 14 [10240/12000 (85.3%)]\tLoss: 3.332834\n","Train Epoch: 14 [10560/12000 (88.0%)]\tLoss: 3.021693\n","Train Epoch: 14 [10880/12000 (90.7%)]\tLoss: 3.891572\n","Train Epoch: 14 [11200/12000 (93.3%)]\tLoss: 2.748078\n","Train Epoch: 14 [11520/12000 (96.0%)]\tLoss: 3.839097\n","Train Epoch: 14 [11840/12000 (98.7%)]\tLoss: 3.223500\n","\n","Test set: Average loss: 4.2761, Accuracy: 815/8580 (9.00%), F1: 0.05\n","\n","Train Epoch: 15 [0/12000 (0.0%)]\tLoss: 2.670940\n","Train Epoch: 15 [320/12000 (2.7%)]\tLoss: 2.378542\n","Train Epoch: 15 [640/12000 (5.3%)]\tLoss: 2.346326\n","Train Epoch: 15 [960/12000 (8.0%)]\tLoss: 2.894359\n","Train Epoch: 15 [1280/12000 (10.7%)]\tLoss: 2.674489\n","Train Epoch: 15 [1600/12000 (13.3%)]\tLoss: 3.289624\n","Train Epoch: 15 [1920/12000 (16.0%)]\tLoss: 2.425100\n","Train Epoch: 15 [2240/12000 (18.7%)]\tLoss: 3.601172\n","Train Epoch: 15 [2560/12000 (21.3%)]\tLoss: 4.173890\n","Train Epoch: 15 [2880/12000 (24.0%)]\tLoss: 2.875900\n","Train Epoch: 15 [3200/12000 (26.7%)]\tLoss: 3.448426\n","Train Epoch: 15 [3520/12000 (29.3%)]\tLoss: 3.341105\n","Train Epoch: 15 [3840/12000 (32.0%)]\tLoss: 4.378943\n","Train Epoch: 15 [4160/12000 (34.7%)]\tLoss: 3.294081\n","Train Epoch: 15 [4480/12000 (37.3%)]\tLoss: 3.531292\n","Train Epoch: 15 [4800/12000 (40.0%)]\tLoss: 2.948634\n","Train Epoch: 15 [5120/12000 (42.7%)]\tLoss: 2.179249\n","Train Epoch: 15 [5440/12000 (45.3%)]\tLoss: 3.142214\n","Train Epoch: 15 [5760/12000 (48.0%)]\tLoss: 3.800528\n","Train Epoch: 15 [6080/12000 (50.7%)]\tLoss: 3.265114\n","Train Epoch: 15 [6400/12000 (53.3%)]\tLoss: 2.658027\n","Train Epoch: 15 [6720/12000 (56.0%)]\tLoss: 2.843401\n","Train Epoch: 15 [7040/12000 (58.7%)]\tLoss: 3.156642\n","Train Epoch: 15 [7360/12000 (61.3%)]\tLoss: 3.391728\n","Train Epoch: 15 [7680/12000 (64.0%)]\tLoss: 2.997368\n","Train Epoch: 15 [8000/12000 (66.7%)]\tLoss: 3.102715\n","Train Epoch: 15 [8320/12000 (69.3%)]\tLoss: 3.324789\n","Train Epoch: 15 [8640/12000 (72.0%)]\tLoss: 3.475407\n","Train Epoch: 15 [8960/12000 (74.7%)]\tLoss: 4.041823\n","Train Epoch: 15 [9280/12000 (77.3%)]\tLoss: 2.757621\n","Train Epoch: 15 [9600/12000 (80.0%)]\tLoss: 2.573129\n","Train Epoch: 15 [9920/12000 (82.7%)]\tLoss: 3.068939\n","Train Epoch: 15 [10240/12000 (85.3%)]\tLoss: 2.384722\n","Train Epoch: 15 [10560/12000 (88.0%)]\tLoss: 3.601717\n","Train Epoch: 15 [10880/12000 (90.7%)]\tLoss: 3.382457\n","Train Epoch: 15 [11200/12000 (93.3%)]\tLoss: 2.198664\n","Train Epoch: 15 [11520/12000 (96.0%)]\tLoss: 2.734162\n","Train Epoch: 15 [11840/12000 (98.7%)]\tLoss: 3.112809\n","\n","Test set: Average loss: 4.2751, Accuracy: 866/8580 (10.00%), F1: 0.06\n","\n","Train Epoch: 16 [0/12000 (0.0%)]\tLoss: 1.847018\n","Train Epoch: 16 [320/12000 (2.7%)]\tLoss: 3.041795\n","Train Epoch: 16 [640/12000 (5.3%)]\tLoss: 3.056570\n","Train Epoch: 16 [960/12000 (8.0%)]\tLoss: 2.684195\n","Train Epoch: 16 [1280/12000 (10.7%)]\tLoss: 3.077473\n","Train Epoch: 16 [1600/12000 (13.3%)]\tLoss: 3.386129\n","Train Epoch: 16 [1920/12000 (16.0%)]\tLoss: 2.529534\n","Train Epoch: 16 [2240/12000 (18.7%)]\tLoss: 3.459031\n","Train Epoch: 16 [2560/12000 (21.3%)]\tLoss: 3.357361\n","Train Epoch: 16 [2880/12000 (24.0%)]\tLoss: 3.994561\n","Train Epoch: 16 [3200/12000 (26.7%)]\tLoss: 2.545461\n","Train Epoch: 16 [3520/12000 (29.3%)]\tLoss: 3.337172\n","Train Epoch: 16 [3840/12000 (32.0%)]\tLoss: 3.430334\n","Train Epoch: 16 [4160/12000 (34.7%)]\tLoss: 3.664449\n","Train Epoch: 16 [4480/12000 (37.3%)]\tLoss: 3.109538\n","Train Epoch: 16 [4800/12000 (40.0%)]\tLoss: 2.914959\n","Train Epoch: 16 [5120/12000 (42.7%)]\tLoss: 2.970295\n","Train Epoch: 16 [5440/12000 (45.3%)]\tLoss: 4.045587\n","Train Epoch: 16 [5760/12000 (48.0%)]\tLoss: 3.740192\n","Train Epoch: 16 [6080/12000 (50.7%)]\tLoss: 3.129617\n","Train Epoch: 16 [6400/12000 (53.3%)]\tLoss: 2.968059\n","Train Epoch: 16 [6720/12000 (56.0%)]\tLoss: 3.497213\n","Train Epoch: 16 [7040/12000 (58.7%)]\tLoss: 3.800847\n","Train Epoch: 16 [7360/12000 (61.3%)]\tLoss: 3.063729\n","Train Epoch: 16 [7680/12000 (64.0%)]\tLoss: 2.455357\n","Train Epoch: 16 [8000/12000 (66.7%)]\tLoss: 3.264468\n","Train Epoch: 16 [8320/12000 (69.3%)]\tLoss: 2.754167\n","Train Epoch: 16 [8640/12000 (72.0%)]\tLoss: 2.830846\n","Train Epoch: 16 [8960/12000 (74.7%)]\tLoss: 3.295164\n","Train Epoch: 16 [9280/12000 (77.3%)]\tLoss: 3.866063\n","Train Epoch: 16 [9600/12000 (80.0%)]\tLoss: 3.592824\n","Train Epoch: 16 [9920/12000 (82.7%)]\tLoss: 3.311690\n","Train Epoch: 16 [10240/12000 (85.3%)]\tLoss: 3.094160\n","Train Epoch: 16 [10560/12000 (88.0%)]\tLoss: 2.787349\n","Train Epoch: 16 [10880/12000 (90.7%)]\tLoss: 3.707266\n","Train Epoch: 16 [11200/12000 (93.3%)]\tLoss: 3.246881\n","Train Epoch: 16 [11520/12000 (96.0%)]\tLoss: 3.077032\n","Train Epoch: 16 [11840/12000 (98.7%)]\tLoss: 3.341051\n","\n","Test set: Average loss: 4.4327, Accuracy: 791/8580 (9.00%), F1: 0.06\n","\n","Train Epoch: 17 [0/12000 (0.0%)]\tLoss: 2.946340\n","Train Epoch: 17 [320/12000 (2.7%)]\tLoss: 3.171495\n","Train Epoch: 17 [640/12000 (5.3%)]\tLoss: 2.574506\n","Train Epoch: 17 [960/12000 (8.0%)]\tLoss: 3.434371\n","Train Epoch: 17 [1280/12000 (10.7%)]\tLoss: 2.758815\n","Train Epoch: 17 [1600/12000 (13.3%)]\tLoss: 2.438230\n","Train Epoch: 17 [1920/12000 (16.0%)]\tLoss: 2.457355\n","Train Epoch: 17 [2240/12000 (18.7%)]\tLoss: 3.213387\n","Train Epoch: 17 [2560/12000 (21.3%)]\tLoss: 2.325447\n","Train Epoch: 17 [2880/12000 (24.0%)]\tLoss: 2.610551\n","Train Epoch: 17 [3200/12000 (26.7%)]\tLoss: 3.174039\n","Train Epoch: 17 [3520/12000 (29.3%)]\tLoss: 3.444728\n","Train Epoch: 17 [3840/12000 (32.0%)]\tLoss: 3.031324\n","Train Epoch: 17 [4160/12000 (34.7%)]\tLoss: 3.401737\n","Train Epoch: 17 [4480/12000 (37.3%)]\tLoss: 2.581551\n","Train Epoch: 17 [4800/12000 (40.0%)]\tLoss: 2.819642\n","Train Epoch: 17 [5120/12000 (42.7%)]\tLoss: 2.808793\n","Train Epoch: 17 [5440/12000 (45.3%)]\tLoss: 2.764065\n","Train Epoch: 17 [5760/12000 (48.0%)]\tLoss: 2.543871\n","Train Epoch: 17 [6080/12000 (50.7%)]\tLoss: 3.280794\n","Train Epoch: 17 [6400/12000 (53.3%)]\tLoss: 2.978021\n","Train Epoch: 17 [6720/12000 (56.0%)]\tLoss: 2.998221\n","Train Epoch: 17 [7040/12000 (58.7%)]\tLoss: 3.090172\n","Train Epoch: 17 [7360/12000 (61.3%)]\tLoss: 3.065553\n","Train Epoch: 17 [7680/12000 (64.0%)]\tLoss: 2.784370\n","Train Epoch: 17 [8000/12000 (66.7%)]\tLoss: 3.320204\n","Train Epoch: 17 [8320/12000 (69.3%)]\tLoss: 3.082424\n","Train Epoch: 17 [8640/12000 (72.0%)]\tLoss: 1.861866\n","Train Epoch: 17 [8960/12000 (74.7%)]\tLoss: 3.130867\n","Train Epoch: 17 [9280/12000 (77.3%)]\tLoss: 2.989699\n","Train Epoch: 17 [9600/12000 (80.0%)]\tLoss: 2.800991\n","Train Epoch: 17 [9920/12000 (82.7%)]\tLoss: 2.868501\n","Train Epoch: 17 [10240/12000 (85.3%)]\tLoss: 2.901145\n","Train Epoch: 17 [10560/12000 (88.0%)]\tLoss: 3.499986\n","Train Epoch: 17 [10880/12000 (90.7%)]\tLoss: 3.729332\n","Train Epoch: 17 [11200/12000 (93.3%)]\tLoss: 2.825682\n","Train Epoch: 17 [11520/12000 (96.0%)]\tLoss: 3.553822\n","Train Epoch: 17 [11840/12000 (98.7%)]\tLoss: 3.601003\n","\n","Test set: Average loss: 4.2756, Accuracy: 914/8580 (10.00%), F1: 0.06\n","\n","Train Epoch: 18 [0/12000 (0.0%)]\tLoss: 2.289283\n","Train Epoch: 18 [320/12000 (2.7%)]\tLoss: 3.081331\n","Train Epoch: 18 [640/12000 (5.3%)]\tLoss: 2.567690\n","Train Epoch: 18 [960/12000 (8.0%)]\tLoss: 3.513093\n","Train Epoch: 18 [1280/12000 (10.7%)]\tLoss: 2.780045\n","Train Epoch: 18 [1600/12000 (13.3%)]\tLoss: 3.102509\n","Train Epoch: 18 [1920/12000 (16.0%)]\tLoss: 3.126284\n","Train Epoch: 18 [2240/12000 (18.7%)]\tLoss: 3.519456\n","Train Epoch: 18 [2560/12000 (21.3%)]\tLoss: 3.101506\n","Train Epoch: 18 [2880/12000 (24.0%)]\tLoss: 2.697917\n","Train Epoch: 18 [3200/12000 (26.7%)]\tLoss: 2.933872\n","Train Epoch: 18 [3520/12000 (29.3%)]\tLoss: 3.851474\n","Train Epoch: 18 [3840/12000 (32.0%)]\tLoss: 2.785336\n","Train Epoch: 18 [4160/12000 (34.7%)]\tLoss: 3.527903\n","Train Epoch: 18 [4480/12000 (37.3%)]\tLoss: 3.832335\n","Train Epoch: 18 [4800/12000 (40.0%)]\tLoss: 3.292665\n","Train Epoch: 18 [5120/12000 (42.7%)]\tLoss: 3.330054\n","Train Epoch: 18 [5440/12000 (45.3%)]\tLoss: 2.993479\n","Train Epoch: 18 [5760/12000 (48.0%)]\tLoss: 3.526896\n","Train Epoch: 18 [6080/12000 (50.7%)]\tLoss: 3.018419\n","Train Epoch: 18 [6400/12000 (53.3%)]\tLoss: 3.469102\n","Train Epoch: 18 [6720/12000 (56.0%)]\tLoss: 3.166710\n","Train Epoch: 18 [7040/12000 (58.7%)]\tLoss: 2.165195\n","Train Epoch: 18 [7360/12000 (61.3%)]\tLoss: 2.959492\n","Train Epoch: 18 [7680/12000 (64.0%)]\tLoss: 3.453109\n","Train Epoch: 18 [8000/12000 (66.7%)]\tLoss: 3.388519\n","Train Epoch: 18 [8320/12000 (69.3%)]\tLoss: 3.733326\n","Train Epoch: 18 [8640/12000 (72.0%)]\tLoss: 3.337948\n","Train Epoch: 18 [8960/12000 (74.7%)]\tLoss: 3.241847\n","Train Epoch: 18 [9280/12000 (77.3%)]\tLoss: 3.905020\n","Train Epoch: 18 [9600/12000 (80.0%)]\tLoss: 3.030227\n","Train Epoch: 18 [9920/12000 (82.7%)]\tLoss: 3.256219\n","Train Epoch: 18 [10240/12000 (85.3%)]\tLoss: 3.177710\n","Train Epoch: 18 [10560/12000 (88.0%)]\tLoss: 3.232747\n","Train Epoch: 18 [10880/12000 (90.7%)]\tLoss: 3.442152\n","Train Epoch: 18 [11200/12000 (93.3%)]\tLoss: 3.570656\n","Train Epoch: 18 [11520/12000 (96.0%)]\tLoss: 3.212448\n","Train Epoch: 18 [11840/12000 (98.7%)]\tLoss: 2.988001\n","\n","Test set: Average loss: 4.4668, Accuracy: 859/8580 (10.00%), F1: 0.06\n","\n","Train Epoch: 19 [0/12000 (0.0%)]\tLoss: 2.054162\n","Train Epoch: 19 [320/12000 (2.7%)]\tLoss: 2.290838\n","Train Epoch: 19 [640/12000 (5.3%)]\tLoss: 2.863585\n","Train Epoch: 19 [960/12000 (8.0%)]\tLoss: 2.585641\n","Train Epoch: 19 [1280/12000 (10.7%)]\tLoss: 3.141633\n","Train Epoch: 19 [1600/12000 (13.3%)]\tLoss: 2.468297\n","Train Epoch: 19 [1920/12000 (16.0%)]\tLoss: 3.325886\n","Train Epoch: 19 [2240/12000 (18.7%)]\tLoss: 3.017042\n","Train Epoch: 19 [2560/12000 (21.3%)]\tLoss: 2.953980\n","Train Epoch: 19 [2880/12000 (24.0%)]\tLoss: 3.636260\n","Train Epoch: 19 [3200/12000 (26.7%)]\tLoss: 3.418690\n","Train Epoch: 19 [3520/12000 (29.3%)]\tLoss: 3.385830\n","Train Epoch: 19 [3840/12000 (32.0%)]\tLoss: 3.377211\n","Train Epoch: 19 [4160/12000 (34.7%)]\tLoss: 3.328834\n","Train Epoch: 19 [4480/12000 (37.3%)]\tLoss: 3.194217\n","Train Epoch: 19 [4800/12000 (40.0%)]\tLoss: 2.661772\n","Train Epoch: 19 [5120/12000 (42.7%)]\tLoss: 3.706770\n","Train Epoch: 19 [5440/12000 (45.3%)]\tLoss: 2.837078\n","Train Epoch: 19 [5760/12000 (48.0%)]\tLoss: 3.501679\n","Train Epoch: 19 [6080/12000 (50.7%)]\tLoss: 4.107221\n","Train Epoch: 19 [6400/12000 (53.3%)]\tLoss: 2.832472\n","Train Epoch: 19 [6720/12000 (56.0%)]\tLoss: 3.048086\n","Train Epoch: 19 [7040/12000 (58.7%)]\tLoss: 3.284201\n","Train Epoch: 19 [7360/12000 (61.3%)]\tLoss: 3.928062\n","Train Epoch: 19 [7680/12000 (64.0%)]\tLoss: 3.736293\n","Train Epoch: 19 [8000/12000 (66.7%)]\tLoss: 2.526060\n","Train Epoch: 19 [8320/12000 (69.3%)]\tLoss: 4.177715\n","Train Epoch: 19 [8640/12000 (72.0%)]\tLoss: 2.883064\n","Train Epoch: 19 [8960/12000 (74.7%)]\tLoss: 2.957068\n","Train Epoch: 19 [9280/12000 (77.3%)]\tLoss: 2.947400\n","Train Epoch: 19 [9600/12000 (80.0%)]\tLoss: 3.400953\n","Train Epoch: 19 [9920/12000 (82.7%)]\tLoss: 3.034982\n","Train Epoch: 19 [10240/12000 (85.3%)]\tLoss: 2.918864\n","Train Epoch: 19 [10560/12000 (88.0%)]\tLoss: 2.987765\n","Train Epoch: 19 [10880/12000 (90.7%)]\tLoss: 2.420361\n","Train Epoch: 19 [11200/12000 (93.3%)]\tLoss: 4.238598\n","Train Epoch: 19 [11520/12000 (96.0%)]\tLoss: 3.189841\n","Train Epoch: 19 [11840/12000 (98.7%)]\tLoss: 3.112323\n","\n","Test set: Average loss: 4.3347, Accuracy: 871/8580 (10.00%), F1: 0.07\n","\n","Train Epoch: 20 [0/12000 (0.0%)]\tLoss: 3.314605\n","Train Epoch: 20 [320/12000 (2.7%)]\tLoss: 3.357785\n","Train Epoch: 20 [640/12000 (5.3%)]\tLoss: 2.361452\n","Train Epoch: 20 [960/12000 (8.0%)]\tLoss: 2.312847\n","Train Epoch: 20 [1280/12000 (10.7%)]\tLoss: 2.078333\n","Train Epoch: 20 [1600/12000 (13.3%)]\tLoss: 2.744902\n","Train Epoch: 20 [1920/12000 (16.0%)]\tLoss: 2.402733\n","Train Epoch: 20 [2240/12000 (18.7%)]\tLoss: 2.378277\n","Train Epoch: 20 [2560/12000 (21.3%)]\tLoss: 2.426363\n","Train Epoch: 20 [2880/12000 (24.0%)]\tLoss: 2.682470\n","Train Epoch: 20 [3200/12000 (26.7%)]\tLoss: 1.640112\n","Train Epoch: 20 [3520/12000 (29.3%)]\tLoss: 2.303357\n","Train Epoch: 20 [3840/12000 (32.0%)]\tLoss: 2.226228\n","Train Epoch: 20 [4160/12000 (34.7%)]\tLoss: 2.789623\n","Train Epoch: 20 [4480/12000 (37.3%)]\tLoss: 1.878549\n","Train Epoch: 20 [4800/12000 (40.0%)]\tLoss: 2.676619\n","Train Epoch: 20 [5120/12000 (42.7%)]\tLoss: 1.671891\n","Train Epoch: 20 [5440/12000 (45.3%)]\tLoss: 2.504272\n","Train Epoch: 20 [5760/12000 (48.0%)]\tLoss: 1.907415\n","Train Epoch: 20 [6080/12000 (50.7%)]\tLoss: 3.397449\n","Train Epoch: 20 [6400/12000 (53.3%)]\tLoss: 2.680974\n","Train Epoch: 20 [6720/12000 (56.0%)]\tLoss: 2.692111\n","Train Epoch: 20 [7040/12000 (58.7%)]\tLoss: 2.055421\n","Train Epoch: 20 [7360/12000 (61.3%)]\tLoss: 2.003782\n","Train Epoch: 20 [7680/12000 (64.0%)]\tLoss: 2.584578\n","Train Epoch: 20 [8000/12000 (66.7%)]\tLoss: 2.102377\n","Train Epoch: 20 [8320/12000 (69.3%)]\tLoss: 1.671309\n","Train Epoch: 20 [8640/12000 (72.0%)]\tLoss: 1.949612\n","Train Epoch: 20 [8960/12000 (74.7%)]\tLoss: 1.727104\n","Train Epoch: 20 [9280/12000 (77.3%)]\tLoss: 1.899060\n","Train Epoch: 20 [9600/12000 (80.0%)]\tLoss: 1.887959\n","Train Epoch: 20 [9920/12000 (82.7%)]\tLoss: 2.325424\n","Train Epoch: 20 [10240/12000 (85.3%)]\tLoss: 1.837680\n","Train Epoch: 20 [10560/12000 (88.0%)]\tLoss: 1.330267\n","Train Epoch: 20 [10880/12000 (90.7%)]\tLoss: 1.462772\n","Train Epoch: 20 [11200/12000 (93.3%)]\tLoss: 2.379097\n","Train Epoch: 20 [11520/12000 (96.0%)]\tLoss: 2.443022\n","Train Epoch: 20 [11840/12000 (98.7%)]\tLoss: 1.824589\n","\n","Test set: Average loss: 4.2417, Accuracy: 1166/8580 (13.00%), F1: 0.09\n","\n","Train Epoch: 21 [0/12000 (0.0%)]\tLoss: 2.179627\n","Train Epoch: 21 [320/12000 (2.7%)]\tLoss: 1.823735\n","Train Epoch: 21 [640/12000 (5.3%)]\tLoss: 1.466359\n","Train Epoch: 21 [960/12000 (8.0%)]\tLoss: 1.689622\n","Train Epoch: 21 [1280/12000 (10.7%)]\tLoss: 1.787098\n","Train Epoch: 21 [1600/12000 (13.3%)]\tLoss: 2.209632\n","Train Epoch: 21 [1920/12000 (16.0%)]\tLoss: 2.749527\n","Train Epoch: 21 [2240/12000 (18.7%)]\tLoss: 1.847847\n","Train Epoch: 21 [2560/12000 (21.3%)]\tLoss: 1.986248\n","Train Epoch: 21 [2880/12000 (24.0%)]\tLoss: 1.429085\n","Train Epoch: 21 [3200/12000 (26.7%)]\tLoss: 1.997247\n","Train Epoch: 21 [3520/12000 (29.3%)]\tLoss: 2.035746\n","Train Epoch: 21 [3840/12000 (32.0%)]\tLoss: 2.057423\n","Train Epoch: 21 [4160/12000 (34.7%)]\tLoss: 1.680878\n","Train Epoch: 21 [4480/12000 (37.3%)]\tLoss: 1.963109\n","Train Epoch: 21 [4800/12000 (40.0%)]\tLoss: 2.339143\n","Train Epoch: 21 [5120/12000 (42.7%)]\tLoss: 1.425462\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mcJ_v697wdrT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQIgheC9c2sw","colab_type":"text"},"source":[""]}]}